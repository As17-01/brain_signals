{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 23:38:38.643386: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-06 23:38:38.650483: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-06 23:38:38.677045: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1743971918.721248    3611 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1743971918.732025    3611 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-06 23:38:38.777378: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GRU, Input, BatchNormalization, Dropout\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.keras import LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "NUM_EXPERIMENTS = 5\n",
    "\n",
    "def create_model(train):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train.shape[1], train.shape[2])))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(20, return_sequences=True))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(20, return_sequences=True))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(10, return_sequences=True))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(10, return_sequences=False))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.002, weight_decay=1e-7, use_ema=True), loss='binary_crossentropy', metrics=[\"accuracy\", AUC(name=\"auc\")])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = [\"ID\"]\n",
    "USER = [\"SubjectID\"]\n",
    "IDS = [\"SubjectID\", \"VideoID\"]\n",
    "TARGET = [\"predefinedlabel\"]\n",
    "FEATURES = [\"Delta\", \"Theta\", \"Alpha1\", \"Alpha2\", \"Beta1\", \"Beta2\", \"Gamma1\", \"Gamma2\"]\n",
    "LAGS = [1, 2]\n",
    "INIT_SEED = 5412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>...</th>\n",
       "      <th>Gamma2_1</th>\n",
       "      <th>Delta_2</th>\n",
       "      <th>Theta_2</th>\n",
       "      <th>Alpha1_2</th>\n",
       "      <th>Alpha2_2</th>\n",
       "      <th>Beta1_2</th>\n",
       "      <th>Beta2_2</th>\n",
       "      <th>Gamma1_2</th>\n",
       "      <th>Gamma2_2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>25354.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SubjectID     Delta     Theta    Alpha1   Alpha2    Beta1     Beta2  \\\n",
       "0   0        0.0  301963.0   90612.0   33735.0  23991.0  27946.0   45097.0   \n",
       "1   0        0.0   73787.0   28083.0    1439.0   2240.0   2746.0    3687.0   \n",
       "2   0        0.0  758353.0  383745.0  201999.0  62107.0  36293.0  130536.0   \n",
       "\n",
       "    Gamma1   Gamma2  ...  Gamma2_1   Delta_2  Theta_2  Alpha1_2  Alpha2_2  \\\n",
       "0  33228.0   8293.0  ...       0.0       0.0      0.0       0.0       0.0   \n",
       "1   5293.0   2740.0  ...    8293.0       0.0      0.0       0.0       0.0   \n",
       "2  57243.0  25354.0  ...    2740.0  301963.0  90612.0   33735.0   23991.0   \n",
       "\n",
       "   Beta1_2  Beta2_2  Gamma1_2  Gamma2_2  predefinedlabel  \n",
       "0      0.0      0.0       0.0       0.0              0.0  \n",
       "1      0.0      0.0       0.0       0.0              0.0  \n",
       "2  27946.0  45097.0   33228.0    8293.0              0.0  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"/home/aseliverstov/projects/brain_signals/data\")\n",
    "data = pd.read_csv(data_dir / \"EEG_data.csv\")\n",
    "\n",
    "new_features = []\n",
    "for lag in LAGS:\n",
    "    for feature_name in FEATURES:\n",
    "        new_feature_name = f\"{feature_name}_{lag}\"\n",
    "        new_features.append(new_feature_name)\n",
    "        data[new_feature_name] = data.groupby(IDS)[feature_name].shift(lag).fillna(0)\n",
    "FEATURES.extend(new_features)\n",
    "\n",
    "data[\"ID\"] = (len(np.unique(data[\"VideoID\"])) * data[\"SubjectID\"] + data[\"VideoID\"]).astype(\"int\")\n",
    "data = data[ID + USER + FEATURES + TARGET]\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(data):\n",
    "    features = []\n",
    "    target = []\n",
    "    for cur_id in np.unique(data[ID].to_numpy()):\n",
    "        cur_id_data = data[data[ID].to_numpy() == cur_id]\n",
    "        target.append(np.mean(cur_id_data[TARGET].to_numpy()).astype(\"int\"))\n",
    "        features.append(cur_id_data[FEATURES].to_numpy())\n",
    "\n",
    "    features = pad_sequences(features)\n",
    "    return np.array(features), np.array(target)\n",
    "\n",
    "def pad_sequences(arrays, pad_value=0):\n",
    "    max_length = max(arr.shape[0] for arr in arrays)\n",
    "    padded_arrays = [\n",
    "        np.pad(\n",
    "            arr,\n",
    "            ((0, max_length - arr.shape[0]), (0, 0)),\n",
    "            mode='constant',\n",
    "            constant_values=pad_value)\n",
    "            for arr in arrays\n",
    "        ]\n",
    "    return np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-06 23:38:44.834733: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,668</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,340</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">870</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc (\u001b[38;5;33mLTC\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │         \u001b[38;5;34m3,668\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_1 (\u001b[38;5;33mLTC\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │         \u001b[38;5;34m3,340\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m20\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_2 (\u001b[38;5;33mLTC\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │         \u001b[38;5;34m1,290\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_3 (\u001b[38;5;33mLTC\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m870\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,179</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,179\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,179</span> (35.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,179\u001b[0m (35.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, _ = reshape_dataset(data)\n",
    "model = create_model(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 3s/step - accuracy: 0.4665 - auc: 0.5504 - loss: 0.7562 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6995\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.4496 - auc: 0.4557 - loss: 0.7086 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6916\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5429 - auc: 0.5440 - loss: 0.6888 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6910\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5179 - auc: 0.4528 - loss: 0.6969 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6902\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4471 - auc: 0.4870 - loss: 0.6955 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6889\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5692 - auc: 0.5164 - loss: 0.6934 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6881\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5117 - auc: 0.4923 - loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6871\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4817 - auc: 0.4233 - loss: 0.7028 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6862\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5359 - auc: 0.5569 - loss: 0.6885 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6854\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5382 - auc: 0.4819 - loss: 0.6950 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6846\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4320 - auc: 0.4566 - loss: 0.6997 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6830\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.3682 - auc: 0.4008 - loss: 0.7004 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6816\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.5954 - auc: 0.7487 - loss: 0.6739 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6794\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5541 - auc: 0.5577 - loss: 0.6877 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6771\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5306 - auc: 0.5023 - loss: 0.6911 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6748\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6241 - auc: 0.6187 - loss: 0.6773 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6720\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5347 - auc: 0.5599 - loss: 0.6830 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6692\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.6289 - auc: 0.5784 - loss: 0.6796 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6656\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6235 - auc: 0.6125 - loss: 0.6685 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6616\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5288 - auc: 0.4504 - loss: 0.6871 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.6531\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5339 - auc: 0.5485 - loss: 0.6784 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.6413\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5604 - auc: 0.6371 - loss: 0.6652 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.6294\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7011 - auc: 0.7593 - loss: 0.6444 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.5964\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.6241 - auc: 0.7391 - loss: 0.6429 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.5821\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7228 - auc: 0.8148 - loss: 0.6040 - val_accuracy: 0.8000 - val_auc: 0.8222 - val_loss: 0.5373\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6407 - auc: 0.6880 - loss: 0.6060 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4992\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.6978 - auc: 0.7388 - loss: 0.5772 - val_accuracy: 0.8000 - val_auc: 0.8222 - val_loss: 0.5014\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7249 - auc: 0.7365 - loss: 0.5620 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4469\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7957 - auc: 0.7794 - loss: 0.5144 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4297\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7362 - auc: 0.7284 - loss: 0.5415 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.5107\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.6373 - auc: 0.7350 - loss: 0.5932 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4889\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7064 - auc: 0.7121 - loss: 0.5538 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4146\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6851 - auc: 0.6777 - loss: 0.5814 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4008\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7117 - auc: 0.7098 - loss: 0.5580 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.5071\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 0.6715 - auc: 0.7516 - loss: 0.5847 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4930\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6854 - auc: 0.7863 - loss: 0.5412 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4646\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6492 - auc: 0.7428 - loss: 0.5577 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4216\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7466 - auc: 0.6399 - loss: 0.5415 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3980\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7476 - auc: 0.5848 - loss: 0.5437 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3906\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6755 - loss: 0.5101 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3901\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6879 - loss: 0.5104 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3881\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7979 - loss: 0.4682 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3870\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7032 - loss: 0.5047 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3852\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6769 - loss: 0.4911 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3841\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7902 - loss: 0.4837 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3831\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6844 - loss: 0.4937 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3825\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7557 - loss: 0.4862 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3820\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6851 - loss: 0.4953 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3815\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6733 - loss: 0.5065 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3811\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7520 - loss: 0.4828 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3809\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7398 - auc: 0.6720 - loss: 0.5031 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3813\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6653 - loss: 0.5022 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3805\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8086 - loss: 0.4642 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3803\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7824 - loss: 0.4695 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3799\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6270 - loss: 0.5042 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3796\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6990 - loss: 0.4803 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3794\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7754 - loss: 0.4840 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3793\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7344 - loss: 0.4824 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3791\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7254 - loss: 0.4856 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3790\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6612 - loss: 0.5054 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3788\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7054 - loss: 0.4957 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3786\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8579 - loss: 0.4659 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3785\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6386 - loss: 0.4973 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3786\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7338 - loss: 0.4743 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3786\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7270 - loss: 0.4960 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7445 - loss: 0.4874 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3781\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7702 - loss: 0.4788 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8102 - loss: 0.4783 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7207 - loss: 0.4780 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8601 - loss: 0.4677 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6940 - loss: 0.4845 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7565 - loss: 0.4787 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7666 - loss: 0.4865 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6907 - loss: 0.4839 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3772\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7302 - loss: 0.4931 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3771\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7371 - loss: 0.4823 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3770\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7313 - loss: 0.4890 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7541 - loss: 0.4793 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7318 - loss: 0.4848 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7182 - loss: 0.4930 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7788 - loss: 0.4738 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6617 - loss: 0.5056 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7325 - loss: 0.4851 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7113 - loss: 0.4867 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7512 - loss: 0.4760 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3766\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7111 - loss: 0.4893 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3766\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8949 - loss: 0.4584 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3766\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6885 - loss: 0.4912 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7023 - loss: 0.4861 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7774 - loss: 0.4736 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6678 - loss: 0.5004 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7066 - loss: 0.4845 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7414 - loss: 0.4919 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3766\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7944 - loss: 0.4807 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3766\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7752 - loss: 0.4807 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6791 - loss: 0.4934 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7368 - loss: 0.4798 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7777 - loss: 0.4735 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3770\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8489 - loss: 0.4579 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8232 - loss: 0.4690 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7457 - loss: 0.4771 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7764 - loss: 0.4777 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6747 - loss: 0.4897 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7501 - loss: 0.4850 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6859 - loss: 0.4866 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3769\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7614 - loss: 0.4781 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3771\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7669 - loss: 0.4763 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3772\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7485 - loss: 0.4778 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3771\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8754 - loss: 0.4689 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7781 - loss: 0.4785 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7407 - loss: 0.4832 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3767\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7518 - loss: 0.4834 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3767\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7051 - loss: 0.4870 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7447 - loss: 0.4847 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6855 - loss: 0.4834 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3767\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7343 - loss: 0.4825 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3767\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7162 - loss: 0.4826 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7544 - loss: 0.4772 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6622 - loss: 0.4934 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3764\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6972 - loss: 0.4879 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3762\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7831 - loss: 0.4824 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3761\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7202 - loss: 0.4892 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3763\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8446 - loss: 0.4684 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3764\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6374 - loss: 0.4897 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3766\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7064 - loss: 0.4816 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6711 - loss: 0.4845 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8102 - loss: 0.4744 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7736 - loss: 0.4762 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8071 - loss: 0.4769 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3767\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8072 - loss: 0.4767 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3769\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6979 - loss: 0.4863 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8096 - loss: 0.4676 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3766\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.9318 - loss: 0.4519 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6832 - loss: 0.4872 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3764\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6511 - loss: 0.4870 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3764\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7297 - loss: 0.4777 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3764\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7842 - loss: 0.4769 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6449 - loss: 0.4968 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3766\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7028 - loss: 0.4810 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3766\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7167 - loss: 0.4817 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3766\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7324 - loss: 0.4835 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7071 - loss: 0.4816 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7637 - loss: 0.4801 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3764\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7575 - loss: 0.4788 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3762\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7271 - loss: 0.4790 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3761\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7673 - loss: 0.4810 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7313 - loss: 0.4834 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6937 - loss: 0.4817 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7820 - loss: 0.4762 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3759\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7591 - loss: 0.4798 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3758\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8116 - loss: 0.4767 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7872 - loss: 0.4720 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8090 - loss: 0.4738 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3759\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7330 - loss: 0.4852 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7249 - loss: 0.4819 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3761\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6954 - loss: 0.4856 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3766\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6229 - loss: 0.4938 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3770\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8126 - loss: 0.4777 - val_accuracy: 0.8000 - val_auc: 0.8222 - val_loss: 0.3942\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7362 - auc: 0.7493 - loss: 0.5207 - val_accuracy: 0.7333 - val_auc: 0.6333 - val_loss: 0.5121\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6597 - auc: 0.5627 - loss: 0.6210 - val_accuracy: 0.7333 - val_auc: 0.6333 - val_loss: 0.5537\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6715 - auc: 0.7254 - loss: 0.5965 - val_accuracy: 0.7333 - val_auc: 0.6333 - val_loss: 0.5250\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6715 - auc: 0.6781 - loss: 0.5726 - val_accuracy: 0.7333 - val_auc: 0.6333 - val_loss: 0.5129\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6402 - auc: 0.6610 - loss: 0.5693 - val_accuracy: 0.7333 - val_auc: 0.6333 - val_loss: 0.5050\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7018 - auc: 0.6172 - loss: 0.5683 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4554\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7501 - auc: 0.8103 - loss: 0.5235 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3917\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7398 - auc: 0.7328 - loss: 0.4945 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3990\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7460 - auc: 0.8284 - loss: 0.4966 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3826\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7558 - auc: 0.6944 - loss: 0.5008 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3800\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7791 - loss: 0.4828 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3867\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7558 - auc: 0.7374 - loss: 0.4909 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3865\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7558 - auc: 0.7483 - loss: 0.4929 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3835\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6403 - loss: 0.5020 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3808\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7165 - loss: 0.4858 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3803\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8080 - loss: 0.4818 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3853\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.9060 - loss: 0.4834 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3788\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8501 - loss: 0.4763 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7558 - auc: 0.7197 - loss: 0.4953 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3759\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7709 - loss: 0.4776 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3771\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6818 - loss: 0.4931 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7165 - loss: 0.4832 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3764\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7183 - loss: 0.4830 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3756\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7550 - loss: 0.4807 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3751\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7835 - loss: 0.4767 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3746\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6619 - loss: 0.4877 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3745\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6271 - loss: 0.4925 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3759\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7137 - loss: 0.4853 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3762\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8168 - loss: 0.4763 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3755\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7212 - loss: 0.4830 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3750\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7168 - loss: 0.4823 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3748\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.8460 - loss: 0.4720 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3744\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7364 - loss: 0.4797 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3742\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7570 - loss: 0.4787 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3743\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7031 - loss: 0.4827 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3744\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7398 - auc: 0.6452 - loss: 0.5133 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3850\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7502 - auc: 0.7236 - loss: 0.5066 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3773\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.6987 - loss: 0.4844 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3750\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7442 - loss: 0.4781 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3751\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7547 - loss: 0.4783 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3744\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7058 - loss: 0.4834 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3743\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7443 - loss: 0.4792 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [57:08, 3428.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - accuracy: 0.4364 - auc: 0.3941 - loss: 0.7143 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.4912 - auc: 0.4807 - loss: 0.6946 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6930\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.5692 - auc: 0.5588 - loss: 0.6900 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6924\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5948 - auc: 0.6118 - loss: 0.6868 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6919\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.4946 - auc: 0.4598 - loss: 0.6969 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6912\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.5569 - auc: 0.6863 - loss: 0.6836 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6900\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6803 - auc: 0.6348 - loss: 0.6852 - val_accuracy: 0.5000 - val_auc: 0.7000 - val_loss: 0.6884\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4799 - auc: 0.5523 - loss: 0.6873 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6870\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.6076 - auc: 0.5909 - loss: 0.6869 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6849\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6142 - auc: 0.5868 - loss: 0.6824 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6824\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5229 - auc: 0.5557 - loss: 0.6909 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6794\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.4707 - auc: 0.4840 - loss: 0.6914 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6767\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4393 - auc: 0.5098 - loss: 0.6941 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6735\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5183 - auc: 0.5841 - loss: 0.6811 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6699\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5552 - auc: 0.5958 - loss: 0.6738 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6663\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.4029 - auc: 0.4944 - loss: 0.6860 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6629\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5757 - auc: 0.5465 - loss: 0.6778 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6595\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5710 - auc: 0.6153 - loss: 0.6686 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6539\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5646 - auc: 0.6355 - loss: 0.6615 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6413\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6135 - auc: 0.6931 - loss: 0.6551 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6279\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5618 - auc: 0.6326 - loss: 0.6568 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.6098\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6832 - auc: 0.7964 - loss: 0.6178 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.5580\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7456 - auc: 0.8331 - loss: 0.5645 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5882\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6321 - auc: 0.7141 - loss: 0.6370 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5494\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7018 - auc: 0.8004 - loss: 0.5767 - val_accuracy: 0.7000 - val_auc: 0.7400 - val_loss: 0.5861\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6086 - auc: 0.5653 - loss: 0.7791 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.9867\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5494 - auc: 0.4820 - loss: 0.8521 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.8554\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.5642 - auc: 0.4701 - loss: 0.7407 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7525\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5707 - auc: 0.4820 - loss: 0.7076 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7021\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4669 - auc: 0.4915 - loss: 0.7112 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6929\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5061 - auc: 0.4950 - loss: 0.7075 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6918\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.3859 - auc: 0.4018 - loss: 0.7338 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6913\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5368 - auc: 0.5273 - loss: 0.7178 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6902\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4763 - auc: 0.5395 - loss: 0.6969 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6917\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.3295 - auc: 0.2311 - loss: 0.7371 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6936\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5257 - auc: 0.5082 - loss: 0.6998 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6947\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5622 - auc: 0.5126 - loss: 0.6999 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6926\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4439 - auc: 0.4876 - loss: 0.7028 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6892\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5632 - auc: 0.5903 - loss: 0.6926 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6803\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5272 - auc: 0.5375 - loss: 0.7132 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6789\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.4960 - auc: 0.4772 - loss: 0.7274 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6669\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5758 - auc: 0.5842 - loss: 0.6923 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.6653\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6528 - auc: 0.6343 - loss: 0.6772 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6539\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6605 - auc: 0.6278 - loss: 0.6790 - val_accuracy: 0.6000 - val_auc: 0.8000 - val_loss: 0.6496\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6502 - auc: 0.7632 - loss: 0.6528 - val_accuracy: 0.7000 - val_auc: 0.7867 - val_loss: 0.6270\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7153 - auc: 0.7276 - loss: 0.6444 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6229\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6550 - auc: 0.6678 - loss: 0.6570 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6239\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5958 - auc: 0.7166 - loss: 0.6596 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.5818\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7301 - auc: 0.8882 - loss: 0.6079 - val_accuracy: 0.7000 - val_auc: 0.7867 - val_loss: 0.5819\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6799 - auc: 0.7798 - loss: 0.6112 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.5567\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7441 - auc: 0.7224 - loss: 0.5800 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.5475\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7554 - auc: 0.7895 - loss: 0.5615 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.5286\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7296 - auc: 0.7595 - loss: 0.5752 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.5166\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7287 - auc: 0.7672 - loss: 0.5543 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.5095\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7610 - auc: 0.7782 - loss: 0.5489 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4915\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7513 - auc: 0.7469 - loss: 0.5459 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.4885\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7229 - loss: 0.5242 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4804\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.6984 - loss: 0.5265 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4728\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7287 - auc: 0.7832 - loss: 0.5227 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4816\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7296 - auc: 0.7252 - loss: 0.5376 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4664\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7865 - loss: 0.4939 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.4681\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7400 - auc: 0.7378 - loss: 0.5075 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4727\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7513 - auc: 0.7230 - loss: 0.5271 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4619\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8241 - loss: 0.4942 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.4667\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7441 - auc: 0.7080 - loss: 0.5066 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4492\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8123 - loss: 0.4822 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4556\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7972 - loss: 0.4958 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4456\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8585 - loss: 0.4702 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4441\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8035 - loss: 0.4747 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4459\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8734 - loss: 0.4859 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4413\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7400 - auc: 0.7976 - loss: 0.4797 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4442\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7513 - auc: 0.8114 - loss: 0.4910 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4411\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7289 - loss: 0.4798 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4378\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7511 - loss: 0.4757 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4361\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7513 - auc: 0.7496 - loss: 0.4886 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4405\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7701 - loss: 0.4828 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4351\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7921 - loss: 0.4642 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4359\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7513 - auc: 0.7175 - loss: 0.4715 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4339\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7357 - loss: 0.4711 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4341\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7041 - loss: 0.4717 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4330\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7321 - loss: 0.4702 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4327\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7384 - loss: 0.4750 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4321\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7513 - auc: 0.7420 - loss: 0.4748 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4317\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7577 - loss: 0.4689 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4318\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8102 - loss: 0.4672 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4295\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7554 - auc: 0.7917 - loss: 0.4643 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4294\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7581 - loss: 0.4657 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4311\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8274 - loss: 0.4659 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4284\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7729 - loss: 0.4577 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4290\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.6968 - loss: 0.4650 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4277\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7507 - loss: 0.4555 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4280\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7491 - loss: 0.4627 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4275\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7389 - loss: 0.4592 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4268\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7379 - loss: 0.4581 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4262\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7931 - loss: 0.4556 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4259\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7554 - auc: 0.7354 - loss: 0.4660 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4279\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.6897 - loss: 0.4821 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4266\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7236 - loss: 0.4662 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4282\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7554 - auc: 0.7485 - loss: 0.4625 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4252\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7589 - loss: 0.4637 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4260\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7568 - loss: 0.4571 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4252\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7444 - loss: 0.4582 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4250\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7799 - loss: 0.4528 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4249\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7689 - loss: 0.4553 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4248\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7777 - loss: 0.4528 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4240\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7933 - loss: 0.4516 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4237\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7804 - loss: 0.4534 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4234\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8134 - loss: 0.4505 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4233\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7845 - loss: 0.4520 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4232\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8570 - loss: 0.4468 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4230\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7201 - loss: 0.4586 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4231\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7643 - loss: 0.4552 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4229\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7301 - loss: 0.4599 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4227\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7513 - auc: 0.8021 - loss: 0.4608 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4254\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7149 - loss: 0.4622 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4283\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7162 - loss: 0.4616 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4246\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7427 - loss: 0.4647 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4239\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.6980 - loss: 0.4571 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4237\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8266 - loss: 0.4469 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4211\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8700 - loss: 0.4436 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4205\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8115 - loss: 0.4480 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4199\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7896 - loss: 0.4477 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4199\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8472 - loss: 0.4449 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4204\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7568 - loss: 0.4519 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4203\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8501 - loss: 0.4387 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4196\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7901 - loss: 0.4469 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4193\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8493 - loss: 0.4438 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4195\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7613 - loss: 0.4548 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4191\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8232 - loss: 0.4490 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4184\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.6881 - loss: 0.4609 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8116 - loss: 0.4479 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4182\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8421 - loss: 0.4417 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4180\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8664 - loss: 0.4389 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4171\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7572 - loss: 0.4556 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4169\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8314 - loss: 0.4444 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4172\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7993 - loss: 0.4471 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4171\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7293 - loss: 0.4567 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4170\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7332 - loss: 0.4561 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4172\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7653 - loss: 0.4541 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4169\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7471 - loss: 0.4573 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4170\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8130 - loss: 0.4527 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4160\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7837 - loss: 0.4505 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4155\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7103 - loss: 0.4572 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4169\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7757 - loss: 0.4480 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4178\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8216 - loss: 0.4457 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4167\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8102 - loss: 0.4456 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4164\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7687 - loss: 0.4474 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4173\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8493 - loss: 0.4407 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4163\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7893 - loss: 0.4468 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4167\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7366 - auc: 0.8319 - loss: 0.4645 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4208\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8974 - loss: 0.4476 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4387\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7582 - loss: 0.4912 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4356\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8489 - loss: 0.4697 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4294\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7797 - loss: 0.4609 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4256\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.6987 - loss: 0.4573 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4232\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8688 - loss: 0.4469 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4213\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7847 - loss: 0.4491 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4211\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8359 - loss: 0.4457 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4211\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7041 - loss: 0.4568 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4210\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7624 - loss: 0.4510 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4212\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7386 - loss: 0.4511 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4213\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8194 - loss: 0.4468 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4214\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8135 - loss: 0.4490 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4215\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7582 - loss: 0.4533 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4211\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8192 - loss: 0.4490 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4208\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8240 - loss: 0.4473 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4206\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7477 - loss: 0.4511 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4206\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8330 - loss: 0.4459 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4205\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8455 - loss: 0.4457 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4205\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7895 - loss: 0.4482 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4206\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8305 - loss: 0.4475 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4206\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7678 - loss: 0.4501 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4206\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8066 - loss: 0.4480 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4203\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8143 - loss: 0.4472 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4201\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7352 - loss: 0.4518 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4198\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8073 - loss: 0.4488 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4196\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8991 - loss: 0.4391 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4196\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7554 - auc: 0.6524 - loss: 0.4615 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4214\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8744 - loss: 0.4526 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4206\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8178 - loss: 0.4464 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4197\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7913 - loss: 0.4519 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4196\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7991 - loss: 0.4467 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4198\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8487 - loss: 0.4440 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4204\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8608 - loss: 0.4408 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4199\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7390 - loss: 0.4502 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4192\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8305 - loss: 0.4421 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4191\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8535 - loss: 0.4433 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8626 - loss: 0.4367 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8144 - loss: 0.4391 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4179\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7917 - loss: 0.4508 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4180\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8390 - loss: 0.4395 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4182\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8187 - loss: 0.4436 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4191\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7554 - auc: 0.7561 - loss: 0.4610 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4217\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7513 - auc: 0.7034 - loss: 0.4917 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4234\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8194 - loss: 0.4511 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4211\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7774 - loss: 0.4659 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4190\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8306 - loss: 0.4444 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7228 - loss: 0.4558 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.8205 - loss: 0.4456 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7667 - auc: 0.7222 - loss: 0.4542 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [1:55:23, 3467.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 3s/step - accuracy: 0.5663 - auc: 0.5996 - loss: 0.7358 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7402\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5663 - auc: 0.4750 - loss: 0.6959 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7018\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5790 - auc: 0.5041 - loss: 0.6847 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6935\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4874 - auc: 0.4908 - loss: 0.6938 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6939\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.4475 - auc: 0.6088 - loss: 0.6919 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6945\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4748 - auc: 0.4471 - loss: 0.7006 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6942\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4480 - auc: 0.5453 - loss: 0.6960 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6934\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5135 - auc: 0.6460 - loss: 0.6891 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6925\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.5282 - auc: 0.6275 - loss: 0.6852 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6920\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4441 - auc: 0.5026 - loss: 0.6922 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6916\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5518 - auc: 0.5901 - loss: 0.6865 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6912\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.3267 - auc: 0.3293 - loss: 0.7040 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6908\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.4924 - auc: 0.4721 - loss: 0.6968 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6904\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4793 - auc: 0.5001 - loss: 0.6939 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6896\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.5709 - auc: 0.6780 - loss: 0.6849 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6885\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5091 - auc: 0.5087 - loss: 0.6933 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6876\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.5361 - auc: 0.5358 - loss: 0.6901 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6870\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5498 - auc: 0.5627 - loss: 0.6882 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6865\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5600 - auc: 0.5802 - loss: 0.6908 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6861\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6182 - auc: 0.6845 - loss: 0.6840 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6856\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5757 - auc: 0.6846 - loss: 0.6841 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6848\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5432 - auc: 0.6427 - loss: 0.6823 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6839\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5150 - auc: 0.5449 - loss: 0.6891 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6822\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5685 - auc: 0.6521 - loss: 0.6815 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6805\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6566 - auc: 0.6399 - loss: 0.6812 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6787\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5930 - auc: 0.5951 - loss: 0.6827 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6769\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6210 - auc: 0.4771 - loss: 0.6856 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6749\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5808 - auc: 0.5725 - loss: 0.6799 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6725\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6340 - auc: 0.5162 - loss: 0.6756 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6702\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6625 - auc: 0.6262 - loss: 0.6678 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6677\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5988 - auc: 0.5597 - loss: 0.6776 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6658\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6629 - auc: 0.7288 - loss: 0.6635 - val_accuracy: 0.7333 - val_auc: 0.7333 - val_loss: 0.6634\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6310 - auc: 0.6570 - loss: 0.6682 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6599\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.5889 - auc: 0.5820 - loss: 0.6782 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6552\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.6129 - auc: 0.6551 - loss: 0.6560 - val_accuracy: 0.5000 - val_auc: 0.8111 - val_loss: 0.6569\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5735 - auc: 0.7299 - loss: 0.6638 - val_accuracy: 0.7333 - val_auc: 0.8111 - val_loss: 0.6318\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6553 - auc: 0.6129 - loss: 0.6506 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.5983\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7983 - auc: 0.7773 - loss: 0.6026 - val_accuracy: 0.7667 - val_auc: 0.7889 - val_loss: 0.5918\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7612 - auc: 0.6971 - loss: 0.6052 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.5275\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7542 - loss: 0.5434 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.5210\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7976 - auc: 0.7550 - loss: 0.5467 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4813\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8058 - auc: 0.8073 - loss: 0.5089 - val_accuracy: 0.7667 - val_auc: 0.7889 - val_loss: 0.5413\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7841 - auc: 0.7422 - loss: 0.5316 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4958\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8114 - auc: 0.7953 - loss: 0.4950 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4438\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7674 - auc: 0.6788 - loss: 0.5243 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4334\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7928 - loss: 0.4699 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4265\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8058 - auc: 0.7236 - loss: 0.4742 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4147\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8089 - auc: 0.7682 - loss: 0.4628 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4100\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7453 - loss: 0.4552 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.5145\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7954 - auc: 0.7129 - loss: 0.4680 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4032\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7954 - loss: 0.4527 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3995\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7406 - loss: 0.4486 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3973\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7166 - loss: 0.4492 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3993\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8181 - loss: 0.4422 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3986\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8078 - loss: 0.4311 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3940\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7190 - loss: 0.4407 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3917\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7936 - loss: 0.4340 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3905\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7898 - loss: 0.4314 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3899\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8395 - loss: 0.4240 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3891\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7922 - loss: 0.4362 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3871\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7509 - loss: 0.4323 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3857\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8536 - loss: 0.4249 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3851\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7987 - loss: 0.4273 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3844\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7356 - loss: 0.4287 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3845\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7667 - loss: 0.4334 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3850\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7738 - loss: 0.4345 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3861\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8082 - loss: 0.4281 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3867\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8135 - loss: 0.4270 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3858\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7847 - loss: 0.4348 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3833\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8084 - loss: 0.4270 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3823\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8038 - loss: 0.4202 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3814\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8382 - loss: 0.4136 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3812\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7804 - loss: 0.4255 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3814\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7898 - loss: 0.4264 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3817\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8031 - loss: 0.4291 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3815\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8251 - loss: 0.4235 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3811\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8665 - loss: 0.4154 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3809\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8014 - loss: 0.4270 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3809\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8016 - auc: 0.7560 - loss: 0.4395 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3798\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7815 - loss: 0.4232 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3793\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7939 - loss: 0.4212 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3793\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7948 - loss: 0.4232 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3796\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7421 - loss: 0.4323 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3794\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8058 - auc: 0.8310 - loss: 0.4193 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8295 - loss: 0.4211 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3787\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8315 - loss: 0.4193 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3786\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7583 - loss: 0.4316 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3786\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7603 - loss: 0.4270 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3787\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8016 - loss: 0.4224 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3790\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 3s/step - accuracy: 0.8171 - auc: 0.7022 - loss: 0.4391 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3802\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8058 - auc: 0.7777 - loss: 0.4329 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8114 - auc: 0.7524 - loss: 0.4344 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3785\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8058 - auc: 0.8277 - loss: 0.4217 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7834 - loss: 0.4302 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3835\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7395 - loss: 0.4311 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3820\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8359 - loss: 0.4207 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3856\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7674 - loss: 0.4287 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3820\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7854 - loss: 0.4211 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3803\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8449 - loss: 0.4154 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3795\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8432 - loss: 0.4164 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3797\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8568 - loss: 0.4147 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3794\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8560 - loss: 0.4132 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3791\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7105 - loss: 0.4327 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3789\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7186 - loss: 0.4369 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3784\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8441 - loss: 0.4147 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3773\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7954 - auc: 0.8662 - loss: 0.4282 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7788 - loss: 0.4285 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8257 - loss: 0.4163 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8113 - loss: 0.4206 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3783\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7588 - loss: 0.4289 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8368 - loss: 0.4205 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7076 - loss: 0.4307 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7939 - loss: 0.4212 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7993 - loss: 0.4185 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8307 - loss: 0.4193 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3775\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.6587 - loss: 0.4359 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7506 - loss: 0.4253 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7837 - loss: 0.4259 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7124 - loss: 0.4285 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3771\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8033 - loss: 0.4181 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8407 - loss: 0.4163 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7245 - loss: 0.4276 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7783 - loss: 0.4241 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8441 - loss: 0.4197 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7410 - loss: 0.4292 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.6915 - loss: 0.4305 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7559 - loss: 0.4216 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7002 - loss: 0.4269 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7297 - loss: 0.4272 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8208 - loss: 0.4192 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8861 - loss: 0.4118 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8799 - loss: 0.4123 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7651 - loss: 0.4216 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8317 - loss: 0.4188 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8368 - loss: 0.4179 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3776\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7454 - loss: 0.4241 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8070 - loss: 0.4178 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3783\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8381 - loss: 0.4165 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3786\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7901 - loss: 0.4244 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8106 - loss: 0.4196 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3781\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7940 - loss: 0.4211 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7429 - loss: 0.4253 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3780\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7029 - loss: 0.4320 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3780\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.6897 - loss: 0.4308 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7264 - loss: 0.4265 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.6775 - loss: 0.4322 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7634 - loss: 0.4229 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3773\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8302 - loss: 0.4171 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3772\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8408 - loss: 0.4160 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8041 - loss: 0.4214 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8339 - loss: 0.4197 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3778\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8708 - loss: 0.4142 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8173 - loss: 0.4192 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7297 - loss: 0.4280 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3773\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7401 - loss: 0.4238 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7782 - loss: 0.4241 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3773\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7536 - loss: 0.4231 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3773\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7861 - loss: 0.4224 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7907 - loss: 0.4216 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7716 - loss: 0.4243 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7807 - loss: 0.4228 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8007 - loss: 0.4214 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3767\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7851 - loss: 0.4214 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3766\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7241 - loss: 0.4264 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3768\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8932 - loss: 0.4106 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3771\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7416 - loss: 0.4261 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8046 - loss: 0.4208 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7362 - loss: 0.4231 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8040 - loss: 0.4226 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3771\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.6531 - loss: 0.4310 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3773\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7135 - loss: 0.4278 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8004 - loss: 0.4220 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7319 - loss: 0.4259 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8045 - loss: 0.4213 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7657 - loss: 0.4223 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3771\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8015 - loss: 0.4199 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7359 - loss: 0.4258 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3766\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7349 - loss: 0.4233 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3766\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7730 - loss: 0.4219 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3766\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8529 - loss: 0.4162 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3769\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 3s/step - accuracy: 0.8171 - auc: 0.7763 - loss: 0.4220 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3770\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 5s/step - accuracy: 0.8171 - auc: 0.8073 - loss: 0.4216 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8127 - loss: 0.4175 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3766\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7935 - loss: 0.4201 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8982 - loss: 0.4125 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3770\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7442 - loss: 0.4245 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8712 - loss: 0.4150 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3761\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7450 - loss: 0.4274 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3761\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8102 - loss: 0.4195 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3754\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7914 - loss: 0.4196 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3756\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8480 - loss: 0.4155 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3759\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7447 - loss: 0.4270 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3761\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8333 - loss: 0.4154 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3762\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7447 - loss: 0.4273 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3761\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.8264 - loss: 0.4153 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3762\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7562 - loss: 0.4216 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3763\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7876 - loss: 0.4220 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3764\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7391 - loss: 0.4291 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3762\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7874 - loss: 0.4200 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3760\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8171 - auc: 0.7443 - loss: 0.4235 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [2:56:07, 3548.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.5113 - auc: 0.4787 - loss: 0.8494 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.7555\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5113 - auc: 0.4943 - loss: 0.7430 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.7028\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5113 - auc: 0.4786 - loss: 0.7117 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6918\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.4923 - auc: 0.4317 - loss: 0.7056 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6961\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5171 - auc: 0.4592 - loss: 0.6951 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6983\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5423 - auc: 0.5775 - loss: 0.6881 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6957\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6012 - auc: 0.5488 - loss: 0.6902 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6920\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4762 - auc: 0.5005 - loss: 0.6972 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6888\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5290 - auc: 0.5871 - loss: 0.6897 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6861\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.4695 - auc: 0.5002 - loss: 0.6946 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6842\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.6477 - auc: 0.6688 - loss: 0.6801 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6829\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5893 - auc: 0.6558 - loss: 0.6776 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6809\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5672 - auc: 0.6397 - loss: 0.6807 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6781\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6037 - auc: 0.6441 - loss: 0.6793 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6741\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5779 - auc: 0.6662 - loss: 0.6726 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6701\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6027 - auc: 0.6623 - loss: 0.6736 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6669\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7447 - auc: 0.8042 - loss: 0.6567 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6620\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5798 - auc: 0.5981 - loss: 0.6731 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6601\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6012 - auc: 0.6073 - loss: 0.6566 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6571\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6701 - auc: 0.6915 - loss: 0.6530 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6498\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.6841 - auc: 0.7423 - loss: 0.6445 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6399\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6282 - auc: 0.7160 - loss: 0.6325 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.6156\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6690 - auc: 0.7130 - loss: 0.6223 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.5674\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7993 - auc: 0.7551 - loss: 0.5853 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.5103\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7119 - auc: 0.7654 - loss: 0.6110 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.8336\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5113 - auc: 0.4696 - loss: 0.8006 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.7357\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.5179 - auc: 0.5251 - loss: 0.7105 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6905\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.4400 - auc: 0.5022 - loss: 0.6970 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6945\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.4691 - auc: 0.4831 - loss: 0.7066 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6934\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.4938 - auc: 0.4580 - loss: 0.7091 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6904\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5534 - auc: 0.5245 - loss: 0.6927 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6893\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.4977 - auc: 0.5093 - loss: 0.6938 - val_accuracy: 0.5000 - val_auc: 0.7333 - val_loss: 0.6892\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6168 - auc: 0.6322 - loss: 0.6796 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6887\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5948 - auc: 0.6516 - loss: 0.6837 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6878\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5039 - auc: 0.6032 - loss: 0.6884 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6870\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5504 - auc: 0.6145 - loss: 0.6806 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6863\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5310 - auc: 0.5580 - loss: 0.6923 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6858\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5479 - auc: 0.6208 - loss: 0.6824 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6850\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5480 - auc: 0.6415 - loss: 0.6757 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6835\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.4752 - auc: 0.5038 - loss: 0.6918 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6816\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5035 - auc: 0.5452 - loss: 0.6933 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6800\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6438 - auc: 0.6654 - loss: 0.6756 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6781\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6285 - auc: 0.6722 - loss: 0.6791 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6757\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5306 - auc: 0.5738 - loss: 0.6854 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6743\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5731 - auc: 0.6216 - loss: 0.6778 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6728\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.6748 - auc: 0.6831 - loss: 0.6655 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6700\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7161 - auc: 0.7097 - loss: 0.6641 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6664\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5399 - auc: 0.6083 - loss: 0.6729 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6633\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6805 - auc: 0.7007 - loss: 0.6582 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6580\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5724 - auc: 0.6163 - loss: 0.6708 - val_accuracy: 0.6333 - val_auc: 0.8333 - val_loss: 0.6492\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6188 - auc: 0.5771 - loss: 0.6834 - val_accuracy: 0.6333 - val_auc: 0.7978 - val_loss: 0.6412\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6740 - auc: 0.7298 - loss: 0.6324 - val_accuracy: 0.6333 - val_auc: 0.8333 - val_loss: 0.6313\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5778 - auc: 0.6165 - loss: 0.6479 - val_accuracy: 0.6333 - val_auc: 0.8333 - val_loss: 0.6226\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5987 - auc: 0.5658 - loss: 0.6522 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6229\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6840 - auc: 0.8541 - loss: 0.6049 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6127\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.6997 - auc: 0.7239 - loss: 0.6081 - val_accuracy: 0.7333 - val_auc: 0.8111 - val_loss: 0.5812\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5957 - auc: 0.6747 - loss: 0.6189 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.5820\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7064 - auc: 0.8298 - loss: 0.5773 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.5087\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.7821 - auc: 0.7237 - loss: 0.5397 - val_accuracy: 0.7667 - val_auc: 0.7667 - val_loss: 0.5044\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7696 - auc: 0.7230 - loss: 0.5099 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4503\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7956 - auc: 0.8166 - loss: 0.4909 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4335\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7981 - auc: 0.7911 - loss: 0.4719 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4223\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8415 - loss: 0.4485 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4142\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8394 - loss: 0.4418 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4539\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7216 - loss: 0.4523 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4134\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8664 - loss: 0.4386 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4086\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8829 - loss: 0.4209 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4477\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7229 - loss: 0.4456 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3954\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7737 - loss: 0.4384 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3926\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8093 - loss: 0.4293 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4202\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7899 - auc: 0.8582 - loss: 0.4265 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3992\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.9109 - loss: 0.3987 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3895\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8083 - auc: 0.7901 - loss: 0.4325 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3888\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8192 - auc: 0.7736 - loss: 0.4347 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4617\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8805 - loss: 0.4010 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4774\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7826 - loss: 0.4251 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4050\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8192 - auc: 0.7693 - loss: 0.4179 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3864\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8821 - loss: 0.4134 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3851\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7800 - loss: 0.4177 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3851\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7570 - loss: 0.4311 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3852\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7956 - auc: 0.8336 - loss: 0.4172 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3827\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7869 - loss: 0.4270 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3811\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8321 - loss: 0.4090 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3798\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7821 - auc: 0.8082 - loss: 0.4297 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3796\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7513 - loss: 0.4318 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3809\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8718 - loss: 0.3981 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3814\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.7956 - auc: 0.7745 - loss: 0.4245 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3781\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8314 - loss: 0.4123 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3781\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8343 - loss: 0.4124 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3788\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8205 - loss: 0.4098 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3774\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8262 - loss: 0.4164 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3773\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7696 - auc: 0.7910 - loss: 0.4317 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3781\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8727 - loss: 0.4043 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3779\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7804 - loss: 0.4194 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3764\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7698 - loss: 0.4252 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3766\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8349 - loss: 0.4107 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3765\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7666 - loss: 0.4271 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3760\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8288 - loss: 0.4142 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3757\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8693 - loss: 0.4064 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3778\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8931 - loss: 0.4045 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3760\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8465 - loss: 0.4088 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3759\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7929 - loss: 0.4161 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3759\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8035 - loss: 0.4127 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3787\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8108 - loss: 0.4128 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3937\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8346 - loss: 0.4105 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3863\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8127 - loss: 0.4121 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3748\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8654 - loss: 0.4032 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3739\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8081 - loss: 0.4107 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3740\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7983 - loss: 0.4216 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3750\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7989 - loss: 0.4139 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3764\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8124 - loss: 0.4166 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3721\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8510 - loss: 0.4093 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3727\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8239 - loss: 0.4128 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3723\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8275 - loss: 0.4138 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3717\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8083 - loss: 0.4108 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3724\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8098 - loss: 0.4136 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3737\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8273 - loss: 0.4105 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3737\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.7696 - auc: 0.7510 - loss: 0.4420 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3742\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8551 - loss: 0.4034 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3744\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8093 - loss: 0.4132 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3767\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7464 - loss: 0.4255 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3713\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8497 - loss: 0.4061 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3722\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7469 - loss: 0.4224 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3817\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7967 - loss: 0.4151 - val_accuracy: 0.7667 - val_auc: 0.8556 - val_loss: 0.4754\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7468 - loss: 0.4214 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3759\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8221 - loss: 0.4082 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3703\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7561 - loss: 0.4168 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3714\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8696 - loss: 0.4083 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3699\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7968 - loss: 0.4122 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3702\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7843 - loss: 0.4186 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3713\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8483 - loss: 0.4088 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3709\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8073 - loss: 0.4142 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3709\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7722 - loss: 0.4165 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3705\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8428 - loss: 0.4109 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3697\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8116 - loss: 0.4115 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3695\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7925 - loss: 0.4165 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3698\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8566 - loss: 0.4079 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3694\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7739 - loss: 0.4153 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3684\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7689 - loss: 0.4185 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3678\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8574 - loss: 0.4053 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3678\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8028 - loss: 0.4126 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3675\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8051 - loss: 0.4119 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3672\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8456 - loss: 0.4060 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3670\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8498 - loss: 0.4045 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3667\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8676 - loss: 0.4035 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3661\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8802 - loss: 0.4013 - val_accuracy: 0.8333 - val_auc: 0.9556 - val_loss: 0.3648\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8526 - loss: 0.4072 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3626\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8447 - loss: 0.4065 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3599\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7452 - loss: 0.4343 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3627\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7835 - loss: 0.4216 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3645\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7476 - loss: 0.4214 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3667\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8651 - loss: 0.3990 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3680\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8173 - loss: 0.4129 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3675\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.9160 - loss: 0.3875 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3659\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8514 - loss: 0.4024 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3633\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7752 - loss: 0.4164 - val_accuracy: 0.8333 - val_auc: 0.9556 - val_loss: 0.3602\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7737 - loss: 0.4287 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3558\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8103 - loss: 0.4111 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3499\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8443 - loss: 0.4028 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.3503\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8093 - loss: 0.4065 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3549\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7717 - loss: 0.4281 - val_accuracy: 0.8333 - val_auc: 0.9222 - val_loss: 0.3574\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7817 - loss: 0.4250 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3532\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8259 - loss: 0.4112 - val_accuracy: 0.8333 - val_auc: 0.9556 - val_loss: 0.3500\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8641 - loss: 0.4026 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3457\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8295 - loss: 0.4082 - val_accuracy: 0.8333 - val_auc: 0.9556 - val_loss: 0.3446\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8194 - loss: 0.4032 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3363\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8652 - loss: 0.3977 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3382\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8444 - loss: 0.4037 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3408\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8636 - loss: 0.4041 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3394\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8713 - loss: 0.3933 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3338\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8374 - loss: 0.4057 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3308\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8410 - loss: 0.4061 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3309\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8844 - loss: 0.3862 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3244\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8722 - loss: 0.3894 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3289\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8540 - loss: 0.4026 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3205\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8457 - loss: 0.3968 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3205\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8220 - loss: 0.4068 - val_accuracy: 0.8333 - val_auc: 0.9556 - val_loss: 0.3314\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.7632 - loss: 0.4124 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3352\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8256 - loss: 0.4133 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3388\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8894 - loss: 0.3940 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3403\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8048 - loss: 0.4053 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.3394\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8062 - loss: 0.4054 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3375\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8293 - loss: 0.4013 - val_accuracy: 0.8333 - val_auc: 0.9222 - val_loss: 0.3361\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8902 - loss: 0.3951 - val_accuracy: 0.8333 - val_auc: 0.9556 - val_loss: 0.3357\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8292 - loss: 0.3957 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3331\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8325 - loss: 0.4069 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3249\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8428 - loss: 0.3961 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3225\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8686 - loss: 0.3864 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3177\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8384 - loss: 0.3990 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3172\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8192 - auc: 0.9084 - loss: 0.3690 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3116\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8727 - loss: 0.3827 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3093\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8328 - loss: 0.4038 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3185\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.9407 - loss: 0.3798 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3083\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.7696 - auc: 0.8606 - loss: 0.3953 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3162\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8128 - loss: 0.3968 - val_accuracy: 0.8333 - val_auc: 0.9556 - val_loss: 0.3204\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8644 - loss: 0.3929 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3173\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8696 - loss: 0.3825 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3055\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 11s/step - accuracy: 0.8038 - auc: 0.9699 - loss: 0.3504 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3078\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2s/step - accuracy: 0.8038 - auc: 0.8657 - loss: 0.3747 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3103\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8274 - auc: 0.8962 - loss: 0.3704 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [3:54:06, 3520.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 3s/step - accuracy: 0.3571 - auc: 0.3519 - loss: 0.7283 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6967\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.4421 - auc: 0.4569 - loss: 0.7017 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6936\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6839 - auc: 0.5978 - loss: 0.6786 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6920\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5459 - auc: 0.6024 - loss: 0.6854 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6925\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.4738 - auc: 0.4203 - loss: 0.7186 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6917\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6451 - auc: 0.6211 - loss: 0.6850 - val_accuracy: 0.5000 - val_auc: 0.7000 - val_loss: 0.6903\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5824 - auc: 0.5868 - loss: 0.6826 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6898\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5762 - auc: 0.6232 - loss: 0.6779 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6893\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6846 - auc: 0.6379 - loss: 0.6851 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6879\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6280 - auc: 0.6021 - loss: 0.6834 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6875\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5568 - auc: 0.6016 - loss: 0.6808 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6878\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5660 - auc: 0.5658 - loss: 0.6849 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6860\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6343 - auc: 0.6437 - loss: 0.6734 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6838\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.4958 - auc: 0.5312 - loss: 0.6889 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6820\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.5242 - auc: 0.5319 - loss: 0.6891 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6800\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5835 - auc: 0.6403 - loss: 0.6758 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6769\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.5640 - auc: 0.5819 - loss: 0.6864 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6738\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5347 - auc: 0.5005 - loss: 0.6907 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6712\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5855 - auc: 0.5460 - loss: 0.6880 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6673\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5515 - auc: 0.6369 - loss: 0.6652 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6627\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5576 - auc: 0.5302 - loss: 0.6755 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6581\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5585 - auc: 0.5599 - loss: 0.6686 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6535\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.6078 - auc: 0.5746 - loss: 0.6638 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6492\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5982 - auc: 0.6088 - loss: 0.6543 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6459\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5781 - auc: 0.6724 - loss: 0.6434 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6429\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5567 - auc: 0.5199 - loss: 0.6678 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6417\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.5034 - auc: 0.5220 - loss: 0.6698 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6405\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6102 - auc: 0.5730 - loss: 0.6437 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6385\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5908 - auc: 0.5206 - loss: 0.6537 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6358\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.5651 - auc: 0.6195 - loss: 0.6348 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6312\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.6578 - auc: 0.7016 - loss: 0.6190 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6247\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.5937 - auc: 0.6155 - loss: 0.6317 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6217\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6936 - auc: 0.7137 - loss: 0.6032 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6089\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.6497 - auc: 0.7155 - loss: 0.5949 - val_accuracy: 0.5000 - val_auc: 0.8000 - val_loss: 0.9346\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.5994 - auc: 0.7018 - loss: 0.6465 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6263\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6934 - auc: 0.6980 - loss: 0.6079 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6268\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.6619 - auc: 0.7150 - loss: 0.5990 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6064\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.7151 - auc: 0.7126 - loss: 0.6025 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5859\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.7408 - auc: 0.7872 - loss: 0.5711 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.5539\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8394 - auc: 0.8637 - loss: 0.5201 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.5041\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8034 - auc: 0.8089 - loss: 0.5019 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4697\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8870 - loss: 0.3843 - val_accuracy: 0.6667 - val_auc: 0.7467 - val_loss: 0.6631\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8258 - auc: 0.8781 - loss: 0.4676 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.5213\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8331 - auc: 0.9021 - loss: 0.3942 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4605\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8709 - loss: 0.3819 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4578\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8600 - auc: 0.8837 - loss: 0.3672 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.4967\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2s/step - accuracy: 0.8413 - auc: 0.8382 - loss: 0.3913 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4594\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8302 - loss: 0.3713 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4422\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8413 - auc: 0.8300 - loss: 0.4032 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4400\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8579 - loss: 0.3613 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.4740\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8413 - auc: 0.8781 - loss: 0.3618 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4323\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8865 - loss: 0.3447 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4320\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9075 - loss: 0.3414 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4412\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8872 - loss: 0.3369 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.4577\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8385 - loss: 0.3568 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4420\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9004 - loss: 0.3352 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4407\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8744 - loss: 0.3523 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4299\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9043 - loss: 0.3427 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4283\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8436 - loss: 0.3444 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.4881\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8389 - loss: 0.3517 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4266\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8285 - loss: 0.3511 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4262\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8622 - loss: 0.3492 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4277\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8563 - loss: 0.3387 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4340\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8276 - loss: 0.3474 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4399\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8339 - loss: 0.3517 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4269\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9022 - loss: 0.3322 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4254\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8686 - loss: 0.3438 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4317\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8600 - auc: 0.9107 - loss: 0.3399 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4280\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8583 - loss: 0.3493 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4241\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8305 - loss: 0.3400 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.6041\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8413 - auc: 0.8834 - loss: 0.3983 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4236\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8829 - loss: 0.3381 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4249\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8444 - loss: 0.3449 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4235\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8602 - loss: 0.3456 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4239\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8698 - loss: 0.3401 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4310\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8779 - loss: 0.3447 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4266\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8563 - loss: 0.3462 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4241\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8445 - loss: 0.3481 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4320\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8194 - loss: 0.3462 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4324\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8612 - loss: 0.3427 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4237\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9060 - loss: 0.3289 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4241\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8538 - loss: 0.3400 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4233\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8717 - loss: 0.3292 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4229\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8798 - loss: 0.3375 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4237\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8830 - loss: 0.3372 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4229\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8900 - loss: 0.3386 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4229\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8821 - loss: 0.3358 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4228\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8933 - loss: 0.3304 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4231\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9015 - loss: 0.3290 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4231\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8137 - loss: 0.3394 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4228\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8976 - loss: 0.3300 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4226\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8882 - loss: 0.3333 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4224\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8459 - loss: 0.3392 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4229\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8956 - loss: 0.3288 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4295\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8758 - loss: 0.3363 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4230\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8487 - loss: 0.3411 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4233\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8358 - loss: 0.3449 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4203\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8675 - loss: 0.3340 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.5137\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8628 - loss: 0.3317 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4222\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8620 - loss: 0.3426 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4201\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9000 - loss: 0.3345 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4209\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8613 - loss: 0.3367 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4209\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8564 - loss: 0.3358 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4207\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8591 - auc: 0.8710 - loss: 0.3762 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5223\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8166 - auc: 0.8336 - loss: 0.4006 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4175\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8608 - loss: 0.3459 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.6819\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8258 - auc: 0.8556 - loss: 0.5418 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4187\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8291 - loss: 0.3552 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4255\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8847 - loss: 0.3444 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4255\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8926 - loss: 0.3384 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4219\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8552 - loss: 0.3411 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4248\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8600 - auc: 0.8942 - loss: 0.3396 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4217\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8874 - loss: 0.3380 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4251\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8925 - loss: 0.3348 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4248\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8267 - loss: 0.3401 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4227\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8608 - loss: 0.3327 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4212\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8834 - loss: 0.3273 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4203\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8750 - loss: 0.3329 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4202\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8839 - loss: 0.3382 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4208\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8716 - loss: 0.3325 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4226\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8568 - loss: 0.3414 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4220\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9016 - loss: 0.3296 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4209\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8636 - loss: 0.3407 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4216\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8481 - loss: 0.3367 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4220\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8900 - loss: 0.3282 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4218\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8155 - loss: 0.3344 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4217\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8985 - loss: 0.3270 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4214\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8534 - loss: 0.3352 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4208\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8869 - loss: 0.3294 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4201\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9011 - loss: 0.3288 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4194\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8445 - loss: 0.3322 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4188\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8696 - loss: 0.3336 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4188\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8499 - loss: 0.3443 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4203\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8723 - loss: 0.3374 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4212\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9046 - loss: 0.3289 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4213\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8725 - loss: 0.3343 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4211\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9148 - loss: 0.3234 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4205\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8585 - loss: 0.3354 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4200\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8219 - loss: 0.3394 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4195\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8758 - loss: 0.3328 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4197\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8838 - loss: 0.3318 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4204\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8085 - loss: 0.3397 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4211\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8177 - loss: 0.3434 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4211\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8372 - loss: 0.3415 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4209\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9038 - loss: 0.3299 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4207\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8306 - loss: 0.3385 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4205\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8991 - loss: 0.3283 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4214\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9193 - loss: 0.3227 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4225\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9193 - loss: 0.3303 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4209\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9420 - loss: 0.3215 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4215\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8553 - loss: 0.3336 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4215\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8468 - loss: 0.3399 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4213\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8552 - loss: 0.3401 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4210\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8513 - loss: 0.3420 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4208\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8709 - loss: 0.3344 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4207\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8530 - loss: 0.3362 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4206\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8307 - loss: 0.3404 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4203\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9198 - loss: 0.3233 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4195\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8723 - loss: 0.3347 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4196\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8673 - loss: 0.3359 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4204\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8484 - loss: 0.3395 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4222\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9001 - loss: 0.3286 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4226\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8805 - loss: 0.3332 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4222\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8584 - loss: 0.3361 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4214\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8979 - loss: 0.3312 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4209\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8419 - loss: 0.3360 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4204\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9208 - loss: 0.3267 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4200\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8787 - loss: 0.3330 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4197\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8710 - loss: 0.3351 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4206\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9192 - loss: 0.3311 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4207\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8853 - loss: 0.3335 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4237\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8723 - loss: 0.3419 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4245\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.7927 - loss: 0.3501 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4224\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8560 - loss: 0.3302 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4209\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8773 - loss: 0.3289 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4346\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8936 - loss: 0.3320 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4196\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8831 - loss: 0.3298 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4201\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8758 - loss: 0.3352 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4204\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8786 - loss: 0.3318 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4202\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8288 - loss: 0.3374 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4199\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8310 - loss: 0.3366 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4196\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8451 - loss: 0.3357 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4192\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.7965 - loss: 0.3402 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4188\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8482 - loss: 0.3326 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4195\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8541 - loss: 0.3323 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4230\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8263 - loss: 0.3372 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4179\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8463 - loss: 0.3344 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4179\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9080 - loss: 0.3291 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4177\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8932 - loss: 0.3298 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4186\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.9080 - loss: 0.3287 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4226\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8645 - loss: 0.3304 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4299\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8668 - loss: 0.3302 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4229\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step - accuracy: 0.8754 - auc: 0.8533 - loss: 0.3402 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4197\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8737 - loss: 0.3328 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4214\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8559 - loss: 0.3358 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4216\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8895 - loss: 0.3306 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4209\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8371 - loss: 0.3350 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4199\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.7912 - loss: 0.3388 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4189\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8681 - loss: 0.3339 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4181\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8368 - loss: 0.3350 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [4:44:51, 3418.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8h 7min 19s, sys: 2h 43s, total: 10h 8min 2s\n",
      "Wall time: 4h 44min 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_acc = []\n",
    "all_loss = []\n",
    "all_auc = []\n",
    "\n",
    "all_val_acc = []\n",
    "all_val_loss = []\n",
    "all_val_auc = []\n",
    "\n",
    "for j, seed in tqdm(enumerate(np.arange(NUM_EXPERIMENTS) + INIT_SEED)):\n",
    "    np.random.seed(int(seed))\n",
    "    random.seed(int(seed))\n",
    "    tf.random.set_seed(int(seed))\n",
    "\n",
    "    train_id = np.random.choice(np.unique(np.ravel(data[USER])), 7, replace=False)\n",
    "    train_index = np.isin(data[USER], train_id)\n",
    "\n",
    "    train = data.iloc[train_index]\n",
    "    test = data.iloc[~train_index]\n",
    "\n",
    "    X_train, y_train = reshape_dataset(train)\n",
    "    X_test, y_test = reshape_dataset(test)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = create_model(X_train)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=10,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    auc = history.history['auc']\n",
    "\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_auc = history.history['val_auc']\n",
    "\n",
    "    all_acc.append(acc)\n",
    "    all_loss.append(loss)\n",
    "    all_auc.append(auc)\n",
    "\n",
    "    all_val_acc.append(val_acc)\n",
    "    all_val_loss.append(val_loss)\n",
    "    all_val_auc.append(val_auc)\n",
    "\n",
    "epoch_acc = np.mean(all_acc, axis=0)\n",
    "epoch_loss = np.mean(all_loss, axis=0)\n",
    "epoch_auc = np.mean(all_auc, axis=0)\n",
    "\n",
    "epoch_val_acc = np.mean(all_val_acc, axis=0)\n",
    "epoch_val_loss = np.mean(all_val_loss, axis=0)\n",
    "epoch_val_auc = np.mean(all_val_auc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: TRAIN Accuracy = 0.469 Loss = 0.754 AUC = 0.473\n",
      "Epoch 1: VAL Accuracy = 0.5 Loss = 0.717 AUC = 0.573\n",
      "Epoch 2: TRAIN Accuracy = 0.483 Loss = 0.712 AUC = 0.486\n",
      "Epoch 2: VAL Accuracy = 0.5 Loss = 0.697 AUC = 0.567\n",
      "Epoch 3: TRAIN Accuracy = 0.543 Loss = 0.693 AUC = 0.532\n",
      "Epoch 3: VAL Accuracy = 0.527 Loss = 0.692 AUC = 0.593\n",
      "Epoch 4: TRAIN Accuracy = 0.534 Loss = 0.69 AUC = 0.557\n",
      "Epoch 4: VAL Accuracy = 0.5 Loss = 0.693 AUC = 0.593\n",
      "Epoch 5: TRAIN Accuracy = 0.486 Loss = 0.698 AUC = 0.489\n",
      "Epoch 5: VAL Accuracy = 0.527 Loss = 0.693 AUC = 0.593\n",
      "Epoch 6: TRAIN Accuracy = 0.569 Loss = 0.691 AUC = 0.558\n",
      "Epoch 6: VAL Accuracy = 0.527 Loss = 0.692 AUC = 0.613\n",
      "Epoch 7: TRAIN Accuracy = 0.546 Loss = 0.691 AUC = 0.536\n",
      "Epoch 7: VAL Accuracy = 0.52 Loss = 0.69 AUC = 0.613\n",
      "Epoch 8: TRAIN Accuracy = 0.526 Loss = 0.689 AUC = 0.557\n",
      "Epoch 8: VAL Accuracy = 0.5 Loss = 0.689 AUC = 0.593\n",
      "Epoch 9: TRAIN Accuracy = 0.534 Loss = 0.689 AUC = 0.566\n",
      "Epoch 9: VAL Accuracy = 0.567 Loss = 0.687 AUC = 0.62\n",
      "Epoch 10: TRAIN Accuracy = 0.531 Loss = 0.69 AUC = 0.546\n",
      "Epoch 10: VAL Accuracy = 0.573 Loss = 0.686 AUC = 0.62\n",
      "Epoch 11: TRAIN Accuracy = 0.52 Loss = 0.689 AUC = 0.553\n",
      "Epoch 11: VAL Accuracy = 0.573 Loss = 0.685 AUC = 0.62\n",
      "Epoch 12: TRAIN Accuracy = 0.509 Loss = 0.688 AUC = 0.535\n",
      "Epoch 12: VAL Accuracy = 0.573 Loss = 0.683 AUC = 0.64\n",
      "Epoch 13: TRAIN Accuracy = 0.549 Loss = 0.683 AUC = 0.592\n",
      "Epoch 13: VAL Accuracy = 0.593 Loss = 0.681 AUC = 0.62\n",
      "Epoch 14: TRAIN Accuracy = 0.537 Loss = 0.685 AUC = 0.562\n",
      "Epoch 14: VAL Accuracy = 0.593 Loss = 0.679 AUC = 0.64\n",
      "Epoch 15: TRAIN Accuracy = 0.546 Loss = 0.683 AUC = 0.566\n",
      "Epoch 15: VAL Accuracy = 0.593 Loss = 0.676 AUC = 0.64\n",
      "Epoch 16: TRAIN Accuracy = 0.54 Loss = 0.681 AUC = 0.58\n",
      "Epoch 16: VAL Accuracy = 0.593 Loss = 0.673 AUC = 0.66\n",
      "Epoch 17: TRAIN Accuracy = 0.58 Loss = 0.68 AUC = 0.597\n",
      "Epoch 17: VAL Accuracy = 0.593 Loss = 0.67 AUC = 0.66\n",
      "Epoch 18: TRAIN Accuracy = 0.566 Loss = 0.677 AUC = 0.573\n",
      "Epoch 18: VAL Accuracy = 0.593 Loss = 0.667 AUC = 0.68\n",
      "Epoch 19: TRAIN Accuracy = 0.569 Loss = 0.674 AUC = 0.579\n",
      "Epoch 19: VAL Accuracy = 0.613 Loss = 0.663 AUC = 0.7\n",
      "Epoch 20: TRAIN Accuracy = 0.594 Loss = 0.669 AUC = 0.623\n",
      "Epoch 20: VAL Accuracy = 0.633 Loss = 0.656 AUC = 0.72\n",
      "Epoch 21: TRAIN Accuracy = 0.591 Loss = 0.666 AUC = 0.617\n",
      "Epoch 21: VAL Accuracy = 0.647 Loss = 0.647 AUC = 0.717\n",
      "Epoch 22: TRAIN Accuracy = 0.62 Loss = 0.649 AUC = 0.68\n",
      "Epoch 22: VAL Accuracy = 0.673 Loss = 0.628 AUC = 0.737\n",
      "Epoch 23: TRAIN Accuracy = 0.646 Loss = 0.634 AUC = 0.693\n",
      "Epoch 23: VAL Accuracy = 0.693 Loss = 0.617 AUC = 0.738\n",
      "Epoch 24: TRAIN Accuracy = 0.651 Loss = 0.63 AUC = 0.713\n",
      "Epoch 24: VAL Accuracy = 0.72 Loss = 0.594 AUC = 0.756\n",
      "Epoch 25: TRAIN Accuracy = 0.66 Loss = 0.638 AUC = 0.684\n",
      "Epoch 25: VAL Accuracy = 0.647 Loss = 0.656 AUC = 0.706\n",
      "Epoch 26: TRAIN Accuracy = 0.569 Loss = 0.725 AUC = 0.58\n",
      "Epoch 26: VAL Accuracy = 0.613 Loss = 0.708 AUC = 0.66\n",
      "Epoch 27: TRAIN Accuracy = 0.571 Loss = 0.697 AUC = 0.59\n",
      "Epoch 27: VAL Accuracy = 0.607 Loss = 0.673 AUC = 0.638\n",
      "Epoch 28: TRAIN Accuracy = 0.591 Loss = 0.66 AUC = 0.593\n",
      "Epoch 28: VAL Accuracy = 0.613 Loss = 0.641 AUC = 0.66\n",
      "Epoch 29: TRAIN Accuracy = 0.617 Loss = 0.642 AUC = 0.587\n",
      "Epoch 29: VAL Accuracy = 0.613 Loss = 0.626 AUC = 0.658\n",
      "Epoch 30: TRAIN Accuracy = 0.586 Loss = 0.647 AUC = 0.578\n",
      "Epoch 30: VAL Accuracy = 0.593 Loss = 0.639 AUC = 0.68\n",
      "Epoch 31: TRAIN Accuracy = 0.577 Loss = 0.652 AUC = 0.596\n",
      "Epoch 31: VAL Accuracy = 0.62 Loss = 0.632 AUC = 0.7\n",
      "Epoch 32: TRAIN Accuracy = 0.571 Loss = 0.642 AUC = 0.604\n",
      "Epoch 32: VAL Accuracy = 0.633 Loss = 0.616 AUC = 0.718\n",
      "Epoch 33: TRAIN Accuracy = 0.611 Loss = 0.641 AUC = 0.621\n",
      "Epoch 33: VAL Accuracy = 0.653 Loss = 0.61 AUC = 0.72\n",
      "Epoch 34: TRAIN Accuracy = 0.594 Loss = 0.636 AUC = 0.606\n",
      "Epoch 34: VAL Accuracy = 0.573 Loss = 0.695 AUC = 0.72\n",
      "Epoch 35: TRAIN Accuracy = 0.554 Loss = 0.65 AUC = 0.57\n",
      "Epoch 35: VAL Accuracy = 0.593 Loss = 0.631 AUC = 0.716\n",
      "Epoch 36: TRAIN Accuracy = 0.594 Loss = 0.636 AUC = 0.634\n",
      "Epoch 36: VAL Accuracy = 0.66 Loss = 0.621 AUC = 0.716\n",
      "Epoch 37: TRAIN Accuracy = 0.597 Loss = 0.636 AUC = 0.612\n",
      "Epoch 37: VAL Accuracy = 0.7 Loss = 0.601 AUC = 0.736\n",
      "Epoch 38: TRAIN Accuracy = 0.68 Loss = 0.614 AUC = 0.683\n",
      "Epoch 38: VAL Accuracy = 0.687 Loss = 0.59 AUC = 0.729\n",
      "Epoch 39: TRAIN Accuracy = 0.666 Loss = 0.607 AUC = 0.67\n",
      "Epoch 39: VAL Accuracy = 0.74 Loss = 0.567 AUC = 0.753\n",
      "Epoch 40: TRAIN Accuracy = 0.686 Loss = 0.581 AUC = 0.696\n",
      "Epoch 40: VAL Accuracy = 0.727 Loss = 0.555 AUC = 0.768\n",
      "Epoch 41: TRAIN Accuracy = 0.671 Loss = 0.59 AUC = 0.66\n",
      "Epoch 41: VAL Accuracy = 0.74 Loss = 0.537 AUC = 0.768\n",
      "Epoch 42: TRAIN Accuracy = 0.717 Loss = 0.55 AUC = 0.726\n",
      "Epoch 42: VAL Accuracy = 0.74 Loss = 0.587 AUC = 0.778\n",
      "Epoch 43: TRAIN Accuracy = 0.714 Loss = 0.558 AUC = 0.732\n",
      "Epoch 43: VAL Accuracy = 0.733 Loss = 0.546 AUC = 0.768\n",
      "Epoch 44: TRAIN Accuracy = 0.706 Loss = 0.552 AUC = 0.71\n",
      "Epoch 44: VAL Accuracy = 0.74 Loss = 0.522 AUC = 0.803\n",
      "Epoch 45: TRAIN Accuracy = 0.717 Loss = 0.541 AUC = 0.735\n",
      "Epoch 45: VAL Accuracy = 0.76 Loss = 0.515 AUC = 0.788\n",
      "Epoch 46: TRAIN Accuracy = 0.749 Loss = 0.529 AUC = 0.753\n",
      "Epoch 46: VAL Accuracy = 0.747 Loss = 0.52 AUC = 0.788\n",
      "Epoch 47: TRAIN Accuracy = 0.737 Loss = 0.531 AUC = 0.74\n",
      "Epoch 47: VAL Accuracy = 0.76 Loss = 0.509 AUC = 0.795\n",
      "Epoch 48: TRAIN Accuracy = 0.723 Loss = 0.528 AUC = 0.736\n",
      "Epoch 48: VAL Accuracy = 0.78 Loss = 0.496 AUC = 0.785\n",
      "Epoch 49: TRAIN Accuracy = 0.766 Loss = 0.522 AUC = 0.767\n",
      "Epoch 49: VAL Accuracy = 0.747 Loss = 0.515 AUC = 0.798\n",
      "Epoch 50: TRAIN Accuracy = 0.743 Loss = 0.513 AUC = 0.747\n",
      "Epoch 50: VAL Accuracy = 0.76 Loss = 0.493 AUC = 0.805\n",
      "Epoch 51: TRAIN Accuracy = 0.754 Loss = 0.509 AUC = 0.752\n",
      "Epoch 51: VAL Accuracy = 0.773 Loss = 0.48 AUC = 0.805\n",
      "Epoch 52: TRAIN Accuracy = 0.769 Loss = 0.493 AUC = 0.777\n",
      "Epoch 52: VAL Accuracy = 0.78 Loss = 0.474 AUC = 0.808\n",
      "Epoch 53: TRAIN Accuracy = 0.751 Loss = 0.493 AUC = 0.769\n",
      "Epoch 53: VAL Accuracy = 0.773 Loss = 0.472 AUC = 0.805\n",
      "Epoch 54: TRAIN Accuracy = 0.751 Loss = 0.49 AUC = 0.759\n",
      "Epoch 54: VAL Accuracy = 0.767 Loss = 0.474 AUC = 0.785\n",
      "Epoch 55: TRAIN Accuracy = 0.769 Loss = 0.487 AUC = 0.779\n",
      "Epoch 55: VAL Accuracy = 0.78 Loss = 0.464 AUC = 0.785\n",
      "Epoch 56: TRAIN Accuracy = 0.771 Loss = 0.479 AUC = 0.778\n",
      "Epoch 56: VAL Accuracy = 0.793 Loss = 0.456 AUC = 0.801\n",
      "Epoch 57: TRAIN Accuracy = 0.769 Loss = 0.475 AUC = 0.782\n",
      "Epoch 57: VAL Accuracy = 0.8 Loss = 0.452 AUC = 0.816\n",
      "Epoch 58: TRAIN Accuracy = 0.783 Loss = 0.464 AUC = 0.83\n",
      "Epoch 58: VAL Accuracy = 0.82 Loss = 0.436 AUC = 0.806\n",
      "Epoch 59: TRAIN Accuracy = 0.794 Loss = 0.454 AUC = 0.818\n",
      "Epoch 59: VAL Accuracy = 0.793 Loss = 0.448 AUC = 0.796\n",
      "Epoch 60: TRAIN Accuracy = 0.797 Loss = 0.458 AUC = 0.768\n",
      "Epoch 60: VAL Accuracy = 0.82 Loss = 0.422 AUC = 0.816\n",
      "Epoch 61: TRAIN Accuracy = 0.803 Loss = 0.446 AUC = 0.781\n",
      "Epoch 61: VAL Accuracy = 0.813 Loss = 0.418 AUC = 0.816\n",
      "Epoch 62: TRAIN Accuracy = 0.797 Loss = 0.443 AUC = 0.798\n",
      "Epoch 62: VAL Accuracy = 0.82 Loss = 0.417 AUC = 0.803\n",
      "Epoch 63: TRAIN Accuracy = 0.803 Loss = 0.44 AUC = 0.792\n",
      "Epoch 63: VAL Accuracy = 0.82 Loss = 0.415 AUC = 0.808\n",
      "Epoch 64: TRAIN Accuracy = 0.806 Loss = 0.432 AUC = 0.795\n",
      "Epoch 64: VAL Accuracy = 0.8 Loss = 0.425 AUC = 0.801\n",
      "Epoch 65: TRAIN Accuracy = 0.8 Loss = 0.441 AUC = 0.777\n",
      "Epoch 65: VAL Accuracy = 0.82 Loss = 0.411 AUC = 0.814\n",
      "Epoch 66: TRAIN Accuracy = 0.806 Loss = 0.433 AUC = 0.794\n",
      "Epoch 66: VAL Accuracy = 0.82 Loss = 0.411 AUC = 0.812\n",
      "Epoch 67: TRAIN Accuracy = 0.806 Loss = 0.427 AUC = 0.816\n",
      "Epoch 67: VAL Accuracy = 0.807 Loss = 0.418 AUC = 0.803\n",
      "Epoch 68: TRAIN Accuracy = 0.803 Loss = 0.426 AUC = 0.814\n",
      "Epoch 68: VAL Accuracy = 0.82 Loss = 0.406 AUC = 0.814\n",
      "Epoch 69: TRAIN Accuracy = 0.806 Loss = 0.43 AUC = 0.799\n",
      "Epoch 69: VAL Accuracy = 0.82 Loss = 0.405 AUC = 0.814\n",
      "Epoch 70: TRAIN Accuracy = 0.806 Loss = 0.426 AUC = 0.812\n",
      "Epoch 70: VAL Accuracy = 0.793 Loss = 0.445 AUC = 0.803\n",
      "Epoch 71: TRAIN Accuracy = 0.791 Loss = 0.432 AUC = 0.798\n",
      "Epoch 71: VAL Accuracy = 0.82 Loss = 0.405 AUC = 0.818\n",
      "Epoch 72: TRAIN Accuracy = 0.803 Loss = 0.422 AUC = 0.827\n",
      "Epoch 72: VAL Accuracy = 0.82 Loss = 0.403 AUC = 0.818\n",
      "Epoch 73: TRAIN Accuracy = 0.806 Loss = 0.428 AUC = 0.787\n",
      "Epoch 73: VAL Accuracy = 0.82 Loss = 0.402 AUC = 0.824\n",
      "Epoch 74: TRAIN Accuracy = 0.809 Loss = 0.427 AUC = 0.789\n",
      "Epoch 74: VAL Accuracy = 0.807 Loss = 0.416 AUC = 0.823\n",
      "Epoch 75: TRAIN Accuracy = 0.803 Loss = 0.425 AUC = 0.809\n",
      "Epoch 75: VAL Accuracy = 0.807 Loss = 0.422 AUC = 0.808\n",
      "Epoch 76: TRAIN Accuracy = 0.806 Loss = 0.423 AUC = 0.805\n",
      "Epoch 76: VAL Accuracy = 0.82 Loss = 0.405 AUC = 0.816\n",
      "Epoch 77: TRAIN Accuracy = 0.809 Loss = 0.42 AUC = 0.808\n",
      "Epoch 77: VAL Accuracy = 0.82 Loss = 0.401 AUC = 0.818\n",
      "Epoch 78: TRAIN Accuracy = 0.803 Loss = 0.422 AUC = 0.806\n",
      "Epoch 78: VAL Accuracy = 0.82 Loss = 0.402 AUC = 0.803\n",
      "Epoch 79: TRAIN Accuracy = 0.803 Loss = 0.426 AUC = 0.765\n",
      "Epoch 79: VAL Accuracy = 0.82 Loss = 0.402 AUC = 0.808\n",
      "Epoch 80: TRAIN Accuracy = 0.806 Loss = 0.425 AUC = 0.775\n",
      "Epoch 80: VAL Accuracy = 0.82 Loss = 0.4 AUC = 0.814\n",
      "Epoch 81: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.808\n",
      "Epoch 81: VAL Accuracy = 0.82 Loss = 0.399 AUC = 0.814\n",
      "Epoch 82: TRAIN Accuracy = 0.806 Loss = 0.424 AUC = 0.791\n",
      "Epoch 82: VAL Accuracy = 0.82 Loss = 0.399 AUC = 0.827\n",
      "Epoch 83: TRAIN Accuracy = 0.803 Loss = 0.419 AUC = 0.798\n",
      "Epoch 83: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.823\n",
      "Epoch 84: TRAIN Accuracy = 0.8 Loss = 0.419 AUC = 0.814\n",
      "Epoch 84: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.827\n",
      "Epoch 85: TRAIN Accuracy = 0.806 Loss = 0.421 AUC = 0.804\n",
      "Epoch 85: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.827\n",
      "Epoch 86: TRAIN Accuracy = 0.803 Loss = 0.416 AUC = 0.825\n",
      "Epoch 86: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.818\n",
      "Epoch 87: TRAIN Accuracy = 0.803 Loss = 0.42 AUC = 0.811\n",
      "Epoch 87: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.827\n",
      "Epoch 88: TRAIN Accuracy = 0.806 Loss = 0.42 AUC = 0.796\n",
      "Epoch 88: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.827\n",
      "Epoch 89: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.813\n",
      "Epoch 89: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.827\n",
      "Epoch 90: TRAIN Accuracy = 0.806 Loss = 0.423 AUC = 0.758\n",
      "Epoch 90: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.823\n",
      "Epoch 91: TRAIN Accuracy = 0.803 Loss = 0.422 AUC = 0.783\n",
      "Epoch 91: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.827\n",
      "Epoch 92: TRAIN Accuracy = 0.8 Loss = 0.425 AUC = 0.789\n",
      "Epoch 92: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.823\n",
      "Epoch 93: TRAIN Accuracy = 0.803 Loss = 0.419 AUC = 0.799\n",
      "Epoch 93: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.827\n",
      "Epoch 94: TRAIN Accuracy = 0.806 Loss = 0.424 AUC = 0.787\n",
      "Epoch 94: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.816\n",
      "Epoch 95: TRAIN Accuracy = 0.806 Loss = 0.422 AUC = 0.781\n",
      "Epoch 95: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.834\n",
      "Epoch 96: TRAIN Accuracy = 0.803 Loss = 0.42 AUC = 0.789\n",
      "Epoch 96: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.82\n",
      "Epoch 97: TRAIN Accuracy = 0.806 Loss = 0.424 AUC = 0.767\n",
      "Epoch 97: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.825\n",
      "Epoch 98: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.789\n",
      "Epoch 98: VAL Accuracy = 0.807 Loss = 0.415 AUC = 0.814\n",
      "Epoch 99: TRAIN Accuracy = 0.803 Loss = 0.413 AUC = 0.818\n",
      "Epoch 99: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.823\n",
      "Epoch 100: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.827\n",
      "Epoch 100: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.828\n",
      "Epoch 101: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.811\n",
      "Epoch 101: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.823\n",
      "Epoch 102: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.811\n",
      "Epoch 102: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.823\n",
      "Epoch 103: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.791\n",
      "Epoch 103: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.823\n",
      "Epoch 104: TRAIN Accuracy = 0.8 Loss = 0.428 AUC = 0.796\n",
      "Epoch 104: VAL Accuracy = 0.8 Loss = 0.419 AUC = 0.808\n",
      "Epoch 105: TRAIN Accuracy = 0.797 Loss = 0.424 AUC = 0.809\n",
      "Epoch 105: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.816\n",
      "Epoch 106: TRAIN Accuracy = 0.803 Loss = 0.419 AUC = 0.801\n",
      "Epoch 106: VAL Accuracy = 0.807 Loss = 0.447 AUC = 0.822\n",
      "Epoch 107: TRAIN Accuracy = 0.8 Loss = 0.438 AUC = 0.793\n",
      "Epoch 107: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.835\n",
      "Epoch 108: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.805\n",
      "Epoch 108: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.832\n",
      "Epoch 109: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.814\n",
      "Epoch 109: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.83\n",
      "Epoch 110: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.828\n",
      "Epoch 110: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.835\n",
      "Epoch 111: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.796\n",
      "Epoch 111: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.824\n",
      "Epoch 112: TRAIN Accuracy = 0.803 Loss = 0.417 AUC = 0.808\n",
      "Epoch 112: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.835\n",
      "Epoch 113: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.804\n",
      "Epoch 113: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.835\n",
      "Epoch 114: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.808\n",
      "Epoch 114: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.832\n",
      "Epoch 115: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.789\n",
      "Epoch 115: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.839\n",
      "Epoch 116: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.776\n",
      "Epoch 116: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.835\n",
      "Epoch 117: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.807\n",
      "Epoch 117: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.827\n",
      "Epoch 118: TRAIN Accuracy = 0.803 Loss = 0.421 AUC = 0.779\n",
      "Epoch 118: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.827\n",
      "Epoch 119: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.802\n",
      "Epoch 119: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.832\n",
      "Epoch 120: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.824\n",
      "Epoch 120: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.829\n",
      "Epoch 121: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.801\n",
      "Epoch 121: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.832\n",
      "Epoch 122: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.796\n",
      "Epoch 122: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.835\n",
      "Epoch 123: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.793\n",
      "Epoch 123: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.824\n",
      "Epoch 124: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.805\n",
      "Epoch 124: VAL Accuracy = 0.807 Loss = 0.414 AUC = 0.835\n",
      "Epoch 125: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.795\n",
      "Epoch 125: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.835\n",
      "Epoch 126: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.771\n",
      "Epoch 126: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.835\n",
      "Epoch 127: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.814\n",
      "Epoch 127: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.835\n",
      "Epoch 128: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.808\n",
      "Epoch 128: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.84\n",
      "Epoch 129: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.804\n",
      "Epoch 129: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.84\n",
      "Epoch 130: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.81\n",
      "Epoch 130: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.835\n",
      "Epoch 131: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.811\n",
      "Epoch 131: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.849\n",
      "Epoch 132: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.836\n",
      "Epoch 132: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.84\n",
      "Epoch 133: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.828\n",
      "Epoch 133: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.835\n",
      "Epoch 134: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.806\n",
      "Epoch 134: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.84\n",
      "Epoch 135: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.819\n",
      "Epoch 135: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.83\n",
      "Epoch 136: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.808\n",
      "Epoch 136: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.84\n",
      "Epoch 137: TRAIN Accuracy = 0.806 Loss = 0.409 AUC = 0.832\n",
      "Epoch 137: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.849\n",
      "Epoch 138: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.776\n",
      "Epoch 138: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.844\n",
      "Epoch 139: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.79\n",
      "Epoch 139: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.849\n",
      "Epoch 140: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.802\n",
      "Epoch 140: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.844\n",
      "Epoch 141: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.804\n",
      "Epoch 141: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.849\n",
      "Epoch 142: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.779\n",
      "Epoch 142: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.853\n",
      "Epoch 143: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.793\n",
      "Epoch 143: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.853\n",
      "Epoch 144: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.809\n",
      "Epoch 144: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.849\n",
      "Epoch 145: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.823\n",
      "Epoch 145: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.849\n",
      "Epoch 146: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.804\n",
      "Epoch 146: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.855\n",
      "Epoch 147: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.824\n",
      "Epoch 147: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.853\n",
      "Epoch 148: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.826\n",
      "Epoch 148: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.849\n",
      "Epoch 149: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.808\n",
      "Epoch 149: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.849\n",
      "Epoch 150: TRAIN Accuracy = 0.794 Loss = 0.421 AUC = 0.823\n",
      "Epoch 150: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.844\n",
      "Epoch 151: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.835\n",
      "Epoch 151: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.848\n",
      "Epoch 152: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.828\n",
      "Epoch 152: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.844\n",
      "Epoch 153: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.814\n",
      "Epoch 153: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.844\n",
      "Epoch 154: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.816\n",
      "Epoch 154: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.843\n",
      "Epoch 155: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.806\n",
      "Epoch 155: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.838\n",
      "Epoch 156: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.781\n",
      "Epoch 156: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.859\n",
      "Epoch 157: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.806\n",
      "Epoch 157: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.848\n",
      "Epoch 158: TRAIN Accuracy = 0.806 Loss = 0.406 AUC = 0.847\n",
      "Epoch 158: VAL Accuracy = 0.813 Loss = 0.392 AUC = 0.849\n",
      "Epoch 159: TRAIN Accuracy = 0.8 Loss = 0.425 AUC = 0.778\n",
      "Epoch 159: VAL Accuracy = 0.8 Loss = 0.416 AUC = 0.807\n",
      "Epoch 160: TRAIN Accuracy = 0.78 Loss = 0.45 AUC = 0.756\n",
      "Epoch 160: VAL Accuracy = 0.8 Loss = 0.425 AUC = 0.806\n",
      "Epoch 161: TRAIN Accuracy = 0.786 Loss = 0.445 AUC = 0.778\n",
      "Epoch 161: VAL Accuracy = 0.8 Loss = 0.421 AUC = 0.806\n",
      "Epoch 162: TRAIN Accuracy = 0.786 Loss = 0.436 AUC = 0.804\n",
      "Epoch 162: VAL Accuracy = 0.8 Loss = 0.417 AUC = 0.8\n",
      "Epoch 163: TRAIN Accuracy = 0.786 Loss = 0.432 AUC = 0.793\n",
      "Epoch 163: VAL Accuracy = 0.8 Loss = 0.415 AUC = 0.812\n",
      "Epoch 164: TRAIN Accuracy = 0.794 Loss = 0.429 AUC = 0.797\n",
      "Epoch 164: VAL Accuracy = 0.82 Loss = 0.404 AUC = 0.846\n",
      "Epoch 165: TRAIN Accuracy = 0.8 Loss = 0.427 AUC = 0.831\n",
      "Epoch 165: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.859\n",
      "Epoch 166: TRAIN Accuracy = 0.803 Loss = 0.416 AUC = 0.801\n",
      "Epoch 166: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.858\n",
      "Epoch 167: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.823\n",
      "Epoch 167: VAL Accuracy = 0.82 Loss = 0.388 AUC = 0.853\n",
      "Epoch 168: TRAIN Accuracy = 0.803 Loss = 0.416 AUC = 0.807\n",
      "Epoch 168: VAL Accuracy = 0.82 Loss = 0.388 AUC = 0.851\n",
      "Epoch 169: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.826\n",
      "Epoch 169: VAL Accuracy = 0.82 Loss = 0.389 AUC = 0.855\n",
      "Epoch 170: TRAIN Accuracy = 0.803 Loss = 0.411 AUC = 0.815\n",
      "Epoch 170: VAL Accuracy = 0.82 Loss = 0.388 AUC = 0.856\n",
      "Epoch 171: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.817\n",
      "Epoch 171: VAL Accuracy = 0.82 Loss = 0.387 AUC = 0.858\n",
      "Epoch 172: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.808\n",
      "Epoch 172: VAL Accuracy = 0.82 Loss = 0.387 AUC = 0.852\n",
      "Epoch 173: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.803\n",
      "Epoch 173: VAL Accuracy = 0.82 Loss = 0.385 AUC = 0.853\n",
      "Epoch 174: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.824\n",
      "Epoch 174: VAL Accuracy = 0.82 Loss = 0.386 AUC = 0.853\n",
      "Epoch 175: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.814\n",
      "Epoch 175: VAL Accuracy = 0.82 Loss = 0.386 AUC = 0.847\n",
      "Epoch 176: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.813\n",
      "Epoch 176: VAL Accuracy = 0.82 Loss = 0.383 AUC = 0.853\n",
      "Epoch 177: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.817\n",
      "Epoch 177: VAL Accuracy = 0.82 Loss = 0.385 AUC = 0.859\n",
      "Epoch 178: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.776\n",
      "Epoch 178: VAL Accuracy = 0.82 Loss = 0.386 AUC = 0.848\n",
      "Epoch 179: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.811\n",
      "Epoch 179: VAL Accuracy = 0.82 Loss = 0.387 AUC = 0.848\n",
      "Epoch 180: TRAIN Accuracy = 0.806 Loss = 0.409 AUC = 0.822\n",
      "Epoch 180: VAL Accuracy = 0.82 Loss = 0.387 AUC = 0.848\n",
      "Epoch 181: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.816\n",
      "Epoch 181: VAL Accuracy = 0.82 Loss = 0.386 AUC = 0.853\n",
      "Epoch 182: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.799\n",
      "Epoch 182: VAL Accuracy = 0.82 Loss = 0.386 AUC = 0.844\n",
      "Epoch 183: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.825\n",
      "Epoch 183: VAL Accuracy = 0.82 Loss = 0.385 AUC = 0.852\n",
      "Epoch 184: TRAIN Accuracy = 0.806 Loss = 0.409 AUC = 0.82\n",
      "Epoch 184: VAL Accuracy = 0.82 Loss = 0.385 AUC = 0.86\n",
      "Epoch 185: TRAIN Accuracy = 0.806 Loss = 0.406 AUC = 0.829\n",
      "Epoch 185: VAL Accuracy = 0.82 Loss = 0.386 AUC = 0.852\n",
      "Epoch 186: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.811\n",
      "Epoch 186: VAL Accuracy = 0.82 Loss = 0.383 AUC = 0.853\n",
      "Epoch 187: TRAIN Accuracy = 0.806 Loss = 0.407 AUC = 0.842\n",
      "Epoch 187: VAL Accuracy = 0.82 Loss = 0.382 AUC = 0.858\n",
      "Epoch 188: TRAIN Accuracy = 0.806 Loss = 0.405 AUC = 0.827\n",
      "Epoch 188: VAL Accuracy = 0.82 Loss = 0.381 AUC = 0.858\n",
      "Epoch 189: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.817\n",
      "Epoch 189: VAL Accuracy = 0.82 Loss = 0.381 AUC = 0.858\n",
      "Epoch 190: TRAIN Accuracy = 0.809 Loss = 0.402 AUC = 0.842\n",
      "Epoch 190: VAL Accuracy = 0.82 Loss = 0.38 AUC = 0.847\n",
      "Epoch 191: TRAIN Accuracy = 0.806 Loss = 0.403 AUC = 0.841\n",
      "Epoch 191: VAL Accuracy = 0.82 Loss = 0.382 AUC = 0.847\n",
      "Epoch 192: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.82\n",
      "Epoch 192: VAL Accuracy = 0.82 Loss = 0.382 AUC = 0.852\n",
      "Epoch 193: TRAIN Accuracy = 0.803 Loss = 0.408 AUC = 0.824\n",
      "Epoch 193: VAL Accuracy = 0.82 Loss = 0.38 AUC = 0.851\n",
      "Epoch 194: TRAIN Accuracy = 0.797 Loss = 0.419 AUC = 0.789\n",
      "Epoch 194: VAL Accuracy = 0.82 Loss = 0.384 AUC = 0.858\n",
      "Epoch 195: TRAIN Accuracy = 0.803 Loss = 0.413 AUC = 0.816\n",
      "Epoch 195: VAL Accuracy = 0.82 Loss = 0.383 AUC = 0.859\n",
      "Epoch 196: TRAIN Accuracy = 0.806 Loss = 0.407 AUC = 0.824\n",
      "Epoch 196: VAL Accuracy = 0.82 Loss = 0.382 AUC = 0.858\n",
      "Epoch 197: TRAIN Accuracy = 0.806 Loss = 0.405 AUC = 0.817\n",
      "Epoch 197: VAL Accuracy = 0.82 Loss = 0.379 AUC = 0.858\n",
      "Epoch 198: TRAIN Accuracy = 0.806 Loss = 0.403 AUC = 0.809\n",
      "Epoch 198: VAL Accuracy = 0.82 Loss = 0.379 AUC = 0.858\n",
      "Epoch 199: TRAIN Accuracy = 0.806 Loss = 0.403 AUC = 0.817\n",
      "Epoch 199: VAL Accuracy = 0.82 Loss = 0.379 AUC = 0.858\n",
      "Epoch 200: TRAIN Accuracy = 0.811 Loss = 0.403 AUC = 0.816\n",
      "Epoch 200: VAL Accuracy = 0.82 Loss = 0.377 AUC = 0.858\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {(i + 1)}: TRAIN Accuracy = {np.round(epoch_acc[i], 3)} Loss = {np.round(epoch_loss[i], 3)} AUC = {np.round(epoch_auc[i], 3)}\")\n",
    "    print(f\"Epoch {(i + 1)}: VAL Accuracy = {np.round(epoch_val_acc[i], 3)} Loss = {np.round(epoch_val_loss[i], 3)} AUC = {np.round(epoch_val_auc[i], 3)}\")\n",
    "\n",
    "with open(\"./logs/Liquidv3_emb2.txt\", \"w\") as f:\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        f.write(f\"Epoch {(i + 1)}: TRAIN Accuracy = {np.round(epoch_acc[i], 3)} Loss = {np.round(epoch_loss[i], 3)} AUC = {np.round(epoch_auc[i], 3)}\\n\")\n",
    "        f.write(f\"Epoch {(i + 1)}: VAL Accuracy = {np.round(epoch_val_acc[i], 3)} Loss = {np.round(epoch_val_loss[i], 3)} AUC = {np.round(epoch_val_auc[i], 3)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-signals-_5HxkjSc-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
