{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GRU, Input, BatchNormalization, Dropout\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.keras import LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "NUM_EXPERIMENTS = 5\n",
    "\n",
    "def create_model(train):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train.shape[1], train.shape[2])))\n",
    "\n",
    "    model.add(LTC(40, return_sequences=True))\n",
    "    model.add(LTC(30, return_sequences=True))\n",
    "    model.add(LTC(20, return_sequences=False))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.002, weight_decay=1e-7, use_ema=True), loss='binary_crossentropy', metrics=[\"accuracy\", AUC(name=\"auc\")])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = [\"ID\"]\n",
    "USER = [\"SubjectID\"]\n",
    "IDS = [\"SubjectID\", \"VideoID\"]\n",
    "TARGET = [\"predefinedlabel\"]\n",
    "FEATURES = [\"Delta\", \"Theta\", \"Alpha1\", \"Alpha2\", \"Beta1\", \"Beta2\", \"Gamma1\", \"Gamma2\"]\n",
    "LAGS = []\n",
    "USE_DIFF = True\n",
    "INIT_SEED = 5412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>Gamma2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-228176.0</td>\n",
       "      <td>-62529.0</td>\n",
       "      <td>-32296.0</td>\n",
       "      <td>-21751.0</td>\n",
       "      <td>-25200.0</td>\n",
       "      <td>-41410.0</td>\n",
       "      <td>-27935.0</td>\n",
       "      <td>-5553.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>684566.0</td>\n",
       "      <td>355662.0</td>\n",
       "      <td>200560.0</td>\n",
       "      <td>59867.0</td>\n",
       "      <td>33547.0</td>\n",
       "      <td>126849.0</td>\n",
       "      <td>51950.0</td>\n",
       "      <td>22614.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SubjectID     Delta     Theta    Alpha1   Alpha2    Beta1     Beta2  \\\n",
       "0   0        0.0  301963.0   90612.0   33735.0  23991.0  27946.0   45097.0   \n",
       "1   0        0.0 -228176.0  -62529.0  -32296.0 -21751.0 -25200.0  -41410.0   \n",
       "2   0        0.0  684566.0  355662.0  200560.0  59867.0  33547.0  126849.0   \n",
       "\n",
       "    Gamma1   Gamma2  predefinedlabel  \n",
       "0  33228.0   8293.0              0.0  \n",
       "1 -27935.0  -5553.0              0.0  \n",
       "2  51950.0  22614.0              0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"/home/aseliverstov/projects/brain_signals/data\")\n",
    "data = pd.read_csv(data_dir / \"EEG_data.csv\")\n",
    "\n",
    "new_features = []\n",
    "for lag in LAGS:\n",
    "    for feature_name in FEATURES:\n",
    "        new_feature_name = f\"{feature_name}_{lag}\"\n",
    "        new_features.append(new_feature_name)\n",
    "        data[new_feature_name] = data.groupby(IDS)[feature_name].shift(lag).fillna(0)\n",
    "FEATURES.extend(new_features)\n",
    "\n",
    "if USE_DIFF:\n",
    "    for feature_name in FEATURES:\n",
    "        data[feature_name] = data[feature_name] - data.groupby(IDS)[feature_name].shift(1).fillna(0)\n",
    "\n",
    "data[\"ID\"] = (len(np.unique(data[\"VideoID\"])) * data[\"SubjectID\"] + data[\"VideoID\"]).astype(\"int\")\n",
    "data = data[ID + USER + FEATURES + TARGET]\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(data):\n",
    "    features = []\n",
    "    target = []\n",
    "    for cur_id in np.unique(data[ID].to_numpy()):\n",
    "        cur_id_data = data[data[ID].to_numpy() == cur_id]\n",
    "        target.append(np.mean(cur_id_data[TARGET].to_numpy()).astype(\"int\"))\n",
    "        features.append(cur_id_data[FEATURES].to_numpy())\n",
    "\n",
    "    features = pad_sequences(features)\n",
    "    return np.array(features), np.array(target)\n",
    "\n",
    "def pad_sequences(arrays, pad_value=0):\n",
    "    max_length = max(arr.shape[0] for arr in arrays)\n",
    "    padded_arrays = [\n",
    "        np.pad(\n",
    "            arr,\n",
    "            ((0, max_length - arr.shape[0]), (0, 0)),\n",
    "            mode='constant',\n",
    "            constant_values=pad_value)\n",
    "            for arr in arrays\n",
    "        ]\n",
    "    return np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ltc_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,630</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ ltc_24 (\u001b[38;5;33mLTC\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │         \u001b[38;5;34m7,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_25 (\u001b[38;5;33mLTC\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │         \u001b[38;5;34m8,630\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_26 (\u001b[38;5;33mLTC\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,707</span> (80.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,707\u001b[0m (80.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,707</span> (80.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,707\u001b[0m (80.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, _ = reshape_dataset(data)\n",
    "model = create_model(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2s/step - accuracy: 0.4665 - auc: 0.4582 - loss: 0.7548 - val_accuracy: 0.5000 - val_auc: 0.4000 - val_loss: 0.6941\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4468 - auc: 0.4848 - loss: 0.6960 - val_accuracy: 0.5000 - val_auc: 0.4667 - val_loss: 0.6963\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5335 - auc: 0.5370 - loss: 0.6910 - val_accuracy: 0.5000 - val_auc: 0.5667 - val_loss: 0.6951\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5335 - auc: 0.5492 - loss: 0.6901 - val_accuracy: 0.5000 - val_auc: 0.5667 - val_loss: 0.6927\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5518 - auc: 0.5432 - loss: 0.6916 - val_accuracy: 0.5000 - val_auc: 0.5667 - val_loss: 0.6922\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4665 - auc: 0.5384 - loss: 0.6936 - val_accuracy: 0.5000 - val_auc: 0.5667 - val_loss: 0.6918\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4665 - auc: 0.5568 - loss: 0.6936 - val_accuracy: 0.5000 - val_auc: 0.5667 - val_loss: 0.6910\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4786 - auc: 0.5488 - loss: 0.6921 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6901\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5334 - loss: 0.6904 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6891\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5466 - loss: 0.6890 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6875\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5703 - loss: 0.6876 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6853\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5703 - loss: 0.6857 - val_accuracy: 0.6000 - val_auc: 0.6333 - val_loss: 0.6821\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5598 - loss: 0.6826 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6773\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5797 - loss: 0.6780 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6700\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5998 - loss: 0.6717 - val_accuracy: 0.6667 - val_auc: 0.7333 - val_loss: 0.6557\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.6714 - auc: 0.6281 - loss: 0.6576 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.5984\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.6367 - auc: 0.6512 - loss: 0.6487 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6379\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.6285 - loss: 0.6467 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6242\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6715 - auc: 0.6297 - loss: 0.6388 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.5927\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7487 - auc: 0.6927 - loss: 0.6319 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.9655\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4665 - auc: 0.5055 - loss: 0.9727 - val_accuracy: 0.5000 - val_auc: 0.5333 - val_loss: 0.7613\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4593 - auc: 0.5078 - loss: 0.7574 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6924\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5335 - auc: 0.5243 - loss: 0.6935 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.7108\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5335 - auc: 0.5924 - loss: 0.6933 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6951\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5428 - auc: 0.5782 - loss: 0.6871 - val_accuracy: 0.5000 - val_auc: 0.5667 - val_loss: 0.6909\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4665 - auc: 0.5828 - loss: 0.6926 - val_accuracy: 0.5000 - val_auc: 0.5667 - val_loss: 0.6921\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4665 - auc: 0.5568 - loss: 0.6959 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6911\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.4665 - auc: 0.5602 - loss: 0.6938 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6898\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.4940 - auc: 0.5607 - loss: 0.6906 - val_accuracy: 0.5667 - val_auc: 0.6333 - val_loss: 0.6892\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5508 - loss: 0.6886 - val_accuracy: 0.5667 - val_auc: 0.6333 - val_loss: 0.6885\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5438 - loss: 0.6876 - val_accuracy: 0.6000 - val_auc: 0.6333 - val_loss: 0.6876\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5552 - loss: 0.6872 - val_accuracy: 0.6000 - val_auc: 0.6333 - val_loss: 0.6865\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5334 - loss: 0.6867 - val_accuracy: 0.6000 - val_auc: 0.6333 - val_loss: 0.6852\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5598 - loss: 0.6855 - val_accuracy: 0.6000 - val_auc: 0.6333 - val_loss: 0.6834\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5328 - loss: 0.6837 - val_accuracy: 0.6000 - val_auc: 0.6333 - val_loss: 0.6813\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5193 - loss: 0.6814 - val_accuracy: 0.6000 - val_auc: 0.6333 - val_loss: 0.6787\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5334 - loss: 0.6790 - val_accuracy: 0.6000 - val_auc: 0.6333 - val_loss: 0.6754\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5328 - loss: 0.6761 - val_accuracy: 0.6000 - val_auc: 0.6333 - val_loss: 0.6711\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5330 - loss: 0.6722 - val_accuracy: 0.6333 - val_auc: 0.8333 - val_loss: 0.6646\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.5972 - loss: 0.6659 - val_accuracy: 0.6333 - val_auc: 0.8156 - val_loss: 0.6539\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.6585 - loss: 0.6608 - val_accuracy: 0.7000 - val_auc: 0.8333 - val_loss: 0.6451\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5099 - auc: 0.6780 - loss: 0.6627 - val_accuracy: 0.7000 - val_auc: 0.8333 - val_loss: 0.6429\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6367 - auc: 0.6625 - loss: 0.6547 - val_accuracy: 0.6333 - val_auc: 0.8333 - val_loss: 0.6314\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6498 - auc: 0.6580 - loss: 0.6396 - val_accuracy: 0.8333 - val_auc: 0.7889 - val_loss: 0.6036\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6715 - auc: 0.6708 - loss: 0.6297 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.5476\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7253 - auc: 0.6504 - loss: 0.5988 - val_accuracy: 0.6667 - val_auc: 0.8222 - val_loss: 0.6158\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6150 - auc: 0.7552 - loss: 0.6627 - val_accuracy: 0.6333 - val_auc: 0.8333 - val_loss: 0.6176\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6221 - auc: 0.6512 - loss: 0.6347 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.6130\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5099 - auc: 0.6826 - loss: 0.6413 - val_accuracy: 0.7333 - val_auc: 0.8222 - val_loss: 0.6028\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6715 - auc: 0.6963 - loss: 0.6288 - val_accuracy: 0.6667 - val_auc: 0.8333 - val_loss: 0.5890\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6715 - auc: 0.7173 - loss: 0.6158 - val_accuracy: 0.7333 - val_auc: 0.8222 - val_loss: 0.5679\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6750 - auc: 0.6919 - loss: 0.6010 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.5266\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7558 - auc: 0.7038 - loss: 0.5731 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4643\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7501 - auc: 0.7552 - loss: 0.5383 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4302\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7502 - auc: 0.7653 - loss: 0.5374 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4229\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7398 - auc: 0.6770 - loss: 0.5242 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4075\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7502 - auc: 0.6866 - loss: 0.5043 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4054\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7001 - loss: 0.5010 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3940\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6856 - loss: 0.5002 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3991\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6728 - loss: 0.4991 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3901\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6873 - loss: 0.4957 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3960\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6834 - loss: 0.4943 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3869\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6873 - loss: 0.4951 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3901\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6797 - loss: 0.4915 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3858\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6679 - loss: 0.4919 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3898\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6733 - loss: 0.4910 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3839\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6784 - loss: 0.4916 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3896\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6735 - loss: 0.4913 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3828\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6811 - loss: 0.4921 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3849\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6802 - loss: 0.4868 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3830\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6758 - loss: 0.4871 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3869\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6903 - loss: 0.4891 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3809\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6890 - loss: 0.4903 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3881\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7398 - auc: 0.6833 - loss: 0.4913 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3808\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7502 - auc: 0.6891 - loss: 0.4934 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3816\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6895 - loss: 0.4877 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3935\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7398 - auc: 0.7073 - loss: 0.4946 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3794\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7502 - auc: 0.6891 - loss: 0.4965 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3802\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7033 - loss: 0.4876 - val_accuracy: 0.8000 - val_auc: 0.8222 - val_loss: 0.3970\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7398 - auc: 0.7144 - loss: 0.4969 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7502 - auc: 0.6971 - loss: 0.4976 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3797\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7042 - loss: 0.4868 - val_accuracy: 0.8000 - val_auc: 0.8222 - val_loss: 0.3989\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7398 - auc: 0.7144 - loss: 0.5000 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3785\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7502 - auc: 0.6891 - loss: 0.4983 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3794\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7049 - loss: 0.4875 - val_accuracy: 0.8000 - val_auc: 0.8222 - val_loss: 0.3971\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7398 - auc: 0.7073 - loss: 0.4990 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3783\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7502 - auc: 0.7338 - loss: 0.4982 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3787\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7502 - auc: 0.7093 - loss: 0.4930 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3839\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6818 - loss: 0.4819 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3838\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7393 - loss: 0.4810 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3779\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7279 - loss: 0.4833 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7025 - loss: 0.4842 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3786\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6880 - loss: 0.4822 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3797\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6871 - loss: 0.4809 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6911 - loss: 0.4808 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3782\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6890 - loss: 0.4812 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6912 - loss: 0.4813 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3782\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7014 - loss: 0.4810 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3782\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7014 - loss: 0.4807 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3780\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7014 - loss: 0.4806 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3779\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4806 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3778\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4805 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3777\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4804 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3776\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4802 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3775\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4801 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3774\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4800 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3772\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4799 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3771\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4797 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3770\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4796 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3769\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4795 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4793 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3766\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4791 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4790 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3763\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7019 - loss: 0.4788 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3762\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7019 - loss: 0.4786 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7079 - loss: 0.4784 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3759\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7030 - loss: 0.4782 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3757\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4780 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3755\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4778 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3753\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4776 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3751\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7078 - loss: 0.4773 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3750\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4771 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3748\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4769 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3746\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4766 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3744\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4764 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3742\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4761 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3740\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4759 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3738\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7019 - loss: 0.4756 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3736\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7085 - loss: 0.4754 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3734\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4751 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3732\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4749 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3730\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4747 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3728\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4744 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3726\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4742 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3724\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4740 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3722\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4738 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3720\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4736 - val_accuracy: 0.8333 - val_auc: 0.8778 - val_loss: 0.3719\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7086 - loss: 0.4734 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3717\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4732 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3715\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4730 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3714\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4728 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3712\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4726 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3711\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7019 - loss: 0.4725 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3709\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7085 - loss: 0.4723 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3708\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7004 - loss: 0.4721 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3707\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4720 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3706\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4718 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3704\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4717 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3703\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4716 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3702\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4714 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3701\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4713 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3700\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4712 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3699\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4711 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3698\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4709 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3697\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4708 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3697\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4707 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3696\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4706 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3695\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4705 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3694\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4704 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3694\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4703 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3693\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4703 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3692\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4702 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3692\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4701 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3691\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4700 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3691\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4699 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3690\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7074 - loss: 0.4699 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3690\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4698 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3689\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7090 - loss: 0.4697 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3689\n",
      "Epoch 169/200\n",
      "\u001b[1m5/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1s/step - accuracy: 0.7383 - auc: 0.6720 - loss: 0.5058"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_acc = []\n",
    "all_loss = []\n",
    "all_auc = []\n",
    "\n",
    "all_val_acc = []\n",
    "all_val_loss = []\n",
    "all_val_auc = []\n",
    "\n",
    "for j, seed in tqdm(enumerate(np.arange(NUM_EXPERIMENTS) + INIT_SEED)):\n",
    "    np.random.seed(int(seed))\n",
    "    random.seed(int(seed))\n",
    "    tf.random.set_seed(int(seed))\n",
    "\n",
    "    train_id = np.random.choice(np.unique(np.ravel(data[USER])), 7, replace=False)\n",
    "    train_index = np.isin(data[USER], train_id)\n",
    "\n",
    "    train = data.iloc[train_index]\n",
    "    test = data.iloc[~train_index]\n",
    "\n",
    "    X_train, y_train = reshape_dataset(train)\n",
    "    X_test, y_test = reshape_dataset(test)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = create_model(X_train)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=10,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    auc = history.history['auc']\n",
    "\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_auc = history.history['val_auc']\n",
    "\n",
    "    all_acc.append(acc)\n",
    "    all_loss.append(loss)\n",
    "    all_auc.append(auc)\n",
    "\n",
    "    all_val_acc.append(val_acc)\n",
    "    all_val_loss.append(val_loss)\n",
    "    all_val_auc.append(val_auc)\n",
    "\n",
    "epoch_acc = np.mean(all_acc, axis=0)\n",
    "epoch_loss = np.mean(all_loss, axis=0)\n",
    "epoch_auc = np.mean(all_auc, axis=0)\n",
    "\n",
    "epoch_val_acc = np.mean(all_val_acc, axis=0)\n",
    "epoch_val_loss = np.mean(all_val_loss, axis=0)\n",
    "epoch_val_auc = np.mean(all_val_auc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: TRAIN Accuracy = 0.474 Loss = 0.712 AUC = 0.418\n",
      "Epoch 1: VAL Accuracy = 0.487 Loss = 0.695 AUC = 0.507\n",
      "Epoch 2: TRAIN Accuracy = 0.517 Loss = 0.695 AUC = 0.503\n",
      "Epoch 2: VAL Accuracy = 0.5 Loss = 0.694 AUC = 0.513\n",
      "Epoch 3: TRAIN Accuracy = 0.503 Loss = 0.694 AUC = 0.522\n",
      "Epoch 3: VAL Accuracy = 0.5 Loss = 0.694 AUC = 0.56\n",
      "Epoch 4: TRAIN Accuracy = 0.477 Loss = 0.698 AUC = 0.455\n",
      "Epoch 4: VAL Accuracy = 0.513 Loss = 0.693 AUC = 0.54\n",
      "Epoch 5: TRAIN Accuracy = 0.449 Loss = 0.698 AUC = 0.446\n",
      "Epoch 5: VAL Accuracy = 0.52 Loss = 0.693 AUC = 0.593\n",
      "Epoch 6: TRAIN Accuracy = 0.509 Loss = 0.693 AUC = 0.515\n",
      "Epoch 6: VAL Accuracy = 0.5 Loss = 0.692 AUC = 0.587\n",
      "Epoch 7: TRAIN Accuracy = 0.506 Loss = 0.695 AUC = 0.495\n",
      "Epoch 7: VAL Accuracy = 0.527 Loss = 0.692 AUC = 0.567\n",
      "Epoch 8: TRAIN Accuracy = 0.497 Loss = 0.694 AUC = 0.514\n",
      "Epoch 8: VAL Accuracy = 0.52 Loss = 0.692 AUC = 0.607\n",
      "Epoch 9: TRAIN Accuracy = 0.509 Loss = 0.691 AUC = 0.54\n",
      "Epoch 9: VAL Accuracy = 0.513 Loss = 0.692 AUC = 0.6\n",
      "Epoch 10: TRAIN Accuracy = 0.506 Loss = 0.695 AUC = 0.486\n",
      "Epoch 10: VAL Accuracy = 0.527 Loss = 0.692 AUC = 0.58\n",
      "Epoch 11: TRAIN Accuracy = 0.446 Loss = 0.697 AUC = 0.446\n",
      "Epoch 11: VAL Accuracy = 0.533 Loss = 0.691 AUC = 0.607\n",
      "Epoch 12: TRAIN Accuracy = 0.511 Loss = 0.691 AUC = 0.534\n",
      "Epoch 12: VAL Accuracy = 0.56 Loss = 0.691 AUC = 0.6\n",
      "Epoch 13: TRAIN Accuracy = 0.506 Loss = 0.693 AUC = 0.517\n",
      "Epoch 13: VAL Accuracy = 0.56 Loss = 0.691 AUC = 0.6\n",
      "Epoch 14: TRAIN Accuracy = 0.514 Loss = 0.693 AUC = 0.514\n",
      "Epoch 14: VAL Accuracy = 0.573 Loss = 0.69 AUC = 0.607\n",
      "Epoch 15: TRAIN Accuracy = 0.514 Loss = 0.693 AUC = 0.506\n",
      "Epoch 15: VAL Accuracy = 0.56 Loss = 0.69 AUC = 0.6\n",
      "Epoch 16: TRAIN Accuracy = 0.463 Loss = 0.696 AUC = 0.456\n",
      "Epoch 16: VAL Accuracy = 0.56 Loss = 0.689 AUC = 0.607\n",
      "Epoch 17: TRAIN Accuracy = 0.551 Loss = 0.689 AUC = 0.57\n",
      "Epoch 17: VAL Accuracy = 0.56 Loss = 0.688 AUC = 0.62\n",
      "Epoch 18: TRAIN Accuracy = 0.534 Loss = 0.691 AUC = 0.521\n",
      "Epoch 18: VAL Accuracy = 0.58 Loss = 0.687 AUC = 0.667\n",
      "Epoch 19: TRAIN Accuracy = 0.529 Loss = 0.691 AUC = 0.513\n",
      "Epoch 19: VAL Accuracy = 0.593 Loss = 0.685 AUC = 0.687\n",
      "Epoch 20: TRAIN Accuracy = 0.569 Loss = 0.684 AUC = 0.58\n",
      "Epoch 20: VAL Accuracy = 0.593 Loss = 0.683 AUC = 0.64\n",
      "Epoch 21: TRAIN Accuracy = 0.571 Loss = 0.681 AUC = 0.618\n",
      "Epoch 21: VAL Accuracy = 0.553 Loss = 0.691 AUC = 0.629\n",
      "Epoch 22: TRAIN Accuracy = 0.569 Loss = 0.681 AUC = 0.597\n",
      "Epoch 22: VAL Accuracy = 0.627 Loss = 0.677 AUC = 0.673\n",
      "Epoch 23: TRAIN Accuracy = 0.58 Loss = 0.676 AUC = 0.582\n",
      "Epoch 23: VAL Accuracy = 0.627 Loss = 0.689 AUC = 0.669\n",
      "Epoch 24: TRAIN Accuracy = 0.606 Loss = 0.679 AUC = 0.59\n",
      "Epoch 24: VAL Accuracy = 0.613 Loss = 0.674 AUC = 0.667\n",
      "Epoch 25: TRAIN Accuracy = 0.589 Loss = 0.669 AUC = 0.624\n",
      "Epoch 25: VAL Accuracy = 0.587 Loss = 0.674 AUC = 0.7\n",
      "Epoch 26: TRAIN Accuracy = 0.54 Loss = 0.679 AUC = 0.564\n",
      "Epoch 26: VAL Accuracy = 0.6 Loss = 0.669 AUC = 0.667\n",
      "Epoch 27: TRAIN Accuracy = 0.577 Loss = 0.673 AUC = 0.581\n",
      "Epoch 27: VAL Accuracy = 0.627 Loss = 0.66 AUC = 0.671\n",
      "Epoch 28: TRAIN Accuracy = 0.631 Loss = 0.657 AUC = 0.638\n",
      "Epoch 28: VAL Accuracy = 0.62 Loss = 0.652 AUC = 0.687\n",
      "Epoch 29: TRAIN Accuracy = 0.58 Loss = 0.662 AUC = 0.615\n",
      "Epoch 29: VAL Accuracy = 0.633 Loss = 0.645 AUC = 0.693\n",
      "Epoch 30: TRAIN Accuracy = 0.617 Loss = 0.651 AUC = 0.616\n",
      "Epoch 30: VAL Accuracy = 0.653 Loss = 0.635 AUC = 0.716\n",
      "Epoch 31: TRAIN Accuracy = 0.623 Loss = 0.634 AUC = 0.642\n",
      "Epoch 31: VAL Accuracy = 0.693 Loss = 0.605 AUC = 0.74\n",
      "Epoch 32: TRAIN Accuracy = 0.629 Loss = 0.616 AUC = 0.656\n",
      "Epoch 32: VAL Accuracy = 0.68 Loss = 0.6 AUC = 0.701\n",
      "Epoch 33: TRAIN Accuracy = 0.64 Loss = 0.61 AUC = 0.625\n",
      "Epoch 33: VAL Accuracy = 0.693 Loss = 0.596 AUC = 0.721\n",
      "Epoch 34: TRAIN Accuracy = 0.651 Loss = 0.592 AUC = 0.66\n",
      "Epoch 34: VAL Accuracy = 0.613 Loss = 0.703 AUC = 0.743\n",
      "Epoch 35: TRAIN Accuracy = 0.591 Loss = 0.716 AUC = 0.58\n",
      "Epoch 35: VAL Accuracy = 0.633 Loss = 0.727 AUC = 0.697\n",
      "Epoch 36: TRAIN Accuracy = 0.6 Loss = 0.698 AUC = 0.627\n",
      "Epoch 36: VAL Accuracy = 0.647 Loss = 0.66 AUC = 0.681\n",
      "Epoch 37: TRAIN Accuracy = 0.597 Loss = 0.64 AUC = 0.677\n",
      "Epoch 37: VAL Accuracy = 0.593 Loss = 0.647 AUC = 0.697\n",
      "Epoch 38: TRAIN Accuracy = 0.614 Loss = 0.642 AUC = 0.64\n",
      "Epoch 38: VAL Accuracy = 0.613 Loss = 0.646 AUC = 0.671\n",
      "Epoch 39: TRAIN Accuracy = 0.609 Loss = 0.647 AUC = 0.616\n",
      "Epoch 39: VAL Accuracy = 0.587 Loss = 0.63 AUC = 0.691\n",
      "Epoch 40: TRAIN Accuracy = 0.603 Loss = 0.634 AUC = 0.61\n",
      "Epoch 40: VAL Accuracy = 0.653 Loss = 0.638 AUC = 0.701\n",
      "Epoch 41: TRAIN Accuracy = 0.594 Loss = 0.626 AUC = 0.616\n",
      "Epoch 41: VAL Accuracy = 0.66 Loss = 0.601 AUC = 0.672\n",
      "Epoch 42: TRAIN Accuracy = 0.674 Loss = 0.604 AUC = 0.651\n",
      "Epoch 42: VAL Accuracy = 0.7 Loss = 0.58 AUC = 0.684\n",
      "Epoch 43: TRAIN Accuracy = 0.657 Loss = 0.604 AUC = 0.66\n",
      "Epoch 43: VAL Accuracy = 0.613 Loss = 0.693 AUC = 0.615\n",
      "Epoch 44: TRAIN Accuracy = 0.606 Loss = 0.658 AUC = 0.606\n",
      "Epoch 44: VAL Accuracy = 0.607 Loss = 0.645 AUC = 0.63\n",
      "Epoch 45: TRAIN Accuracy = 0.606 Loss = 0.633 AUC = 0.627\n",
      "Epoch 45: VAL Accuracy = 0.613 Loss = 0.609 AUC = 0.662\n",
      "Epoch 46: TRAIN Accuracy = 0.6 Loss = 0.623 AUC = 0.592\n",
      "Epoch 46: VAL Accuracy = 0.62 Loss = 0.6 AUC = 0.66\n",
      "Epoch 47: TRAIN Accuracy = 0.591 Loss = 0.61 AUC = 0.601\n",
      "Epoch 47: VAL Accuracy = 0.613 Loss = 0.609 AUC = 0.654\n",
      "Epoch 48: TRAIN Accuracy = 0.583 Loss = 0.617 AUC = 0.589\n",
      "Epoch 48: VAL Accuracy = 0.627 Loss = 0.588 AUC = 0.635\n",
      "Epoch 49: TRAIN Accuracy = 0.646 Loss = 0.6 AUC = 0.659\n",
      "Epoch 49: VAL Accuracy = 0.6 Loss = 0.613 AUC = 0.635\n",
      "Epoch 50: TRAIN Accuracy = 0.609 Loss = 0.618 AUC = 0.608\n",
      "Epoch 50: VAL Accuracy = 0.6 Loss = 0.613 AUC = 0.621\n",
      "Epoch 51: TRAIN Accuracy = 0.614 Loss = 0.61 AUC = 0.614\n",
      "Epoch 51: VAL Accuracy = 0.613 Loss = 0.606 AUC = 0.664\n",
      "Epoch 52: TRAIN Accuracy = 0.557 Loss = 0.634 AUC = 0.556\n",
      "Epoch 52: VAL Accuracy = 0.593 Loss = 0.614 AUC = 0.621\n",
      "Epoch 53: TRAIN Accuracy = 0.549 Loss = 0.622 AUC = 0.549\n",
      "Epoch 53: VAL Accuracy = 0.593 Loss = 0.623 AUC = 0.641\n",
      "Epoch 54: TRAIN Accuracy = 0.591 Loss = 0.618 AUC = 0.589\n",
      "Epoch 54: VAL Accuracy = 0.6 Loss = 0.609 AUC = 0.635\n",
      "Epoch 55: TRAIN Accuracy = 0.586 Loss = 0.614 AUC = 0.583\n",
      "Epoch 55: VAL Accuracy = 0.6 Loss = 0.608 AUC = 0.668\n",
      "Epoch 56: TRAIN Accuracy = 0.643 Loss = 0.612 AUC = 0.64\n",
      "Epoch 56: VAL Accuracy = 0.613 Loss = 0.603 AUC = 0.647\n",
      "Epoch 57: TRAIN Accuracy = 0.583 Loss = 0.62 AUC = 0.573\n",
      "Epoch 57: VAL Accuracy = 0.6 Loss = 0.623 AUC = 0.689\n",
      "Epoch 58: TRAIN Accuracy = 0.606 Loss = 0.609 AUC = 0.632\n",
      "Epoch 58: VAL Accuracy = 0.553 Loss = 0.809 AUC = 0.673\n",
      "Epoch 59: TRAIN Accuracy = 0.603 Loss = 0.62 AUC = 0.593\n",
      "Epoch 59: VAL Accuracy = 0.613 Loss = 0.594 AUC = 0.693\n",
      "Epoch 60: TRAIN Accuracy = 0.58 Loss = 0.619 AUC = 0.56\n",
      "Epoch 60: VAL Accuracy = 0.64 Loss = 0.599 AUC = 0.681\n",
      "Epoch 61: TRAIN Accuracy = 0.631 Loss = 0.608 AUC = 0.618\n",
      "Epoch 61: VAL Accuracy = 0.64 Loss = 0.594 AUC = 0.681\n",
      "Epoch 62: TRAIN Accuracy = 0.617 Loss = 0.603 AUC = 0.611\n",
      "Epoch 62: VAL Accuracy = 0.627 Loss = 0.587 AUC = 0.677\n",
      "Epoch 63: TRAIN Accuracy = 0.634 Loss = 0.591 AUC = 0.653\n",
      "Epoch 63: VAL Accuracy = 0.627 Loss = 0.584 AUC = 0.676\n",
      "Epoch 64: TRAIN Accuracy = 0.6 Loss = 0.594 AUC = 0.599\n",
      "Epoch 64: VAL Accuracy = 0.627 Loss = 0.58 AUC = 0.666\n",
      "Epoch 65: TRAIN Accuracy = 0.637 Loss = 0.583 AUC = 0.658\n",
      "Epoch 65: VAL Accuracy = 0.66 Loss = 0.579 AUC = 0.708\n",
      "Epoch 66: TRAIN Accuracy = 0.663 Loss = 0.578 AUC = 0.683\n",
      "Epoch 66: VAL Accuracy = 0.667 Loss = 0.576 AUC = 0.737\n",
      "Epoch 67: TRAIN Accuracy = 0.666 Loss = 0.576 AUC = 0.668\n",
      "Epoch 67: VAL Accuracy = 0.667 Loss = 0.567 AUC = 0.73\n",
      "Epoch 68: TRAIN Accuracy = 0.677 Loss = 0.568 AUC = 0.699\n",
      "Epoch 68: VAL Accuracy = 0.693 Loss = 0.548 AUC = 0.717\n",
      "Epoch 69: TRAIN Accuracy = 0.671 Loss = 0.566 AUC = 0.681\n",
      "Epoch 69: VAL Accuracy = 0.68 Loss = 0.551 AUC = 0.713\n",
      "Epoch 70: TRAIN Accuracy = 0.677 Loss = 0.556 AUC = 0.652\n",
      "Epoch 70: VAL Accuracy = 0.76 Loss = 0.531 AUC = 0.753\n",
      "Epoch 71: TRAIN Accuracy = 0.694 Loss = 0.548 AUC = 0.697\n",
      "Epoch 71: VAL Accuracy = 0.753 Loss = 0.513 AUC = 0.764\n",
      "Epoch 72: TRAIN Accuracy = 0.717 Loss = 0.537 AUC = 0.711\n",
      "Epoch 72: VAL Accuracy = 0.74 Loss = 0.515 AUC = 0.766\n",
      "Epoch 73: TRAIN Accuracy = 0.74 Loss = 0.518 AUC = 0.76\n",
      "Epoch 73: VAL Accuracy = 0.753 Loss = 0.491 AUC = 0.773\n",
      "Epoch 74: TRAIN Accuracy = 0.711 Loss = 0.534 AUC = 0.714\n",
      "Epoch 74: VAL Accuracy = 0.687 Loss = 0.547 AUC = 0.707\n",
      "Epoch 75: TRAIN Accuracy = 0.68 Loss = 0.552 AUC = 0.677\n",
      "Epoch 75: VAL Accuracy = 0.693 Loss = 0.535 AUC = 0.702\n",
      "Epoch 76: TRAIN Accuracy = 0.691 Loss = 0.546 AUC = 0.659\n",
      "Epoch 76: VAL Accuracy = 0.693 Loss = 0.52 AUC = 0.7\n",
      "Epoch 77: TRAIN Accuracy = 0.654 Loss = 0.54 AUC = 0.648\n",
      "Epoch 77: VAL Accuracy = 0.693 Loss = 0.516 AUC = 0.706\n",
      "Epoch 78: TRAIN Accuracy = 0.711 Loss = 0.532 AUC = 0.718\n",
      "Epoch 78: VAL Accuracy = 0.693 Loss = 0.517 AUC = 0.706\n",
      "Epoch 79: TRAIN Accuracy = 0.703 Loss = 0.53 AUC = 0.716\n",
      "Epoch 79: VAL Accuracy = 0.68 Loss = 0.515 AUC = 0.706\n",
      "Epoch 80: TRAIN Accuracy = 0.7 Loss = 0.535 AUC = 0.676\n",
      "Epoch 80: VAL Accuracy = 0.693 Loss = 0.517 AUC = 0.709\n",
      "Epoch 81: TRAIN Accuracy = 0.669 Loss = 0.529 AUC = 0.684\n",
      "Epoch 81: VAL Accuracy = 0.68 Loss = 0.526 AUC = 0.704\n",
      "Epoch 82: TRAIN Accuracy = 0.64 Loss = 0.541 AUC = 0.621\n",
      "Epoch 82: VAL Accuracy = 0.693 Loss = 0.519 AUC = 0.711\n",
      "Epoch 83: TRAIN Accuracy = 0.669 Loss = 0.564 AUC = 0.664\n",
      "Epoch 83: VAL Accuracy = 0.68 Loss = 0.563 AUC = 0.698\n",
      "Epoch 84: TRAIN Accuracy = 0.654 Loss = 0.54 AUC = 0.639\n",
      "Epoch 84: VAL Accuracy = 0.693 Loss = 0.516 AUC = 0.698\n",
      "Epoch 85: TRAIN Accuracy = 0.68 Loss = 0.541 AUC = 0.665\n",
      "Epoch 85: VAL Accuracy = 0.693 Loss = 0.514 AUC = 0.714\n",
      "Epoch 86: TRAIN Accuracy = 0.654 Loss = 0.533 AUC = 0.667\n",
      "Epoch 86: VAL Accuracy = 0.693 Loss = 0.515 AUC = 0.704\n",
      "Epoch 87: TRAIN Accuracy = 0.643 Loss = 0.538 AUC = 0.62\n",
      "Epoch 87: VAL Accuracy = 0.693 Loss = 0.515 AUC = 0.707\n",
      "Epoch 88: TRAIN Accuracy = 0.703 Loss = 0.528 AUC = 0.708\n",
      "Epoch 88: VAL Accuracy = 0.693 Loss = 0.515 AUC = 0.704\n",
      "Epoch 89: TRAIN Accuracy = 0.709 Loss = 0.527 AUC = 0.735\n",
      "Epoch 89: VAL Accuracy = 0.693 Loss = 0.514 AUC = 0.707\n",
      "Epoch 90: TRAIN Accuracy = 0.646 Loss = 0.534 AUC = 0.645\n",
      "Epoch 90: VAL Accuracy = 0.693 Loss = 0.514 AUC = 0.709\n",
      "Epoch 91: TRAIN Accuracy = 0.683 Loss = 0.534 AUC = 0.688\n",
      "Epoch 91: VAL Accuracy = 0.693 Loss = 0.514 AUC = 0.709\n",
      "Epoch 92: TRAIN Accuracy = 0.703 Loss = 0.53 AUC = 0.704\n",
      "Epoch 92: VAL Accuracy = 0.693 Loss = 0.515 AUC = 0.709\n",
      "Epoch 93: TRAIN Accuracy = 0.683 Loss = 0.53 AUC = 0.692\n",
      "Epoch 93: VAL Accuracy = 0.693 Loss = 0.516 AUC = 0.709\n",
      "Epoch 94: TRAIN Accuracy = 0.683 Loss = 0.531 AUC = 0.668\n",
      "Epoch 94: VAL Accuracy = 0.693 Loss = 0.516 AUC = 0.707\n",
      "Epoch 95: TRAIN Accuracy = 0.706 Loss = 0.534 AUC = 0.702\n",
      "Epoch 95: VAL Accuracy = 0.693 Loss = 0.515 AUC = 0.707\n",
      "Epoch 96: TRAIN Accuracy = 0.691 Loss = 0.53 AUC = 0.701\n",
      "Epoch 96: VAL Accuracy = 0.68 Loss = 0.554 AUC = 0.704\n",
      "Epoch 97: TRAIN Accuracy = 0.683 Loss = 0.548 AUC = 0.682\n",
      "Epoch 97: VAL Accuracy = 0.713 Loss = 0.523 AUC = 0.709\n",
      "Epoch 98: TRAIN Accuracy = 0.703 Loss = 0.539 AUC = 0.708\n",
      "Epoch 98: VAL Accuracy = 0.707 Loss = 0.518 AUC = 0.704\n",
      "Epoch 99: TRAIN Accuracy = 0.703 Loss = 0.536 AUC = 0.696\n",
      "Epoch 99: VAL Accuracy = 0.7 Loss = 0.533 AUC = 0.701\n",
      "Epoch 100: TRAIN Accuracy = 0.666 Loss = 0.528 AUC = 0.717\n",
      "Epoch 100: VAL Accuracy = 0.707 Loss = 0.519 AUC = 0.704\n",
      "Epoch 101: TRAIN Accuracy = 0.683 Loss = 0.532 AUC = 0.679\n",
      "Epoch 101: VAL Accuracy = 0.713 Loss = 0.513 AUC = 0.707\n",
      "Epoch 102: TRAIN Accuracy = 0.686 Loss = 0.526 AUC = 0.687\n",
      "Epoch 102: VAL Accuracy = 0.713 Loss = 0.514 AUC = 0.709\n",
      "Epoch 103: TRAIN Accuracy = 0.68 Loss = 0.533 AUC = 0.656\n",
      "Epoch 103: VAL Accuracy = 0.7 Loss = 0.522 AUC = 0.707\n",
      "Epoch 104: TRAIN Accuracy = 0.691 Loss = 0.527 AUC = 0.701\n",
      "Epoch 104: VAL Accuracy = 0.7 Loss = 0.526 AUC = 0.707\n",
      "Epoch 105: TRAIN Accuracy = 0.671 Loss = 0.537 AUC = 0.667\n",
      "Epoch 105: VAL Accuracy = 0.713 Loss = 0.513 AUC = 0.713\n",
      "Epoch 106: TRAIN Accuracy = 0.697 Loss = 0.538 AUC = 0.693\n",
      "Epoch 106: VAL Accuracy = 0.713 Loss = 0.511 AUC = 0.74\n",
      "Epoch 107: TRAIN Accuracy = 0.669 Loss = 0.537 AUC = 0.643\n",
      "Epoch 107: VAL Accuracy = 0.713 Loss = 0.511 AUC = 0.742\n",
      "Epoch 108: TRAIN Accuracy = 0.686 Loss = 0.536 AUC = 0.677\n",
      "Epoch 108: VAL Accuracy = 0.713 Loss = 0.51 AUC = 0.709\n",
      "Epoch 109: TRAIN Accuracy = 0.694 Loss = 0.532 AUC = 0.671\n",
      "Epoch 109: VAL Accuracy = 0.713 Loss = 0.509 AUC = 0.734\n",
      "Epoch 110: TRAIN Accuracy = 0.689 Loss = 0.526 AUC = 0.704\n",
      "Epoch 110: VAL Accuracy = 0.713 Loss = 0.51 AUC = 0.731\n",
      "Epoch 111: TRAIN Accuracy = 0.731 Loss = 0.525 AUC = 0.707\n",
      "Epoch 111: VAL Accuracy = 0.713 Loss = 0.508 AUC = 0.8\n",
      "Epoch 112: TRAIN Accuracy = 0.714 Loss = 0.52 AUC = 0.725\n",
      "Epoch 112: VAL Accuracy = 0.713 Loss = 0.508 AUC = 0.733\n",
      "Epoch 113: TRAIN Accuracy = 0.7 Loss = 0.527 AUC = 0.684\n",
      "Epoch 113: VAL Accuracy = 0.733 Loss = 0.505 AUC = 0.745\n",
      "Epoch 114: TRAIN Accuracy = 0.731 Loss = 0.519 AUC = 0.739\n",
      "Epoch 114: VAL Accuracy = 0.72 Loss = 0.505 AUC = 0.732\n",
      "Epoch 115: TRAIN Accuracy = 0.72 Loss = 0.522 AUC = 0.725\n",
      "Epoch 115: VAL Accuracy = 0.713 Loss = 0.506 AUC = 0.734\n",
      "Epoch 116: TRAIN Accuracy = 0.691 Loss = 0.523 AUC = 0.706\n",
      "Epoch 116: VAL Accuracy = 0.713 Loss = 0.505 AUC = 0.736\n",
      "Epoch 117: TRAIN Accuracy = 0.723 Loss = 0.522 AUC = 0.711\n",
      "Epoch 117: VAL Accuracy = 0.727 Loss = 0.5 AUC = 0.776\n",
      "Epoch 118: TRAIN Accuracy = 0.72 Loss = 0.512 AUC = 0.737\n",
      "Epoch 118: VAL Accuracy = 0.753 Loss = 0.487 AUC = 0.753\n",
      "Epoch 119: TRAIN Accuracy = 0.717 Loss = 0.507 AUC = 0.727\n",
      "Epoch 119: VAL Accuracy = 0.727 Loss = 0.499 AUC = 0.747\n",
      "Epoch 120: TRAIN Accuracy = 0.72 Loss = 0.512 AUC = 0.725\n",
      "Epoch 120: VAL Accuracy = 0.733 Loss = 0.49 AUC = 0.759\n",
      "Epoch 121: TRAIN Accuracy = 0.723 Loss = 0.499 AUC = 0.758\n",
      "Epoch 121: VAL Accuracy = 0.733 Loss = 0.49 AUC = 0.753\n",
      "Epoch 122: TRAIN Accuracy = 0.726 Loss = 0.507 AUC = 0.725\n",
      "Epoch 122: VAL Accuracy = 0.747 Loss = 0.481 AUC = 0.768\n",
      "Epoch 123: TRAIN Accuracy = 0.68 Loss = 0.555 AUC = 0.669\n",
      "Epoch 123: VAL Accuracy = 0.693 Loss = 0.542 AUC = 0.745\n",
      "Epoch 124: TRAIN Accuracy = 0.723 Loss = 0.526 AUC = 0.712\n",
      "Epoch 124: VAL Accuracy = 0.733 Loss = 0.493 AUC = 0.76\n",
      "Epoch 125: TRAIN Accuracy = 0.711 Loss = 0.512 AUC = 0.722\n",
      "Epoch 125: VAL Accuracy = 0.747 Loss = 0.493 AUC = 0.755\n",
      "Epoch 126: TRAIN Accuracy = 0.729 Loss = 0.511 AUC = 0.731\n",
      "Epoch 126: VAL Accuracy = 0.753 Loss = 0.484 AUC = 0.794\n",
      "Epoch 127: TRAIN Accuracy = 0.731 Loss = 0.509 AUC = 0.715\n",
      "Epoch 127: VAL Accuracy = 0.733 Loss = 0.488 AUC = 0.824\n",
      "Epoch 128: TRAIN Accuracy = 0.703 Loss = 0.519 AUC = 0.706\n",
      "Epoch 128: VAL Accuracy = 0.753 Loss = 0.477 AUC = 0.762\n",
      "Epoch 129: TRAIN Accuracy = 0.734 Loss = 0.493 AUC = 0.73\n",
      "Epoch 129: VAL Accuracy = 0.753 Loss = 0.471 AUC = 0.778\n",
      "Epoch 130: TRAIN Accuracy = 0.746 Loss = 0.493 AUC = 0.712\n",
      "Epoch 130: VAL Accuracy = 0.747 Loss = 0.481 AUC = 0.756\n",
      "Epoch 131: TRAIN Accuracy = 0.746 Loss = 0.487 AUC = 0.772\n",
      "Epoch 131: VAL Accuracy = 0.753 Loss = 0.467 AUC = 0.783\n",
      "Epoch 132: TRAIN Accuracy = 0.731 Loss = 0.497 AUC = 0.703\n",
      "Epoch 132: VAL Accuracy = 0.747 Loss = 0.477 AUC = 0.769\n",
      "Epoch 133: TRAIN Accuracy = 0.737 Loss = 0.495 AUC = 0.734\n",
      "Epoch 133: VAL Accuracy = 0.747 Loss = 0.477 AUC = 0.779\n",
      "Epoch 134: TRAIN Accuracy = 0.743 Loss = 0.494 AUC = 0.744\n",
      "Epoch 134: VAL Accuracy = 0.74 Loss = 0.48 AUC = 0.768\n",
      "Epoch 135: TRAIN Accuracy = 0.74 Loss = 0.501 AUC = 0.754\n",
      "Epoch 135: VAL Accuracy = 0.753 Loss = 0.465 AUC = 0.769\n",
      "Epoch 136: TRAIN Accuracy = 0.746 Loss = 0.481 AUC = 0.762\n",
      "Epoch 136: VAL Accuracy = 0.753 Loss = 0.467 AUC = 0.766\n",
      "Epoch 137: TRAIN Accuracy = 0.74 Loss = 0.486 AUC = 0.729\n",
      "Epoch 137: VAL Accuracy = 0.747 Loss = 0.468 AUC = 0.769\n",
      "Epoch 138: TRAIN Accuracy = 0.754 Loss = 0.485 AUC = 0.737\n",
      "Epoch 138: VAL Accuracy = 0.753 Loss = 0.464 AUC = 0.797\n",
      "Epoch 139: TRAIN Accuracy = 0.749 Loss = 0.486 AUC = 0.754\n",
      "Epoch 139: VAL Accuracy = 0.753 Loss = 0.463 AUC = 0.772\n",
      "Epoch 140: TRAIN Accuracy = 0.746 Loss = 0.48 AUC = 0.717\n",
      "Epoch 140: VAL Accuracy = 0.753 Loss = 0.462 AUC = 0.77\n",
      "Epoch 141: TRAIN Accuracy = 0.746 Loss = 0.485 AUC = 0.747\n",
      "Epoch 141: VAL Accuracy = 0.753 Loss = 0.463 AUC = 0.78\n",
      "Epoch 142: TRAIN Accuracy = 0.76 Loss = 0.481 AUC = 0.757\n",
      "Epoch 142: VAL Accuracy = 0.74 Loss = 0.477 AUC = 0.794\n",
      "Epoch 143: TRAIN Accuracy = 0.709 Loss = 0.485 AUC = 0.715\n",
      "Epoch 143: VAL Accuracy = 0.753 Loss = 0.46 AUC = 0.782\n",
      "Epoch 144: TRAIN Accuracy = 0.749 Loss = 0.482 AUC = 0.746\n",
      "Epoch 144: VAL Accuracy = 0.753 Loss = 0.462 AUC = 0.791\n",
      "Epoch 145: TRAIN Accuracy = 0.743 Loss = 0.476 AUC = 0.748\n",
      "Epoch 145: VAL Accuracy = 0.747 Loss = 0.462 AUC = 0.799\n",
      "Epoch 146: TRAIN Accuracy = 0.769 Loss = 0.477 AUC = 0.748\n",
      "Epoch 146: VAL Accuracy = 0.793 Loss = 0.459 AUC = 0.808\n",
      "Epoch 147: TRAIN Accuracy = 0.771 Loss = 0.463 AUC = 0.799\n",
      "Epoch 147: VAL Accuracy = 0.787 Loss = 0.448 AUC = 0.829\n",
      "Epoch 148: TRAIN Accuracy = 0.783 Loss = 0.459 AUC = 0.789\n",
      "Epoch 148: VAL Accuracy = 0.8 Loss = 0.442 AUC = 0.827\n",
      "Epoch 149: TRAIN Accuracy = 0.771 Loss = 0.465 AUC = 0.788\n",
      "Epoch 149: VAL Accuracy = 0.807 Loss = 0.45 AUC = 0.828\n",
      "Epoch 150: TRAIN Accuracy = 0.774 Loss = 0.472 AUC = 0.8\n",
      "Epoch 150: VAL Accuracy = 0.8 Loss = 0.447 AUC = 0.823\n",
      "Epoch 151: TRAIN Accuracy = 0.78 Loss = 0.469 AUC = 0.754\n",
      "Epoch 151: VAL Accuracy = 0.8 Loss = 0.439 AUC = 0.83\n",
      "Epoch 152: TRAIN Accuracy = 0.786 Loss = 0.457 AUC = 0.775\n",
      "Epoch 152: VAL Accuracy = 0.8 Loss = 0.432 AUC = 0.83\n",
      "Epoch 153: TRAIN Accuracy = 0.791 Loss = 0.456 AUC = 0.788\n",
      "Epoch 153: VAL Accuracy = 0.813 Loss = 0.421 AUC = 0.828\n",
      "Epoch 154: TRAIN Accuracy = 0.803 Loss = 0.432 AUC = 0.819\n",
      "Epoch 154: VAL Accuracy = 0.82 Loss = 0.406 AUC = 0.825\n",
      "Epoch 155: TRAIN Accuracy = 0.803 Loss = 0.428 AUC = 0.817\n",
      "Epoch 155: VAL Accuracy = 0.82 Loss = 0.406 AUC = 0.823\n",
      "Epoch 156: TRAIN Accuracy = 0.803 Loss = 0.43 AUC = 0.798\n",
      "Epoch 156: VAL Accuracy = 0.82 Loss = 0.404 AUC = 0.825\n",
      "Epoch 157: TRAIN Accuracy = 0.803 Loss = 0.428 AUC = 0.791\n",
      "Epoch 157: VAL Accuracy = 0.82 Loss = 0.402 AUC = 0.827\n",
      "Epoch 158: TRAIN Accuracy = 0.803 Loss = 0.429 AUC = 0.783\n",
      "Epoch 158: VAL Accuracy = 0.813 Loss = 0.409 AUC = 0.822\n",
      "Epoch 159: TRAIN Accuracy = 0.797 Loss = 0.426 AUC = 0.813\n",
      "Epoch 159: VAL Accuracy = 0.8 Loss = 0.42 AUC = 0.824\n",
      "Epoch 160: TRAIN Accuracy = 0.783 Loss = 0.445 AUC = 0.783\n",
      "Epoch 160: VAL Accuracy = 0.793 Loss = 0.43 AUC = 0.822\n",
      "Epoch 161: TRAIN Accuracy = 0.783 Loss = 0.444 AUC = 0.79\n",
      "Epoch 161: VAL Accuracy = 0.8 Loss = 0.42 AUC = 0.829\n",
      "Epoch 162: TRAIN Accuracy = 0.786 Loss = 0.438 AUC = 0.795\n",
      "Epoch 162: VAL Accuracy = 0.8 Loss = 0.419 AUC = 0.832\n",
      "Epoch 163: TRAIN Accuracy = 0.786 Loss = 0.437 AUC = 0.799\n",
      "Epoch 163: VAL Accuracy = 0.82 Loss = 0.401 AUC = 0.834\n",
      "Epoch 164: TRAIN Accuracy = 0.803 Loss = 0.427 AUC = 0.786\n",
      "Epoch 164: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.832\n",
      "Epoch 165: TRAIN Accuracy = 0.803 Loss = 0.42 AUC = 0.795\n",
      "Epoch 165: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.832\n",
      "Epoch 166: TRAIN Accuracy = 0.803 Loss = 0.424 AUC = 0.79\n",
      "Epoch 166: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.832\n",
      "Epoch 167: TRAIN Accuracy = 0.803 Loss = 0.422 AUC = 0.789\n",
      "Epoch 167: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.829\n",
      "Epoch 168: TRAIN Accuracy = 0.803 Loss = 0.419 AUC = 0.799\n",
      "Epoch 168: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.834\n",
      "Epoch 169: TRAIN Accuracy = 0.8 Loss = 0.42 AUC = 0.808\n",
      "Epoch 169: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.829\n",
      "Epoch 170: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.8\n",
      "Epoch 170: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.827\n",
      "Epoch 171: TRAIN Accuracy = 0.803 Loss = 0.421 AUC = 0.778\n",
      "Epoch 171: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.825\n",
      "Epoch 172: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.793\n",
      "Epoch 172: VAL Accuracy = 0.813 Loss = 0.407 AUC = 0.82\n",
      "Epoch 173: TRAIN Accuracy = 0.8 Loss = 0.428 AUC = 0.79\n",
      "Epoch 173: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.825\n",
      "Epoch 174: TRAIN Accuracy = 0.8 Loss = 0.429 AUC = 0.769\n",
      "Epoch 174: VAL Accuracy = 0.813 Loss = 0.408 AUC = 0.814\n",
      "Epoch 175: TRAIN Accuracy = 0.794 Loss = 0.43 AUC = 0.799\n",
      "Epoch 175: VAL Accuracy = 0.813 Loss = 0.411 AUC = 0.806\n",
      "Epoch 176: TRAIN Accuracy = 0.797 Loss = 0.433 AUC = 0.781\n",
      "Epoch 176: VAL Accuracy = 0.813 Loss = 0.405 AUC = 0.819\n",
      "Epoch 177: TRAIN Accuracy = 0.786 Loss = 0.438 AUC = 0.798\n",
      "Epoch 177: VAL Accuracy = 0.8 Loss = 0.424 AUC = 0.827\n",
      "Epoch 178: TRAIN Accuracy = 0.777 Loss = 0.454 AUC = 0.755\n",
      "Epoch 178: VAL Accuracy = 0.78 Loss = 0.438 AUC = 0.822\n",
      "Epoch 179: TRAIN Accuracy = 0.777 Loss = 0.448 AUC = 0.775\n",
      "Epoch 179: VAL Accuracy = 0.787 Loss = 0.431 AUC = 0.812\n",
      "Epoch 180: TRAIN Accuracy = 0.789 Loss = 0.443 AUC = 0.78\n",
      "Epoch 180: VAL Accuracy = 0.8 Loss = 0.419 AUC = 0.834\n",
      "Epoch 181: TRAIN Accuracy = 0.786 Loss = 0.435 AUC = 0.802\n",
      "Epoch 181: VAL Accuracy = 0.8 Loss = 0.417 AUC = 0.832\n",
      "Epoch 182: TRAIN Accuracy = 0.786 Loss = 0.443 AUC = 0.761\n",
      "Epoch 182: VAL Accuracy = 0.8 Loss = 0.418 AUC = 0.822\n",
      "Epoch 183: TRAIN Accuracy = 0.774 Loss = 0.458 AUC = 0.766\n",
      "Epoch 183: VAL Accuracy = 0.78 Loss = 0.442 AUC = 0.781\n",
      "Epoch 184: TRAIN Accuracy = 0.774 Loss = 0.459 AUC = 0.752\n",
      "Epoch 184: VAL Accuracy = 0.8 Loss = 0.428 AUC = 0.784\n",
      "Epoch 185: TRAIN Accuracy = 0.774 Loss = 0.456 AUC = 0.774\n",
      "Epoch 185: VAL Accuracy = 0.8 Loss = 0.42 AUC = 0.788\n",
      "Epoch 186: TRAIN Accuracy = 0.771 Loss = 0.449 AUC = 0.788\n",
      "Epoch 186: VAL Accuracy = 0.8 Loss = 0.419 AUC = 0.797\n",
      "Epoch 187: TRAIN Accuracy = 0.777 Loss = 0.446 AUC = 0.801\n",
      "Epoch 187: VAL Accuracy = 0.8 Loss = 0.419 AUC = 0.801\n",
      "Epoch 188: TRAIN Accuracy = 0.777 Loss = 0.443 AUC = 0.781\n",
      "Epoch 188: VAL Accuracy = 0.8 Loss = 0.418 AUC = 0.792\n",
      "Epoch 189: TRAIN Accuracy = 0.783 Loss = 0.444 AUC = 0.78\n",
      "Epoch 189: VAL Accuracy = 0.8 Loss = 0.419 AUC = 0.792\n",
      "Epoch 190: TRAIN Accuracy = 0.783 Loss = 0.44 AUC = 0.781\n",
      "Epoch 190: VAL Accuracy = 0.8 Loss = 0.42 AUC = 0.785\n",
      "Epoch 191: TRAIN Accuracy = 0.783 Loss = 0.441 AUC = 0.771\n",
      "Epoch 191: VAL Accuracy = 0.793 Loss = 0.424 AUC = 0.776\n",
      "Epoch 192: TRAIN Accuracy = 0.789 Loss = 0.436 AUC = 0.78\n",
      "Epoch 192: VAL Accuracy = 0.8 Loss = 0.43 AUC = 0.816\n",
      "Epoch 193: TRAIN Accuracy = 0.789 Loss = 0.435 AUC = 0.809\n",
      "Epoch 193: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.823\n",
      "Epoch 194: TRAIN Accuracy = 0.803 Loss = 0.424 AUC = 0.82\n",
      "Epoch 194: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.83\n",
      "Epoch 195: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.806\n",
      "Epoch 195: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.835\n",
      "Epoch 196: TRAIN Accuracy = 0.803 Loss = 0.42 AUC = 0.808\n",
      "Epoch 196: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.83\n",
      "Epoch 197: TRAIN Accuracy = 0.8 Loss = 0.426 AUC = 0.765\n",
      "Epoch 197: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 198: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.807\n",
      "Epoch 198: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.82\n",
      "Epoch 199: TRAIN Accuracy = 0.803 Loss = 0.422 AUC = 0.775\n",
      "Epoch 199: VAL Accuracy = 0.813 Loss = 0.399 AUC = 0.818\n",
      "Epoch 200: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.781\n",
      "Epoch 200: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.821\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {(i + 1)}: TRAIN Accuracy = {np.round(epoch_acc[i], 3)} Loss = {np.round(epoch_loss[i], 3)} AUC = {np.round(epoch_auc[i], 3)}\")\n",
    "    print(f\"Epoch {(i + 1)}: VAL Accuracy = {np.round(epoch_val_acc[i], 3)} Loss = {np.round(epoch_val_loss[i], 3)} AUC = {np.round(epoch_val_auc[i], 3)}\")\n",
    "\n",
    "with open(\"./logs/Liquidv3_emb4.txt\", \"w\") as f:\n",
    "    for i in range(NUM_EPOCHS):\n",
    "        f.write(f\"Epoch {(i + 1)}: TRAIN Accuracy = {np.round(epoch_acc[i], 3)} Loss = {np.round(epoch_loss[i], 3)} AUC = {np.round(epoch_auc[i], 3)}\\n\")\n",
    "        f.write(f\"Epoch {(i + 1)}: VAL Accuracy = {np.round(epoch_val_acc[i], 3)} Loss = {np.round(epoch_val_loss[i], 3)} AUC = {np.round(epoch_val_auc[i], 3)}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-signals-_5HxkjSc-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
