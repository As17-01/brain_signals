{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 00:03:25.943562: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-22 00:03:25.960151: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-22 00:03:25.989487: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742591006.017360 1358316 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742591006.025730 1358316 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-22 00:03:26.077007: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GRU, Input, BatchNormalization, Dropout, TimeDistributed\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.keras import LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "NUM_EXPERIMENTS = 5\n",
    "\n",
    "def create_model(train):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train.shape[1], train.shape[2])))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(10, return_sequences=True))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(10, return_sequences=True))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(10, return_sequences=False))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(6, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.003), loss='binary_crossentropy', metrics=[\"accuracy\", AUC(name=\"auc\")])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = [\"ID\"]\n",
    "USER = [\"SubjectID\"]\n",
    "IDS = [\"SubjectID\", \"VideoID\"]\n",
    "TARGET = [\"predefinedlabel\"]\n",
    "FEATURES = [\"Raw\", \"Delta\", \"Theta\", \"Alpha1\", \"Alpha2\", \"Beta1\", \"Beta2\", \"Gamma1\", \"Gamma2\"]\n",
    "LAGS = [1]\n",
    "INIT_SEED = 5412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>...</th>\n",
       "      <th>Raw_1</th>\n",
       "      <th>Delta_1</th>\n",
       "      <th>Theta_1</th>\n",
       "      <th>Alpha1_1</th>\n",
       "      <th>Alpha2_1</th>\n",
       "      <th>Beta1_1</th>\n",
       "      <th>Beta2_1</th>\n",
       "      <th>Gamma1_1</th>\n",
       "      <th>Gamma2_1</th>\n",
       "      <th>predefinedlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>...</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SubjectID    Raw     Delta     Theta    Alpha1   Alpha2    Beta1  \\\n",
       "0   0        0.0  278.0  301963.0   90612.0   33735.0  23991.0  27946.0   \n",
       "1   0        0.0  -50.0   73787.0   28083.0    1439.0   2240.0   2746.0   \n",
       "2   0        0.0  101.0  758353.0  383745.0  201999.0  62107.0  36293.0   \n",
       "\n",
       "      Beta2   Gamma1  ...  Raw_1   Delta_1  Theta_1  Alpha1_1  Alpha2_1  \\\n",
       "0   45097.0  33228.0  ...    0.0       0.0      0.0       0.0       0.0   \n",
       "1    3687.0   5293.0  ...  278.0  301963.0  90612.0   33735.0   23991.0   \n",
       "2  130536.0  57243.0  ...  -50.0   73787.0  28083.0    1439.0    2240.0   \n",
       "\n",
       "   Beta1_1  Beta2_1  Gamma1_1  Gamma2_1  predefinedlabel  \n",
       "0      0.0      0.0       0.0       0.0              0.0  \n",
       "1  27946.0  45097.0   33228.0    8293.0              0.0  \n",
       "2   2746.0   3687.0    5293.0    2740.0              0.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"/home/aseliverstov/projects/brain_signals/data\")\n",
    "data = pd.read_csv(data_dir / \"EEG_data.csv\")\n",
    "\n",
    "new_features = []\n",
    "for lag in LAGS:\n",
    "    for feature_name in FEATURES:\n",
    "        new_feature_name = f\"{feature_name}_{lag}\"\n",
    "        new_features.append(new_feature_name)\n",
    "        data[new_feature_name] = data.groupby(IDS)[feature_name].shift(lag).fillna(0)\n",
    "FEATURES.extend(new_features)\n",
    "\n",
    "data[\"ID\"] = (len(np.unique(data[\"VideoID\"])) * data[\"SubjectID\"] + data[\"VideoID\"]).astype(\"int\")\n",
    "data = data[ID + USER + FEATURES + TARGET]\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(data):\n",
    "    features = []\n",
    "    target = []\n",
    "    for cur_id in np.unique(data[ID].to_numpy()):\n",
    "        cur_id_data = data[data[ID].to_numpy() == cur_id]\n",
    "        target.append(np.mean(cur_id_data[TARGET].to_numpy()).astype(\"int\"))\n",
    "        features.append(cur_id_data[FEATURES].to_numpy())\n",
    "\n",
    "    features = pad_sequences(features)\n",
    "    return np.array(features), np.array(target)\n",
    "\n",
    "def pad_sequences(arrays, pad_value=0):\n",
    "    max_length = max(arr.shape[0] for arr in arrays)\n",
    "    padded_arrays = [\n",
    "        np.pad(\n",
    "            arr,\n",
    "            ((0, max_length - arr.shape[0]), (0, 0)),\n",
    "            mode='constant',\n",
    "            constant_values=pad_value)\n",
    "            for arr in arrays\n",
    "        ]\n",
    "    return np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 00:03:29.443542: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,206</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">870</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">870</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m18\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc (\u001b[38;5;33mLTC\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │         \u001b[38;5;34m1,206\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_1 (\u001b[38;5;33mLTC\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │           \u001b[38;5;34m870\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_2 (\u001b[38;5;33mLTC\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m870\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m7\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,019</span> (11.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,019\u001b[0m (11.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,019</span> (11.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,019\u001b[0m (11.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, _ = reshape_dataset(data)\n",
    "model = create_model(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 844ms/step - accuracy: 0.5471 - auc: 0.6494 - loss: 0.6916 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6959\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.4160 - auc: 0.5337 - loss: 0.7033 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6934\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 567ms/step - accuracy: 0.5258 - auc: 0.4990 - loss: 0.6956 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 572ms/step - accuracy: 0.4188 - auc: 0.4240 - loss: 0.7111 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 959ms/step - accuracy: 0.4200 - auc: 0.4179 - loss: 0.7015 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 681ms/step - accuracy: 0.4549 - auc: 0.4358 - loss: 0.7105 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.6102 - auc: 0.6080 - loss: 0.6848 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 639ms/step - accuracy: 0.4921 - auc: 0.4701 - loss: 0.6925 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 606ms/step - accuracy: 0.5217 - auc: 0.5023 - loss: 0.6987 - val_accuracy: 0.5000 - val_auc: 0.3667 - val_loss: 0.6941\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.4018 - auc: 0.3737 - loss: 0.7009 - val_accuracy: 0.3667 - val_auc: 0.3667 - val_loss: 0.6941\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.5493 - auc: 0.6083 - loss: 0.6879 - val_accuracy: 0.3667 - val_auc: 0.5000 - val_loss: 0.6940\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.6272 - auc: 0.6432 - loss: 0.6822 - val_accuracy: 0.3667 - val_auc: 0.5000 - val_loss: 0.6937\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 862ms/step - accuracy: 0.3813 - auc: 0.3734 - loss: 0.7076 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6927\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.4951 - auc: 0.5003 - loss: 0.6888 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 801ms/step - accuracy: 0.5283 - auc: 0.5344 - loss: 0.6865 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.5818 - auc: 0.6363 - loss: 0.6880 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 712ms/step - accuracy: 0.4738 - auc: 0.4791 - loss: 0.6939 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 766ms/step - accuracy: 0.5599 - auc: 0.5511 - loss: 0.6923 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 778ms/step - accuracy: 0.5174 - auc: 0.5990 - loss: 0.6877 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6908\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 836ms/step - accuracy: 0.4836 - auc: 0.5135 - loss: 0.6900 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6890\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 906ms/step - accuracy: 0.5827 - auc: 0.5391 - loss: 0.6940 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6874\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.6024 - auc: 0.6321 - loss: 0.6812 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6803\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 946ms/step - accuracy: 0.6096 - auc: 0.6773 - loss: 0.6670 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6713\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 958ms/step - accuracy: 0.4681 - auc: 0.4479 - loss: 0.7042 - val_accuracy: 0.7333 - val_auc: 0.7333 - val_loss: 0.6664\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4072 - auc: 0.4070 - loss: 0.7181 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.6584\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 826ms/step - accuracy: 0.7359 - auc: 0.7393 - loss: 0.6485 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.6343\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 780ms/step - accuracy: 0.5799 - auc: 0.6319 - loss: 0.6714 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.5921\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.6526 - auc: 0.6120 - loss: 0.6637 - val_accuracy: 0.8000 - val_auc: 0.7889 - val_loss: 0.5672\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 822ms/step - accuracy: 0.7026 - auc: 0.7260 - loss: 0.6196 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.5031\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 769ms/step - accuracy: 0.7124 - auc: 0.7877 - loss: 0.5614 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4591\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 773ms/step - accuracy: 0.7460 - auc: 0.7550 - loss: 0.5492 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4356\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 957ms/step - accuracy: 0.7460 - auc: 0.7389 - loss: 0.5398 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4094\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.7615 - auc: 0.6930 - loss: 0.5218 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3973\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7957 - loss: 0.5005 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3895\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 899ms/step - accuracy: 0.7615 - auc: 0.6846 - loss: 0.5179 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3903\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 915ms/step - accuracy: 0.7460 - auc: 0.6702 - loss: 0.5404 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3902\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 795ms/step - accuracy: 0.7579 - auc: 0.7576 - loss: 0.4965 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3837\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.7615 - auc: 0.8351 - loss: 0.4672 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3800\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.7579 - auc: 0.7396 - loss: 0.5116 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3801\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 793ms/step - accuracy: 0.7615 - auc: 0.7914 - loss: 0.4868 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3810\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900ms/step - accuracy: 0.7341 - auc: 0.6516 - loss: 0.5160 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3833\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 871ms/step - accuracy: 0.7615 - auc: 0.7954 - loss: 0.4737 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3820\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 903ms/step - accuracy: 0.7615 - auc: 0.7699 - loss: 0.4901 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3801\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890ms/step - accuracy: 0.7615 - auc: 0.7495 - loss: 0.4868 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3798\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 758ms/step - accuracy: 0.7615 - auc: 0.7720 - loss: 0.4618 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 947ms/step - accuracy: 0.7347 - auc: 0.7787 - loss: 0.4997 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.6520 - auc: 0.6544 - loss: 0.6081 - val_accuracy: 0.7333 - val_auc: 0.7333 - val_loss: 0.5026\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 775ms/step - accuracy: 0.6267 - auc: 0.7158 - loss: 0.5932 - val_accuracy: 0.7333 - val_auc: 0.7333 - val_loss: 0.5007\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 797ms/step - accuracy: 0.6827 - auc: 0.7040 - loss: 0.5701 - val_accuracy: 0.7333 - val_auc: 0.6333 - val_loss: 0.4973\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 821ms/step - accuracy: 0.6777 - auc: 0.7053 - loss: 0.5820 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4855\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.6533 - auc: 0.6823 - loss: 0.5728 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4641\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867ms/step - accuracy: 0.6777 - auc: 0.7431 - loss: 0.5448 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3950\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.7491 - auc: 0.6941 - loss: 0.5078 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3916\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.7615 - auc: 0.8134 - loss: 0.4745 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3859\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 789ms/step - accuracy: 0.7243 - auc: 0.7459 - loss: 0.5055 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4082\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 806ms/step - accuracy: 0.7044 - auc: 0.7381 - loss: 0.5508 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4801\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 861ms/step - accuracy: 0.7199 - auc: 0.6857 - loss: 0.5520 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3860\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 905ms/step - accuracy: 0.7398 - auc: 0.7668 - loss: 0.4985 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3865\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 782ms/step - accuracy: 0.7957 - auc: 0.8243 - loss: 0.4569 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3890\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 960ms/step - accuracy: 0.7615 - auc: 0.6822 - loss: 0.5107 - val_accuracy: 0.8000 - val_auc: 0.8222 - val_loss: 0.3925\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 833ms/step - accuracy: 0.7615 - auc: 0.6908 - loss: 0.5018 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3855\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.7615 - auc: 0.7902 - loss: 0.4721 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3771\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.7615 - auc: 0.7901 - loss: 0.4812 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3759\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 905ms/step - accuracy: 0.7615 - auc: 0.8020 - loss: 0.4690 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3759\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 899ms/step - accuracy: 0.7615 - auc: 0.7169 - loss: 0.4863 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3778\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 814ms/step - accuracy: 0.7615 - auc: 0.6942 - loss: 0.4911 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3794\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 816ms/step - accuracy: 0.7615 - auc: 0.7520 - loss: 0.4790 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3792\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 794ms/step - accuracy: 0.7615 - auc: 0.7311 - loss: 0.4876 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3784\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.7615 - auc: 0.7064 - loss: 0.4918 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3782\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.7615 - auc: 0.6052 - loss: 0.5269 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3791\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 784ms/step - accuracy: 0.7615 - auc: 0.7753 - loss: 0.4753 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3791\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 907ms/step - accuracy: 0.7615 - auc: 0.7707 - loss: 0.4770 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3781\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 908ms/step - accuracy: 0.7615 - auc: 0.6789 - loss: 0.4939 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3775\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 852ms/step - accuracy: 0.7362 - auc: 0.7310 - loss: 0.5409 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4648\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 950ms/step - accuracy: 0.6715 - auc: 0.6700 - loss: 0.5877 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4761\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774ms/step - accuracy: 0.7172 - auc: 0.7905 - loss: 0.5375 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3979\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 893ms/step - accuracy: 0.7579 - auc: 0.6895 - loss: 0.5198 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3847\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.7615 - auc: 0.7042 - loss: 0.4928 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3859\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.7615 - auc: 0.6552 - loss: 0.4984 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3818\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 906ms/step - accuracy: 0.7615 - auc: 0.8131 - loss: 0.4668 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3786\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.7615 - auc: 0.8138 - loss: 0.4704 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3773\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 813ms/step - accuracy: 0.7615 - auc: 0.7191 - loss: 0.4919 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3782\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864ms/step - accuracy: 0.7615 - auc: 0.7869 - loss: 0.4706 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3783\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.7615 - auc: 0.7217 - loss: 0.4990 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3799\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.7615 - auc: 0.7531 - loss: 0.4705 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3808\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 791ms/step - accuracy: 0.7615 - auc: 0.6250 - loss: 0.4991 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3819\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 801ms/step - accuracy: 0.7615 - auc: 0.6939 - loss: 0.4839 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3817\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 900ms/step - accuracy: 0.7615 - auc: 0.8335 - loss: 0.4618 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3797\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 812ms/step - accuracy: 0.7615 - auc: 0.7784 - loss: 0.4820 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 816ms/step - accuracy: 0.7615 - auc: 0.7911 - loss: 0.4689 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3783\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 891ms/step - accuracy: 0.7615 - auc: 0.7305 - loss: 0.4844 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3781\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 798ms/step - accuracy: 0.7615 - auc: 0.7354 - loss: 0.4858 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3778\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 886ms/step - accuracy: 0.7615 - auc: 0.7259 - loss: 0.4932 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3785\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.7615 - auc: 0.7584 - loss: 0.4850 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3797\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 817ms/step - accuracy: 0.7615 - auc: 0.7370 - loss: 0.4820 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3805\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 898ms/step - accuracy: 0.7615 - auc: 0.7252 - loss: 0.4757 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 802ms/step - accuracy: 0.7615 - auc: 0.7843 - loss: 0.4740 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 796ms/step - accuracy: 0.7615 - auc: 0.7000 - loss: 0.4944 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 797ms/step - accuracy: 0.7615 - auc: 0.7315 - loss: 0.4935 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 795ms/step - accuracy: 0.7615 - auc: 0.6773 - loss: 0.4984 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 918ms/step - accuracy: 0.7615 - auc: 0.7842 - loss: 0.4695 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 795ms/step - accuracy: 0.7615 - auc: 0.6929 - loss: 0.4913 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 884ms/step - accuracy: 0.7615 - auc: 0.6790 - loss: 0.5004 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 840ms/step - accuracy: 0.7615 - auc: 0.7783 - loss: 0.4737 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 798ms/step - accuracy: 0.7615 - auc: 0.7327 - loss: 0.4820 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 881ms/step - accuracy: 0.7615 - auc: 0.8612 - loss: 0.4673 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3781\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.7615 - auc: 0.7439 - loss: 0.4811 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3790\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.7615 - auc: 0.8097 - loss: 0.4619 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 791ms/step - accuracy: 0.7615 - auc: 0.7667 - loss: 0.4679 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3785\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 791ms/step - accuracy: 0.7615 - auc: 0.7422 - loss: 0.4822 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3782\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882ms/step - accuracy: 0.7615 - auc: 0.7335 - loss: 0.4835 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3786\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.7615 - auc: 0.7683 - loss: 0.4878 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3783\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 898ms/step - accuracy: 0.7615 - auc: 0.7759 - loss: 0.4722 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.7615 - auc: 0.7996 - loss: 0.4693 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.7615 - auc: 0.8616 - loss: 0.4562 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.7615 - auc: 0.7582 - loss: 0.4822 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893ms/step - accuracy: 0.7615 - auc: 0.6640 - loss: 0.4993 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882ms/step - accuracy: 0.7615 - auc: 0.6994 - loss: 0.4855 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3786\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 881ms/step - accuracy: 0.7615 - auc: 0.7936 - loss: 0.4723 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 806ms/step - accuracy: 0.7615 - auc: 0.7115 - loss: 0.4853 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3799\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 888ms/step - accuracy: 0.7615 - auc: 0.7214 - loss: 0.4809 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792ms/step - accuracy: 0.7615 - auc: 0.6996 - loss: 0.4848 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3787\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 802ms/step - accuracy: 0.7615 - auc: 0.7531 - loss: 0.4681 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 754ms/step - accuracy: 0.7615 - auc: 0.7595 - loss: 0.4756 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.7615 - auc: 0.7033 - loss: 0.4880 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.7615 - auc: 0.6811 - loss: 0.4911 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 808ms/step - accuracy: 0.7615 - auc: 0.7413 - loss: 0.4894 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 927ms/step - accuracy: 0.7615 - auc: 0.7365 - loss: 0.4813 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3785\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 829ms/step - accuracy: 0.7615 - auc: 0.7368 - loss: 0.4860 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3800\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 790ms/step - accuracy: 0.7615 - auc: 0.7872 - loss: 0.4754 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3812\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 881ms/step - accuracy: 0.7615 - auc: 0.7293 - loss: 0.4806 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3811\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 888ms/step - accuracy: 0.7615 - auc: 0.7945 - loss: 0.4726 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3803\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893ms/step - accuracy: 0.7615 - auc: 0.7685 - loss: 0.4780 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3790\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 775ms/step - accuracy: 0.7615 - auc: 0.7668 - loss: 0.4782 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3784\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 763ms/step - accuracy: 0.7615 - auc: 0.8719 - loss: 0.4563 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867ms/step - accuracy: 0.7615 - auc: 0.8471 - loss: 0.4543 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864ms/step - accuracy: 0.7615 - auc: 0.6178 - loss: 0.5125 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3777\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 859ms/step - accuracy: 0.7615 - auc: 0.7316 - loss: 0.4836 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3784\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883ms/step - accuracy: 0.7615 - auc: 0.6762 - loss: 0.4945 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3786\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 885ms/step - accuracy: 0.7615 - auc: 0.6672 - loss: 0.4987 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3786\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 898ms/step - accuracy: 0.7615 - auc: 0.7512 - loss: 0.4760 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3783\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875ms/step - accuracy: 0.7615 - auc: 0.7283 - loss: 0.4842 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 865ms/step - accuracy: 0.7615 - auc: 0.7708 - loss: 0.4801 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3781\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 769ms/step - accuracy: 0.7615 - auc: 0.7270 - loss: 0.4862 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3788\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 768ms/step - accuracy: 0.7615 - auc: 0.8290 - loss: 0.4710 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3791\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 826ms/step - accuracy: 0.7615 - auc: 0.7124 - loss: 0.4873 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3797\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 948ms/step - accuracy: 0.7615 - auc: 0.7493 - loss: 0.4816 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3796\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 900ms/step - accuracy: 0.7615 - auc: 0.7184 - loss: 0.4896 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3782\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.7615 - auc: 0.7226 - loss: 0.4833 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3786\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 812ms/step - accuracy: 0.7615 - auc: 0.7836 - loss: 0.4751 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3795\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 884ms/step - accuracy: 0.7615 - auc: 0.7342 - loss: 0.4838 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3795\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809ms/step - accuracy: 0.7615 - auc: 0.7067 - loss: 0.4853 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3786\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 898ms/step - accuracy: 0.7615 - auc: 0.7058 - loss: 0.4891 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3779\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 909ms/step - accuracy: 0.7615 - auc: 0.6910 - loss: 0.4874 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3770\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.7615 - auc: 0.7136 - loss: 0.4818 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3766\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 925ms/step - accuracy: 0.7615 - auc: 0.7484 - loss: 0.4850 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.7615 - auc: 0.7162 - loss: 0.4865 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3774\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 771ms/step - accuracy: 0.7615 - auc: 0.8605 - loss: 0.4630 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3776\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 888ms/step - accuracy: 0.7615 - auc: 0.7874 - loss: 0.4712 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3772\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 949ms/step - accuracy: 0.7615 - auc: 0.8166 - loss: 0.4892 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 922ms/step - accuracy: 0.7615 - auc: 0.7584 - loss: 0.4779 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3768\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 922ms/step - accuracy: 0.7558 - auc: 0.7609 - loss: 0.4837 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3773\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 785ms/step - accuracy: 0.7615 - auc: 0.5877 - loss: 0.5036 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3809\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 777ms/step - accuracy: 0.7080 - auc: 0.6211 - loss: 0.5607 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3802\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 797ms/step - accuracy: 0.7615 - auc: 0.7653 - loss: 0.4728 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3838\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.7501 - auc: 0.7056 - loss: 0.5067 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3807\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 921ms/step - accuracy: 0.7615 - auc: 0.6609 - loss: 0.4931 - val_accuracy: 0.7333 - val_auc: 0.6333 - val_loss: 0.5029\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.6967 - auc: 0.7106 - loss: 0.5543 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4789\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 788ms/step - accuracy: 0.7243 - auc: 0.7928 - loss: 0.5175 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3819\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 887ms/step - accuracy: 0.7615 - auc: 0.7961 - loss: 0.4659 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3805\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 919ms/step - accuracy: 0.7615 - auc: 0.8150 - loss: 0.4767 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3791\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 903ms/step - accuracy: 0.7615 - auc: 0.6616 - loss: 0.5021 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3787\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 827ms/step - accuracy: 0.7615 - auc: 0.7045 - loss: 0.4845 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3791\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 938ms/step - accuracy: 0.7615 - auc: 0.8344 - loss: 0.4754 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3797\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.7615 - auc: 0.8044 - loss: 0.4668 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3790\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.7615 - auc: 0.7240 - loss: 0.4916 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3792\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 894ms/step - accuracy: 0.7615 - auc: 0.7248 - loss: 0.4752 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3794\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 908ms/step - accuracy: 0.7615 - auc: 0.8297 - loss: 0.4716 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3787\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 907ms/step - accuracy: 0.7615 - auc: 0.6900 - loss: 0.4874 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3784\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 903ms/step - accuracy: 0.7615 - auc: 0.7146 - loss: 0.4870 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3776\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.7615 - auc: 0.8215 - loss: 0.4703 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3767\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 803ms/step - accuracy: 0.7615 - auc: 0.7245 - loss: 0.4877 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 778ms/step - accuracy: 0.7615 - auc: 0.8575 - loss: 0.4635 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3767\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 795ms/step - accuracy: 0.7615 - auc: 0.8114 - loss: 0.4716 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 889ms/step - accuracy: 0.7615 - auc: 0.7776 - loss: 0.4657 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3763\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 822ms/step - accuracy: 0.7615 - auc: 0.8214 - loss: 0.4851 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3759\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 812ms/step - accuracy: 0.7615 - auc: 0.6845 - loss: 0.4962 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3762\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 893ms/step - accuracy: 0.7615 - auc: 0.6831 - loss: 0.4865 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.7615 - auc: 0.8483 - loss: 0.4560 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 798ms/step - accuracy: 0.7615 - auc: 0.8115 - loss: 0.4665 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3765\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 834ms/step - accuracy: 0.7615 - auc: 0.7301 - loss: 0.4844 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3762\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 808ms/step - accuracy: 0.7615 - auc: 0.6396 - loss: 0.5001 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3770\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.7615 - auc: 0.6293 - loss: 0.4914 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3780\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 906ms/step - accuracy: 0.7615 - auc: 0.6831 - loss: 0.4954 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3795\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 920ms/step - accuracy: 0.7615 - auc: 0.6987 - loss: 0.4827 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3806\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 801ms/step - accuracy: 0.7615 - auc: 0.7804 - loss: 0.4719 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3807\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.7615 - auc: 0.8663 - loss: 0.4634 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3788\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 787ms/step - accuracy: 0.7615 - auc: 0.8344 - loss: 0.4696 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3772\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 783ms/step - accuracy: 0.7615 - auc: 0.7710 - loss: 0.4738 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3762\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.7615 - auc: 0.7912 - loss: 0.4769 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [24:46, 1486.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.5668 - auc: 0.6065 - loss: 0.6795 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6958\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 778ms/step - accuracy: 0.5753 - auc: 0.5773 - loss: 0.6775 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6875\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 794ms/step - accuracy: 0.5689 - auc: 0.5967 - loss: 0.6751 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6910\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 885ms/step - accuracy: 0.4177 - auc: 0.3689 - loss: 0.7085 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6870\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 838ms/step - accuracy: 0.6362 - auc: 0.6132 - loss: 0.6781 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6843\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 891ms/step - accuracy: 0.5374 - auc: 0.4953 - loss: 0.6850 - val_accuracy: 0.5000 - val_auc: 0.7000 - val_loss: 0.6849\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 970ms/step - accuracy: 0.6016 - auc: 0.6132 - loss: 0.6764 - val_accuracy: 0.5000 - val_auc: 0.7000 - val_loss: 0.6818\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774ms/step - accuracy: 0.5112 - auc: 0.5482 - loss: 0.6854 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6827\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 816ms/step - accuracy: 0.5372 - auc: 0.6039 - loss: 0.6780 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6834\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 780ms/step - accuracy: 0.5154 - auc: 0.5615 - loss: 0.6792 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6791\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 898ms/step - accuracy: 0.5749 - auc: 0.6023 - loss: 0.6803 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6694\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 806ms/step - accuracy: 0.5205 - auc: 0.6253 - loss: 0.6759 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6601\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.4012 - auc: 0.4154 - loss: 0.7034 - val_accuracy: 0.6000 - val_auc: 0.8000 - val_loss: 0.6584\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 846ms/step - accuracy: 0.5407 - auc: 0.4649 - loss: 0.7017 - val_accuracy: 0.6000 - val_auc: 0.8000 - val_loss: 0.6534\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 911ms/step - accuracy: 0.5327 - auc: 0.6458 - loss: 0.6650 - val_accuracy: 0.7000 - val_auc: 0.7867 - val_loss: 0.6244\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.6043 - auc: 0.6359 - loss: 0.6573 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.5903\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 846ms/step - accuracy: 0.7428 - auc: 0.7677 - loss: 0.5992 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.5464\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.7064 - auc: 0.7752 - loss: 0.5669 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.5175\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.7475 - auc: 0.8094 - loss: 0.5284 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4892\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 814ms/step - accuracy: 0.7783 - auc: 0.8333 - loss: 0.4989 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4802\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 873ms/step - accuracy: 0.7631 - auc: 0.7256 - loss: 0.5334 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.4647\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 910ms/step - accuracy: 0.7245 - auc: 0.8861 - loss: 0.4785 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4650\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 921ms/step - accuracy: 0.6761 - auc: 0.8594 - loss: 0.5287 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4387\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 803ms/step - accuracy: 0.7667 - auc: 0.7967 - loss: 0.4655 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.4504\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 897ms/step - accuracy: 0.7513 - auc: 0.7300 - loss: 0.4878 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4652\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 792ms/step - accuracy: 0.6743 - auc: 0.7201 - loss: 0.5776 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4498\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890ms/step - accuracy: 0.7585 - auc: 0.7801 - loss: 0.4898 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4350\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 814ms/step - accuracy: 0.7349 - auc: 0.7827 - loss: 0.4561 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4264\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 963ms/step - accuracy: 0.7513 - auc: 0.8072 - loss: 0.4654 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4345\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809ms/step - accuracy: 0.7513 - auc: 0.7789 - loss: 0.4909 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4244\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 954ms/step - accuracy: 0.7667 - auc: 0.7568 - loss: 0.4653 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4245\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 835ms/step - accuracy: 0.7667 - auc: 0.7288 - loss: 0.4721 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4226\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 884ms/step - accuracy: 0.7667 - auc: 0.7568 - loss: 0.4869 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4346\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.7667 - auc: 0.7350 - loss: 0.5029 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4291\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.7325 - auc: 0.8989 - loss: 0.4645 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4230\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 942ms/step - accuracy: 0.7518 - auc: 0.8095 - loss: 0.4556 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4239\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 813ms/step - accuracy: 0.7667 - auc: 0.8546 - loss: 0.4283 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4218\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 781ms/step - accuracy: 0.7667 - auc: 0.7708 - loss: 0.4622 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4215\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 834ms/step - accuracy: 0.7450 - auc: 0.6880 - loss: 0.5047 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4208\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.7667 - auc: 0.7789 - loss: 0.4800 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4204\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 907ms/step - accuracy: 0.7667 - auc: 0.7514 - loss: 0.4744 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4202\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 897ms/step - accuracy: 0.7667 - auc: 0.8394 - loss: 0.4415 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4202\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.7498 - auc: 0.7883 - loss: 0.4718 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4210\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 841ms/step - accuracy: 0.7667 - auc: 0.8973 - loss: 0.4352 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4236\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.7667 - auc: 0.7899 - loss: 0.4670 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4198\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 824ms/step - accuracy: 0.7667 - auc: 0.7664 - loss: 0.4479 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4214\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.7513 - auc: 0.6698 - loss: 0.4856 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4224\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.7513 - auc: 0.7118 - loss: 0.4787 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4289\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 908ms/step - accuracy: 0.7513 - auc: 0.8158 - loss: 0.4949 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4220\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 814ms/step - accuracy: 0.7667 - auc: 0.6735 - loss: 0.5026 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 802ms/step - accuracy: 0.7667 - auc: 0.7954 - loss: 0.4530 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4194\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 910ms/step - accuracy: 0.7667 - auc: 0.7720 - loss: 0.4515 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4196\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.7667 - auc: 0.7051 - loss: 0.4648 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4195\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.7667 - auc: 0.7630 - loss: 0.4507 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4193\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 807ms/step - accuracy: 0.7667 - auc: 0.7660 - loss: 0.4503 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4192\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 892ms/step - accuracy: 0.7667 - auc: 0.7726 - loss: 0.4464 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.7667 - auc: 0.7461 - loss: 0.4553 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 786ms/step - accuracy: 0.7667 - auc: 0.7340 - loss: 0.4604 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 808ms/step - accuracy: 0.7631 - auc: 0.7897 - loss: 0.4504 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.7667 - auc: 0.7657 - loss: 0.4540 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4194\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 869ms/step - accuracy: 0.7667 - auc: 0.7561 - loss: 0.4648 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787ms/step - accuracy: 0.7667 - auc: 0.7112 - loss: 0.4763 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.7667 - auc: 0.7354 - loss: 0.4704 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4190\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 810ms/step - accuracy: 0.7667 - auc: 0.7637 - loss: 0.4537 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 843ms/step - accuracy: 0.7667 - auc: 0.7759 - loss: 0.4515 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.7667 - auc: 0.8225 - loss: 0.4439 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.7667 - auc: 0.7156 - loss: 0.4650 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865ms/step - accuracy: 0.7667 - auc: 0.7916 - loss: 0.4505 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.7667 - auc: 0.7916 - loss: 0.4438 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4192\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 924ms/step - accuracy: 0.7667 - auc: 0.7663 - loss: 0.4648 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 764ms/step - accuracy: 0.7667 - auc: 0.7697 - loss: 0.4492 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 791ms/step - accuracy: 0.7667 - auc: 0.7021 - loss: 0.4733 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.7667 - auc: 0.8549 - loss: 0.4399 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 845ms/step - accuracy: 0.7667 - auc: 0.8817 - loss: 0.4295 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.7667 - auc: 0.6797 - loss: 0.4710 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4198\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 930ms/step - accuracy: 0.7513 - auc: 0.6838 - loss: 0.4863 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.7667 - auc: 0.8076 - loss: 0.4366 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 895ms/step - accuracy: 0.7667 - auc: 0.8008 - loss: 0.4460 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 897ms/step - accuracy: 0.7667 - auc: 0.7555 - loss: 0.4646 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.4793\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 951ms/step - accuracy: 0.7287 - auc: 0.7692 - loss: 0.5531 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5421\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.6352 - auc: 0.6868 - loss: 0.6070 - val_accuracy: 0.7000 - val_auc: 0.7000 - val_loss: 0.5967\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.5749 - auc: 0.5888 - loss: 0.6895 - val_accuracy: 0.7000 - val_auc: 0.6000 - val_loss: 0.5593\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6217 - auc: 0.6418 - loss: 0.6131 - val_accuracy: 0.7000 - val_auc: 0.7000 - val_loss: 0.5348\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 918ms/step - accuracy: 0.6434 - auc: 0.7037 - loss: 0.5674 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5281\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 965ms/step - accuracy: 0.6954 - auc: 0.7674 - loss: 0.5251 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4493\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 796ms/step - accuracy: 0.7400 - auc: 0.7369 - loss: 0.4845 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5216\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 774ms/step - accuracy: 0.6588 - auc: 0.6766 - loss: 0.5607 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5231\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 780ms/step - accuracy: 0.6490 - auc: 0.8078 - loss: 0.5503 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4414\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 757ms/step - accuracy: 0.7667 - auc: 0.7627 - loss: 0.4705 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4247\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 782ms/step - accuracy: 0.7287 - auc: 0.8100 - loss: 0.4785 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4673\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.6743 - auc: 0.8058 - loss: 0.5322 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5232\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 900ms/step - accuracy: 0.6645 - auc: 0.6685 - loss: 0.5637 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5066\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 781ms/step - accuracy: 0.6862 - auc: 0.7929 - loss: 0.5346 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4315\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 761ms/step - accuracy: 0.7667 - auc: 0.7628 - loss: 0.4569 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4204\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 763ms/step - accuracy: 0.7667 - auc: 0.7294 - loss: 0.4480 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4198\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 875ms/step - accuracy: 0.7667 - auc: 0.7442 - loss: 0.4537 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4199\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 861ms/step - accuracy: 0.7513 - auc: 0.7526 - loss: 0.4578 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 763ms/step - accuracy: 0.7667 - auc: 0.7739 - loss: 0.4495 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4202\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.7667 - auc: 0.7793 - loss: 0.4627 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4194\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 844ms/step - accuracy: 0.7667 - auc: 0.6894 - loss: 0.4658 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759ms/step - accuracy: 0.7667 - auc: 0.8551 - loss: 0.4351 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4191\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 863ms/step - accuracy: 0.7667 - auc: 0.7565 - loss: 0.4686 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4192\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.7667 - auc: 0.7889 - loss: 0.4510 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4192\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.7667 - auc: 0.8652 - loss: 0.4399 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4192\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 764ms/step - accuracy: 0.7667 - auc: 0.7631 - loss: 0.4496 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4192\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 885ms/step - accuracy: 0.7667 - auc: 0.7862 - loss: 0.4527 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4191\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 769ms/step - accuracy: 0.7667 - auc: 0.7417 - loss: 0.4527 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4190\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 925ms/step - accuracy: 0.7667 - auc: 0.8138 - loss: 0.4385 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 966ms/step - accuracy: 0.7667 - auc: 0.7951 - loss: 0.4456 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.7667 - auc: 0.8152 - loss: 0.4416 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900ms/step - accuracy: 0.7667 - auc: 0.7365 - loss: 0.4574 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 864ms/step - accuracy: 0.7667 - auc: 0.7628 - loss: 0.4668 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 867ms/step - accuracy: 0.7667 - auc: 0.7957 - loss: 0.4361 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4192\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 766ms/step - accuracy: 0.7667 - auc: 0.8143 - loss: 0.4609 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 806ms/step - accuracy: 0.7667 - auc: 0.8413 - loss: 0.4362 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4192\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867ms/step - accuracy: 0.7667 - auc: 0.8141 - loss: 0.4433 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 831ms/step - accuracy: 0.7667 - auc: 0.7143 - loss: 0.4651 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.7667 - auc: 0.7847 - loss: 0.4464 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.7667 - auc: 0.6848 - loss: 0.4690 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 796ms/step - accuracy: 0.7667 - auc: 0.8910 - loss: 0.4346 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.7667 - auc: 0.7937 - loss: 0.4464 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 922ms/step - accuracy: 0.7667 - auc: 0.8070 - loss: 0.4439 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 898ms/step - accuracy: 0.7667 - auc: 0.6678 - loss: 0.4826 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 808ms/step - accuracy: 0.7667 - auc: 0.7803 - loss: 0.4462 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.7667 - auc: 0.8174 - loss: 0.4446 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 862ms/step - accuracy: 0.7667 - auc: 0.7668 - loss: 0.4449 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.7667 - auc: 0.7928 - loss: 0.4541 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 780ms/step - accuracy: 0.7667 - auc: 0.7991 - loss: 0.4527 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 782ms/step - accuracy: 0.7667 - auc: 0.7713 - loss: 0.4466 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.7667 - auc: 0.8495 - loss: 0.4333 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.7667 - auc: 0.8294 - loss: 0.4418 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 758ms/step - accuracy: 0.7667 - auc: 0.8115 - loss: 0.4488 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 844ms/step - accuracy: 0.7667 - auc: 0.8092 - loss: 0.4472 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4189\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.7667 - auc: 0.7713 - loss: 0.4542 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4189\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 761ms/step - accuracy: 0.7667 - auc: 0.8402 - loss: 0.4398 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4190\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.7667 - auc: 0.7574 - loss: 0.4591 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4189\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 873ms/step - accuracy: 0.7667 - auc: 0.8405 - loss: 0.4375 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4189\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 791ms/step - accuracy: 0.7667 - auc: 0.6678 - loss: 0.4679 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 868ms/step - accuracy: 0.7667 - auc: 0.7981 - loss: 0.4496 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4186\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809ms/step - accuracy: 0.7667 - auc: 0.7002 - loss: 0.4597 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4186\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.7667 - auc: 0.8066 - loss: 0.4450 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 764ms/step - accuracy: 0.7667 - auc: 0.7541 - loss: 0.4505 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 881ms/step - accuracy: 0.7667 - auc: 0.8537 - loss: 0.4367 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4186\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 785ms/step - accuracy: 0.7667 - auc: 0.7383 - loss: 0.4532 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4186\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 895ms/step - accuracy: 0.7667 - auc: 0.7719 - loss: 0.4531 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4186\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 862ms/step - accuracy: 0.7667 - auc: 0.8149 - loss: 0.4459 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.7667 - auc: 0.8118 - loss: 0.4462 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.7667 - auc: 0.7765 - loss: 0.4460 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4186\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 944ms/step - accuracy: 0.7667 - auc: 0.7894 - loss: 0.4578 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 785ms/step - accuracy: 0.7667 - auc: 0.6935 - loss: 0.4633 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759ms/step - accuracy: 0.7667 - auc: 0.7964 - loss: 0.4462 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4181\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 801ms/step - accuracy: 0.7667 - auc: 0.8079 - loss: 0.4566 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4181\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 882ms/step - accuracy: 0.7667 - auc: 0.7972 - loss: 0.4479 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4183\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 770ms/step - accuracy: 0.7667 - auc: 0.7887 - loss: 0.4463 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4182\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 798ms/step - accuracy: 0.7554 - auc: 0.8572 - loss: 0.4521 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4195\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 808ms/step - accuracy: 0.7667 - auc: 0.7265 - loss: 0.4617 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4205\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 788ms/step - accuracy: 0.7513 - auc: 0.7473 - loss: 0.4952 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 811ms/step - accuracy: 0.7667 - auc: 0.7485 - loss: 0.4536 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4186\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 752ms/step - accuracy: 0.7667 - auc: 0.7945 - loss: 0.4357 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 862ms/step - accuracy: 0.7667 - auc: 0.7525 - loss: 0.4485 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.7667 - auc: 0.7033 - loss: 0.4635 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.7667 - auc: 0.7802 - loss: 0.4450 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 762ms/step - accuracy: 0.7667 - auc: 0.8198 - loss: 0.4459 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 821ms/step - accuracy: 0.7667 - auc: 0.7527 - loss: 0.4510 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.7667 - auc: 0.7210 - loss: 0.4563 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 769ms/step - accuracy: 0.7667 - auc: 0.7545 - loss: 0.4536 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 769ms/step - accuracy: 0.7667 - auc: 0.7517 - loss: 0.4491 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 797ms/step - accuracy: 0.7667 - auc: 0.8135 - loss: 0.4453 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 786ms/step - accuracy: 0.7667 - auc: 0.8188 - loss: 0.4401 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 798ms/step - accuracy: 0.7667 - auc: 0.7177 - loss: 0.4608 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4183\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 788ms/step - accuracy: 0.7667 - auc: 0.8178 - loss: 0.4433 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4183\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 756ms/step - accuracy: 0.7667 - auc: 0.7973 - loss: 0.4418 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937ms/step - accuracy: 0.7667 - auc: 0.7757 - loss: 0.4471 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4185\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890ms/step - accuracy: 0.7667 - auc: 0.7341 - loss: 0.4677 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875ms/step - accuracy: 0.7667 - auc: 0.7661 - loss: 0.4544 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4179\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 768ms/step - accuracy: 0.7667 - auc: 0.7326 - loss: 0.4581 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 907ms/step - accuracy: 0.7667 - auc: 0.7867 - loss: 0.4508 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 840ms/step - accuracy: 0.7667 - auc: 0.8991 - loss: 0.4304 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4176\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 914ms/step - accuracy: 0.7667 - auc: 0.8348 - loss: 0.4443 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 891ms/step - accuracy: 0.7667 - auc: 0.7206 - loss: 0.4618 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4176\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.7667 - auc: 0.8290 - loss: 0.4430 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4175\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 929ms/step - accuracy: 0.7667 - auc: 0.7665 - loss: 0.4580 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4173\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 769ms/step - accuracy: 0.7667 - auc: 0.7619 - loss: 0.4547 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4178\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.7667 - auc: 0.7929 - loss: 0.4432 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4180\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 825ms/step - accuracy: 0.7667 - auc: 0.7716 - loss: 0.4478 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4180\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 856ms/step - accuracy: 0.7667 - auc: 0.8249 - loss: 0.4368 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4179\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.7667 - auc: 0.6900 - loss: 0.4580 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4178\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 806ms/step - accuracy: 0.7667 - auc: 0.7909 - loss: 0.4459 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4178\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 778ms/step - accuracy: 0.7667 - auc: 0.8460 - loss: 0.4371 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4178\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.7667 - auc: 0.8413 - loss: 0.4387 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4178\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 763ms/step - accuracy: 0.7667 - auc: 0.8121 - loss: 0.4377 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4178\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 889ms/step - accuracy: 0.7667 - auc: 0.7500 - loss: 0.4524 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4178\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 819ms/step - accuracy: 0.7667 - auc: 0.8507 - loss: 0.4398 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 805ms/step - accuracy: 0.7667 - auc: 0.8235 - loss: 0.4437 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937ms/step - accuracy: 0.7667 - auc: 0.8325 - loss: 0.4399 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4178\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 789ms/step - accuracy: 0.7667 - auc: 0.8064 - loss: 0.4493 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 761ms/step - accuracy: 0.7667 - auc: 0.7453 - loss: 0.4506 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 887ms/step - accuracy: 0.7667 - auc: 0.7811 - loss: 0.4505 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4176\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 810ms/step - accuracy: 0.7667 - auc: 0.8275 - loss: 0.4387 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4175\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 776ms/step - accuracy: 0.7667 - auc: 0.7225 - loss: 0.4548 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [49:11, 1473.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.5663 - auc: 0.6518 - loss: 0.6619 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.7005\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 901ms/step - accuracy: 0.5641 - auc: 0.5025 - loss: 0.6886 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6900\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.6212 - auc: 0.6070 - loss: 0.6737 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6910\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 972ms/step - accuracy: 0.5356 - auc: 0.5690 - loss: 0.6836 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6939\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 905ms/step - accuracy: 0.4574 - auc: 0.5041 - loss: 0.7009 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6934\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.3546 - auc: 0.4964 - loss: 0.7105 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6924\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 937ms/step - accuracy: 0.5264 - auc: 0.5308 - loss: 0.6931 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6918\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 984ms/step - accuracy: 0.5354 - auc: 0.5063 - loss: 0.6926 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6907\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 874ms/step - accuracy: 0.3958 - auc: 0.4056 - loss: 0.7051 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6895\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 888ms/step - accuracy: 0.5096 - auc: 0.5322 - loss: 0.6841 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6886\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 973ms/step - accuracy: 0.5393 - auc: 0.5932 - loss: 0.6743 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6881\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 910ms/step - accuracy: 0.6597 - auc: 0.6678 - loss: 0.6779 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6858\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.4943 - auc: 0.5687 - loss: 0.6899 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6823\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893ms/step - accuracy: 0.4645 - auc: 0.4629 - loss: 0.6998 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6815\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 927ms/step - accuracy: 0.5367 - auc: 0.4952 - loss: 0.6951 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6814\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 892ms/step - accuracy: 0.4910 - auc: 0.4604 - loss: 0.6944 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6837\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 921ms/step - accuracy: 0.5464 - auc: 0.6079 - loss: 0.6814 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6857\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 895ms/step - accuracy: 0.5760 - auc: 0.6655 - loss: 0.6856 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6823\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.5861 - auc: 0.5932 - loss: 0.6834 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6806\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.5890 - auc: 0.5849 - loss: 0.6898 - val_accuracy: 0.5000 - val_auc: 0.7333 - val_loss: 0.6798\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854ms/step - accuracy: 0.4493 - auc: 0.5203 - loss: 0.6943 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6783\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 905ms/step - accuracy: 0.6540 - auc: 0.6778 - loss: 0.6751 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6768\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.5134 - auc: 0.5111 - loss: 0.6860 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6743\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 871ms/step - accuracy: 0.5087 - auc: 0.5376 - loss: 0.6840 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6733\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.5629 - auc: 0.5984 - loss: 0.6827 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6728\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 969ms/step - accuracy: 0.6178 - auc: 0.6525 - loss: 0.6717 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6706\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 901ms/step - accuracy: 0.6428 - auc: 0.6313 - loss: 0.6701 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6678\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 887ms/step - accuracy: 0.5148 - auc: 0.4834 - loss: 0.7007 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6663\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 919ms/step - accuracy: 0.5669 - auc: 0.5323 - loss: 0.6854 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6649\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.5882 - auc: 0.6503 - loss: 0.6653 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6569\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.7354 - auc: 0.7497 - loss: 0.6489 - val_accuracy: 0.5000 - val_auc: 0.7889 - val_loss: 0.6844\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 887ms/step - accuracy: 0.5107 - auc: 0.5786 - loss: 0.6945 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.6162\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 939ms/step - accuracy: 0.7282 - auc: 0.7635 - loss: 0.6326 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.6041\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 910ms/step - accuracy: 0.7847 - auc: 0.7747 - loss: 0.6076 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.5837\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 946ms/step - accuracy: 0.7386 - auc: 0.7891 - loss: 0.5889 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.5350\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 871ms/step - accuracy: 0.8171 - auc: 0.7662 - loss: 0.5707 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.5569\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.7954 - auc: 0.7748 - loss: 0.5579 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4947\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 779ms/step - accuracy: 0.8108 - auc: 0.7886 - loss: 0.5314 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4766\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8010 - auc: 0.8159 - loss: 0.5096 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4618\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 926ms/step - accuracy: 0.8135 - auc: 0.7831 - loss: 0.4987 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4452\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.8171 - auc: 0.8425 - loss: 0.4699 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4322\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8135 - auc: 0.7731 - loss: 0.4788 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4214\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7828 - auc: 0.6989 - loss: 0.5318 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4133\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 961ms/step - accuracy: 0.7910 - auc: 0.7915 - loss: 0.4659 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4078\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 921ms/step - accuracy: 0.7835 - auc: 0.8755 - loss: 0.4337 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4033\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 961ms/step - accuracy: 0.8171 - auc: 0.6822 - loss: 0.4895 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3993\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 822ms/step - accuracy: 0.8171 - auc: 0.7066 - loss: 0.4777 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3973\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 892ms/step - accuracy: 0.8022 - auc: 0.7017 - loss: 0.4904 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3935\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 882ms/step - accuracy: 0.8089 - auc: 0.8653 - loss: 0.4246 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3911\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 858ms/step - accuracy: 0.7829 - auc: 0.8109 - loss: 0.4674 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3957\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 917ms/step - accuracy: 0.8171 - auc: 0.7784 - loss: 0.4442 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4069\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 905ms/step - accuracy: 0.7582 - auc: 0.7444 - loss: 0.4962 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4127\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 938ms/step - accuracy: 0.7578 - auc: 0.7405 - loss: 0.4962 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3853\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 933ms/step - accuracy: 0.7954 - auc: 0.8737 - loss: 0.4199 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4147\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 910ms/step - accuracy: 0.7395 - auc: 0.7565 - loss: 0.4904 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4759\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 879ms/step - accuracy: 0.7841 - auc: 0.6899 - loss: 0.5501 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3844\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 912ms/step - accuracy: 0.8232 - auc: 0.7121 - loss: 0.4537 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3848\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 949ms/step - accuracy: 0.7612 - auc: 0.8240 - loss: 0.4708 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3836\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 975ms/step - accuracy: 0.8171 - auc: 0.8302 - loss: 0.4248 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3828\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 929ms/step - accuracy: 0.8171 - auc: 0.7752 - loss: 0.4237 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3825\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 870ms/step - accuracy: 0.8171 - auc: 0.8168 - loss: 0.4319 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3817\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.8171 - auc: 0.7536 - loss: 0.4359 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3810\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.8171 - auc: 0.7984 - loss: 0.4233 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3804\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 979ms/step - accuracy: 0.8058 - auc: 0.7290 - loss: 0.4480 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3799\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 983ms/step - accuracy: 0.8171 - auc: 0.7514 - loss: 0.4393 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3795\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 959ms/step - accuracy: 0.8135 - auc: 0.7389 - loss: 0.4529 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3794\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8171 - auc: 0.7269 - loss: 0.4492 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3798\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8171 - auc: 0.7505 - loss: 0.4322 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3802\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893ms/step - accuracy: 0.8171 - auc: 0.7243 - loss: 0.4455 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3805\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 871ms/step - accuracy: 0.8171 - auc: 0.7604 - loss: 0.4356 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3802\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 946ms/step - accuracy: 0.8171 - auc: 0.7485 - loss: 0.4479 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3793\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 804ms/step - accuracy: 0.8171 - auc: 0.7190 - loss: 0.4370 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 987ms/step - accuracy: 0.8171 - auc: 0.8594 - loss: 0.4190 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3781\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8171 - auc: 0.7200 - loss: 0.4381 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8171 - auc: 0.8452 - loss: 0.4179 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3779\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.8171 - auc: 0.7183 - loss: 0.4440 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3783\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 799ms/step - accuracy: 0.8171 - auc: 0.8417 - loss: 0.4091 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3780\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809ms/step - accuracy: 0.8171 - auc: 0.7322 - loss: 0.4314 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3783\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830ms/step - accuracy: 0.8171 - auc: 0.7256 - loss: 0.4390 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3796\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8171 - auc: 0.7558 - loss: 0.4436 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3800\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8089 - auc: 0.6890 - loss: 0.4505 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3799\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 837ms/step - accuracy: 0.8171 - auc: 0.7895 - loss: 0.4265 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3791\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 821ms/step - accuracy: 0.8171 - auc: 0.7684 - loss: 0.4363 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3785\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.8171 - auc: 0.7791 - loss: 0.4307 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3781\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.8171 - auc: 0.7918 - loss: 0.4297 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.8171 - auc: 0.8384 - loss: 0.4146 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8171 - auc: 0.6899 - loss: 0.4521 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3770\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 856ms/step - accuracy: 0.8171 - auc: 0.8507 - loss: 0.4129 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.8171 - auc: 0.8331 - loss: 0.4141 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3765\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.8171 - auc: 0.8526 - loss: 0.4058 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3761\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 804ms/step - accuracy: 0.8171 - auc: 0.6730 - loss: 0.4470 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3764\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 822ms/step - accuracy: 0.8171 - auc: 0.7070 - loss: 0.4417 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 793ms/step - accuracy: 0.8171 - auc: 0.7812 - loss: 0.4161 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 826ms/step - accuracy: 0.8171 - auc: 0.7116 - loss: 0.4374 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.8171 - auc: 0.8167 - loss: 0.4123 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3760\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.8171 - auc: 0.7715 - loss: 0.4194 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3759\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 975ms/step - accuracy: 0.8171 - auc: 0.7404 - loss: 0.4410 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3766\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 824ms/step - accuracy: 0.8171 - auc: 0.6866 - loss: 0.4404 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3785\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 969ms/step - accuracy: 0.8058 - auc: 0.7502 - loss: 0.4468 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3816\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 940ms/step - accuracy: 0.8001 - auc: 0.7920 - loss: 0.4494 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4861\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.8058 - auc: 0.7503 - loss: 0.4638 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3813\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 973ms/step - accuracy: 0.8171 - auc: 0.7396 - loss: 0.4442 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3810\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 795ms/step - accuracy: 0.8171 - auc: 0.8025 - loss: 0.4247 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3915\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 882ms/step - accuracy: 0.8058 - auc: 0.8237 - loss: 0.4422 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3787\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 797ms/step - accuracy: 0.8171 - auc: 0.7195 - loss: 0.4571 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4243\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783ms/step - accuracy: 0.8058 - auc: 0.7510 - loss: 0.4712 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4020\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 796ms/step - accuracy: 0.8114 - auc: 0.7688 - loss: 0.4319 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3897\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 821ms/step - accuracy: 0.8171 - auc: 0.8750 - loss: 0.4179 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3840\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 912ms/step - accuracy: 0.7374 - auc: 0.6622 - loss: 0.4778 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3828\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.8058 - auc: 0.7914 - loss: 0.4336 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3820\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 945ms/step - accuracy: 0.8171 - auc: 0.7974 - loss: 0.4306 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3814\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 868ms/step - accuracy: 0.8171 - auc: 0.8199 - loss: 0.4136 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3811\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 919ms/step - accuracy: 0.8171 - auc: 0.7309 - loss: 0.4373 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3808\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 899ms/step - accuracy: 0.8171 - auc: 0.6945 - loss: 0.4449 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3802\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 921ms/step - accuracy: 0.8171 - auc: 0.7423 - loss: 0.4353 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3797\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 909ms/step - accuracy: 0.8171 - auc: 0.8119 - loss: 0.4179 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3790\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 926ms/step - accuracy: 0.8171 - auc: 0.7967 - loss: 0.4181 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3787\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.8171 - auc: 0.7032 - loss: 0.4458 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 825ms/step - accuracy: 0.8171 - auc: 0.7938 - loss: 0.4266 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 909ms/step - accuracy: 0.8171 - auc: 0.7115 - loss: 0.4357 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 944ms/step - accuracy: 0.8171 - auc: 0.7283 - loss: 0.4404 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 802ms/step - accuracy: 0.8171 - auc: 0.9144 - loss: 0.4029 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3779\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8171 - auc: 0.7435 - loss: 0.4349 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 932ms/step - accuracy: 0.8171 - auc: 0.7351 - loss: 0.4317 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 968ms/step - accuracy: 0.8252 - auc: 0.8036 - loss: 0.4177 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.7954 - auc: 0.8840 - loss: 0.4231 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8171 - auc: 0.8701 - loss: 0.4142 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.8171 - auc: 0.8141 - loss: 0.4243 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 932ms/step - accuracy: 0.8171 - auc: 0.8798 - loss: 0.4087 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3772\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 936ms/step - accuracy: 0.8171 - auc: 0.7702 - loss: 0.4302 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.8171 - auc: 0.8345 - loss: 0.4126 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 845ms/step - accuracy: 0.8171 - auc: 0.7703 - loss: 0.4270 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 948ms/step - accuracy: 0.8171 - auc: 0.7964 - loss: 0.4231 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 895ms/step - accuracy: 0.8171 - auc: 0.7355 - loss: 0.4279 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 913ms/step - accuracy: 0.8171 - auc: 0.7423 - loss: 0.4337 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.8513 - auc: 0.9172 - loss: 0.3838 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865ms/step - accuracy: 0.8171 - auc: 0.8897 - loss: 0.3997 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3762\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.8171 - auc: 0.7539 - loss: 0.4379 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3760\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 922ms/step - accuracy: 0.8171 - auc: 0.7284 - loss: 0.4344 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3762\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 871ms/step - accuracy: 0.8171 - auc: 0.7754 - loss: 0.4266 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3765\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 917ms/step - accuracy: 0.8171 - auc: 0.7422 - loss: 0.4302 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 831ms/step - accuracy: 0.8171 - auc: 0.7618 - loss: 0.4290 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3771\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854ms/step - accuracy: 0.8171 - auc: 0.6448 - loss: 0.4462 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.8171 - auc: 0.7902 - loss: 0.4205 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3783\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.8171 - auc: 0.7126 - loss: 0.4378 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3782\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.8171 - auc: 0.8386 - loss: 0.4171 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3794\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.8171 - auc: 0.7888 - loss: 0.4309 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3786\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 833ms/step - accuracy: 0.8171 - auc: 0.8168 - loss: 0.4233 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3787\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 950ms/step - accuracy: 0.8171 - auc: 0.7716 - loss: 0.4261 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.8171 - auc: 0.8274 - loss: 0.4156 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3771\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 866ms/step - accuracy: 0.8171 - auc: 0.8330 - loss: 0.4117 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3756\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 957ms/step - accuracy: 0.8171 - auc: 0.8798 - loss: 0.4027 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3749\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 914ms/step - accuracy: 0.8058 - auc: 0.7044 - loss: 0.4426 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3752\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 956ms/step - accuracy: 0.8171 - auc: 0.8402 - loss: 0.4077 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3763\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 991ms/step - accuracy: 0.8171 - auc: 0.7825 - loss: 0.4258 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3785\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 833ms/step - accuracy: 0.8171 - auc: 0.7640 - loss: 0.4289 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3795\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 855ms/step - accuracy: 0.8171 - auc: 0.8218 - loss: 0.4223 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3806\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 912ms/step - accuracy: 0.8227 - auc: 0.7854 - loss: 0.4217 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3799\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 978ms/step - accuracy: 0.8171 - auc: 0.8267 - loss: 0.4254 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.8171 - auc: 0.8654 - loss: 0.4113 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 961ms/step - accuracy: 0.8171 - auc: 0.7426 - loss: 0.4349 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 874ms/step - accuracy: 0.8171 - auc: 0.7400 - loss: 0.4358 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3771\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 868ms/step - accuracy: 0.8171 - auc: 0.8252 - loss: 0.4191 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8171 - auc: 0.7397 - loss: 0.4332 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3772\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8171 - auc: 0.7689 - loss: 0.4336 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 958ms/step - accuracy: 0.8171 - auc: 0.8106 - loss: 0.4221 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8171 - auc: 0.8413 - loss: 0.4161 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8171 - auc: 0.8000 - loss: 0.4210 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 880ms/step - accuracy: 0.8171 - auc: 0.7740 - loss: 0.4265 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 870ms/step - accuracy: 0.8171 - auc: 0.7002 - loss: 0.4385 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3781\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 921ms/step - accuracy: 0.8171 - auc: 0.7886 - loss: 0.4260 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3781\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.8171 - auc: 0.8080 - loss: 0.4219 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 869ms/step - accuracy: 0.8135 - auc: 0.7296 - loss: 0.4396 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 891ms/step - accuracy: 0.7829 - auc: 0.8175 - loss: 0.4286 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8171 - auc: 0.7481 - loss: 0.4390 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 905ms/step - accuracy: 0.7954 - auc: 0.8096 - loss: 0.4308 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 871ms/step - accuracy: 0.8171 - auc: 0.8312 - loss: 0.4171 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 866ms/step - accuracy: 0.8171 - auc: 0.7900 - loss: 0.4246 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3772\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.8016 - auc: 0.7766 - loss: 0.4307 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.8171 - auc: 0.8203 - loss: 0.4153 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8171 - auc: 0.7860 - loss: 0.4226 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 810ms/step - accuracy: 0.7954 - auc: 0.7657 - loss: 0.4344 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 958ms/step - accuracy: 0.8171 - auc: 0.6783 - loss: 0.4325 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 924ms/step - accuracy: 0.8171 - auc: 0.7770 - loss: 0.4269 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 965ms/step - accuracy: 0.8171 - auc: 0.8692 - loss: 0.4073 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 925ms/step - accuracy: 0.8171 - auc: 0.8046 - loss: 0.4182 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8171 - auc: 0.7018 - loss: 0.4385 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3766\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.8171 - auc: 0.8028 - loss: 0.4184 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.8171 - auc: 0.7901 - loss: 0.4227 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 807ms/step - accuracy: 0.8171 - auc: 0.7810 - loss: 0.4234 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8171 - auc: 0.7519 - loss: 0.4314 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3770\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 947ms/step - accuracy: 0.8171 - auc: 0.7258 - loss: 0.4396 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 789ms/step - accuracy: 0.7954 - auc: 0.8076 - loss: 0.4242 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3778\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830ms/step - accuracy: 0.8171 - auc: 0.7596 - loss: 0.4303 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.8227 - auc: 0.7843 - loss: 0.4189 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875ms/step - accuracy: 0.8171 - auc: 0.6750 - loss: 0.4462 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 835ms/step - accuracy: 0.8171 - auc: 0.7777 - loss: 0.4242 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 804ms/step - accuracy: 0.8171 - auc: 0.7429 - loss: 0.4306 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3777\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.8171 - auc: 0.7679 - loss: 0.4266 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 966ms/step - accuracy: 0.8171 - auc: 0.7497 - loss: 0.4287 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [1:14:22, 1490.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.5005 - auc: 0.4736 - loss: 0.7141 - val_accuracy: 0.5000 - val_auc: 0.7333 - val_loss: 0.6932\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 824ms/step - accuracy: 0.3886 - auc: 0.3238 - loss: 0.7357 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6954\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 834ms/step - accuracy: 0.5269 - auc: 0.5520 - loss: 0.6891 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6926\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.5307 - auc: 0.4960 - loss: 0.6955 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6923\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 908ms/step - accuracy: 0.4584 - auc: 0.4786 - loss: 0.6987 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6919\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.5841 - auc: 0.5432 - loss: 0.6903 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6895\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.5127 - auc: 0.5250 - loss: 0.7030 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6867\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 915ms/step - accuracy: 0.4825 - auc: 0.4679 - loss: 0.7015 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6827\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7089 - auc: 0.7269 - loss: 0.6615 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6783\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.5629 - auc: 0.4773 - loss: 0.7018 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6761\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 872ms/step - accuracy: 0.6264 - auc: 0.6799 - loss: 0.6695 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6778\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 885ms/step - accuracy: 0.5306 - auc: 0.5932 - loss: 0.6848 - val_accuracy: 0.5000 - val_auc: 0.7333 - val_loss: 0.6702\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.5626 - auc: 0.5241 - loss: 0.6929 - val_accuracy: 0.7333 - val_auc: 0.7667 - val_loss: 0.6594\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 892ms/step - accuracy: 0.5279 - auc: 0.6686 - loss: 0.6601 - val_accuracy: 0.8333 - val_auc: 0.7667 - val_loss: 0.6330\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 812ms/step - accuracy: 0.6943 - auc: 0.7128 - loss: 0.6422 - val_accuracy: 0.4667 - val_auc: 0.7311 - val_loss: 0.6581\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 829ms/step - accuracy: 0.6916 - auc: 0.7348 - loss: 0.6175 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.5929\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 919ms/step - accuracy: 0.7210 - auc: 0.8055 - loss: 0.5960 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.5538\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.7693 - auc: 0.8057 - loss: 0.5729 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4966\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 834ms/step - accuracy: 0.7981 - auc: 0.8824 - loss: 0.4878 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4470\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 906ms/step - accuracy: 0.7981 - auc: 0.8054 - loss: 0.4728 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4178\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 907ms/step - accuracy: 0.8038 - auc: 0.7408 - loss: 0.4921 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4047\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 898ms/step - accuracy: 0.8038 - auc: 0.8438 - loss: 0.4313 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4016\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 855ms/step - accuracy: 0.7465 - auc: 0.8281 - loss: 0.4440 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3971\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8119 - auc: 0.7796 - loss: 0.4521 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3976\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 961ms/step - accuracy: 0.7925 - auc: 0.7922 - loss: 0.4548 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3935\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.7925 - auc: 0.8185 - loss: 0.4400 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3885\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 952ms/step - accuracy: 0.8038 - auc: 0.7879 - loss: 0.4498 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3833\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 936ms/step - accuracy: 0.8119 - auc: 0.8535 - loss: 0.4116 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3926\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 814ms/step - accuracy: 0.7956 - auc: 0.7550 - loss: 0.4480 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3818\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.8038 - auc: 0.8166 - loss: 0.4189 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3875\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.8002 - auc: 0.7824 - loss: 0.4297 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3828\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 834ms/step - accuracy: 0.8192 - auc: 0.8551 - loss: 0.4061 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3820\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 810ms/step - accuracy: 0.7821 - auc: 0.7232 - loss: 0.4557 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3801\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 933ms/step - accuracy: 0.7925 - auc: 0.8273 - loss: 0.4092 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3791\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 833ms/step - accuracy: 0.8038 - auc: 0.7900 - loss: 0.4356 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3808\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8038 - auc: 0.7101 - loss: 0.4552 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3805\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.8038 - auc: 0.8252 - loss: 0.4103 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3778\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 965ms/step - accuracy: 0.7981 - auc: 0.8368 - loss: 0.4153 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3801\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 821ms/step - accuracy: 0.8038 - auc: 0.8288 - loss: 0.4205 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3802\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 874ms/step - accuracy: 0.8038 - auc: 0.7843 - loss: 0.4362 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.7899 - auc: 0.7715 - loss: 0.4438 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3787\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 942ms/step - accuracy: 0.7797 - auc: 0.8703 - loss: 0.4269 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3983\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.8038 - auc: 0.7480 - loss: 0.4401 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3845\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7899 - auc: 0.8101 - loss: 0.4541 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3813\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 984ms/step - accuracy: 0.7728 - auc: 0.8591 - loss: 0.4275 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4804\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 940ms/step - accuracy: 0.7707 - auc: 0.8397 - loss: 0.4482 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4278\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 914ms/step - accuracy: 0.8057 - auc: 0.7647 - loss: 0.4571 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3804\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830ms/step - accuracy: 0.7557 - auc: 0.8393 - loss: 0.4352 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3811\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 932ms/step - accuracy: 0.8038 - auc: 0.8073 - loss: 0.4141 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3784\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 877ms/step - accuracy: 0.7796 - auc: 0.7759 - loss: 0.4410 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3768\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 944ms/step - accuracy: 0.7899 - auc: 0.7437 - loss: 0.4483 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3755\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 917ms/step - accuracy: 0.7925 - auc: 0.8362 - loss: 0.4256 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3748\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 821ms/step - accuracy: 0.7981 - auc: 0.8318 - loss: 0.4116 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3749\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 828ms/step - accuracy: 0.8038 - auc: 0.7934 - loss: 0.4280 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3750\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.8038 - auc: 0.8762 - loss: 0.4006 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3748\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 796ms/step - accuracy: 0.8038 - auc: 0.7995 - loss: 0.4219 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3748\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 799ms/step - accuracy: 0.8038 - auc: 0.7961 - loss: 0.4134 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3747\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 908ms/step - accuracy: 0.8038 - auc: 0.8389 - loss: 0.4111 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3730\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 908ms/step - accuracy: 0.8038 - auc: 0.8016 - loss: 0.4207 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3714\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.8038 - auc: 0.8618 - loss: 0.3999 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3706\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8038 - auc: 0.8666 - loss: 0.3977 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3711\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 937ms/step - accuracy: 0.8038 - auc: 0.8069 - loss: 0.4268 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3724\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.7975 - auc: 0.7737 - loss: 0.4329 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3754\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 810ms/step - accuracy: 0.8038 - auc: 0.8151 - loss: 0.4205 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3774\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 949ms/step - accuracy: 0.8192 - auc: 0.8800 - loss: 0.3993 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3757\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.8038 - auc: 0.8228 - loss: 0.4146 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3736\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 806ms/step - accuracy: 0.8038 - auc: 0.7808 - loss: 0.4213 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3714\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.8038 - auc: 0.7489 - loss: 0.4431 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3706\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.8038 - auc: 0.8285 - loss: 0.4076 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3700\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 819ms/step - accuracy: 0.8038 - auc: 0.8278 - loss: 0.4119 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3693\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 978ms/step - accuracy: 0.8038 - auc: 0.7551 - loss: 0.4309 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3703\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.7981 - auc: 0.7441 - loss: 0.4461 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3748\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.8038 - auc: 0.7704 - loss: 0.4266 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3759\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.8038 - auc: 0.8797 - loss: 0.3932 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3747\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 884ms/step - accuracy: 0.8038 - auc: 0.7919 - loss: 0.4221 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3741\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8002 - auc: 0.8886 - loss: 0.3971 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3733\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 929ms/step - accuracy: 0.8119 - auc: 0.8205 - loss: 0.4067 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3709\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 938ms/step - accuracy: 0.8038 - auc: 0.7979 - loss: 0.4215 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3683\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.8038 - auc: 0.8292 - loss: 0.4078 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3674\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 859ms/step - accuracy: 0.8038 - auc: 0.8434 - loss: 0.4175 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3670\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.8038 - auc: 0.8351 - loss: 0.4088 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3673\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 909ms/step - accuracy: 0.8038 - auc: 0.8316 - loss: 0.4111 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3667\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 946ms/step - accuracy: 0.8038 - auc: 0.8349 - loss: 0.4067 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3661\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 829ms/step - accuracy: 0.8038 - auc: 0.7646 - loss: 0.4240 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3665\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 814ms/step - accuracy: 0.8038 - auc: 0.7898 - loss: 0.4219 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3664\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.8038 - auc: 0.8590 - loss: 0.3974 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3654\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 856ms/step - accuracy: 0.8038 - auc: 0.8376 - loss: 0.4072 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3649\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 924ms/step - accuracy: 0.8038 - auc: 0.8459 - loss: 0.4045 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3663\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.8038 - auc: 0.8114 - loss: 0.4178 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3671\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.8038 - auc: 0.7754 - loss: 0.4185 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3689\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 930ms/step - accuracy: 0.8038 - auc: 0.7634 - loss: 0.4272 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3744\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 905ms/step - accuracy: 0.8002 - auc: 0.8856 - loss: 0.3908 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3713\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.8038 - auc: 0.8025 - loss: 0.4141 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3660\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 984ms/step - accuracy: 0.8038 - auc: 0.7770 - loss: 0.4331 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3641\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.7981 - auc: 0.7966 - loss: 0.4188 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3670\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 868ms/step - accuracy: 0.8038 - auc: 0.8591 - loss: 0.4037 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3805\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 924ms/step - accuracy: 0.7981 - auc: 0.8018 - loss: 0.4403 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3755\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 849ms/step - accuracy: 0.8038 - auc: 0.7385 - loss: 0.4294 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3709\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.7899 - auc: 0.7351 - loss: 0.4592 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3767\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 905ms/step - accuracy: 0.7853 - auc: 0.8284 - loss: 0.4284 - val_accuracy: 0.7333 - val_auc: 0.6556 - val_loss: 0.5348\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 922ms/step - accuracy: 0.7342 - auc: 0.6980 - loss: 0.5239 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.4044\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 919ms/step - accuracy: 0.7821 - auc: 0.7052 - loss: 0.4609 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3857\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 902ms/step - accuracy: 0.8038 - auc: 0.8035 - loss: 0.4216 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4354\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 808ms/step - accuracy: 0.7557 - auc: 0.7411 - loss: 0.4494 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3856\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 814ms/step - accuracy: 0.8038 - auc: 0.7592 - loss: 0.4218 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3801\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 947ms/step - accuracy: 0.8038 - auc: 0.8923 - loss: 0.4044 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3784\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 931ms/step - accuracy: 0.8038 - auc: 0.8365 - loss: 0.4070 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3770\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 819ms/step - accuracy: 0.8038 - auc: 0.8389 - loss: 0.4074 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3758\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900ms/step - accuracy: 0.8038 - auc: 0.7759 - loss: 0.4190 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3726\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 942ms/step - accuracy: 0.8038 - auc: 0.7983 - loss: 0.4127 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3710\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 914ms/step - accuracy: 0.8038 - auc: 0.8251 - loss: 0.4105 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3711\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 835ms/step - accuracy: 0.8038 - auc: 0.8578 - loss: 0.4087 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3715\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 867ms/step - accuracy: 0.8038 - auc: 0.8281 - loss: 0.4065 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3715\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 941ms/step - accuracy: 0.8038 - auc: 0.8080 - loss: 0.4155 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3720\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 959ms/step - accuracy: 0.8038 - auc: 0.7963 - loss: 0.4121 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3747\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 865ms/step - accuracy: 0.8038 - auc: 0.8190 - loss: 0.4098 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3785\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.8119 - auc: 0.8791 - loss: 0.3889 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3746\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 944ms/step - accuracy: 0.8038 - auc: 0.7156 - loss: 0.4487 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3751\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 865ms/step - accuracy: 0.7981 - auc: 0.8031 - loss: 0.4105 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3725\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 963ms/step - accuracy: 0.8038 - auc: 0.8549 - loss: 0.4078 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3720\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8038 - auc: 0.7734 - loss: 0.4201 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3779\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.8038 - auc: 0.8813 - loss: 0.3939 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3766\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.8094 - auc: 0.8349 - loss: 0.3998 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3751\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.8038 - auc: 0.8421 - loss: 0.4081 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3719\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 904ms/step - accuracy: 0.7981 - auc: 0.8555 - loss: 0.4136 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3709\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.8038 - auc: 0.8052 - loss: 0.4123 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3739\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.8038 - auc: 0.7848 - loss: 0.4184 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3809\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 881ms/step - accuracy: 0.8119 - auc: 0.7240 - loss: 0.4444 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3830\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 907ms/step - accuracy: 0.8119 - auc: 0.8507 - loss: 0.3935 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3779\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 871ms/step - accuracy: 0.8038 - auc: 0.8801 - loss: 0.4002 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3750\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 919ms/step - accuracy: 0.7956 - auc: 0.8543 - loss: 0.4109 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3728\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.8038 - auc: 0.7414 - loss: 0.4354 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3743\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 961ms/step - accuracy: 0.7696 - auc: 0.7377 - loss: 0.4437 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.8038 - auc: 0.8275 - loss: 0.4205 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3794\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 958ms/step - accuracy: 0.8038 - auc: 0.8064 - loss: 0.4154 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3791\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 951ms/step - accuracy: 0.8038 - auc: 0.8157 - loss: 0.4244 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3786\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 879ms/step - accuracy: 0.8038 - auc: 0.8127 - loss: 0.4113 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3792\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 836ms/step - accuracy: 0.8038 - auc: 0.8353 - loss: 0.4063 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3781\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 951ms/step - accuracy: 0.7981 - auc: 0.8182 - loss: 0.4092 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.8038 - auc: 0.7590 - loss: 0.4176 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3764\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 870ms/step - accuracy: 0.8038 - auc: 0.7874 - loss: 0.4217 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3764\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.8038 - auc: 0.7488 - loss: 0.4213 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3762\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 922ms/step - accuracy: 0.8038 - auc: 0.8195 - loss: 0.4018 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3765\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 969ms/step - accuracy: 0.8038 - auc: 0.8210 - loss: 0.4025 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3754\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.8038 - auc: 0.8462 - loss: 0.4012 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3736\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8038 - auc: 0.7734 - loss: 0.4204 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3713\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 854ms/step - accuracy: 0.8038 - auc: 0.8065 - loss: 0.4175 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3712\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 958ms/step - accuracy: 0.8038 - auc: 0.7893 - loss: 0.4148 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3719\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 852ms/step - accuracy: 0.8038 - auc: 0.8306 - loss: 0.4099 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3715\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937ms/step - accuracy: 0.8038 - auc: 0.8600 - loss: 0.3971 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3705\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 876ms/step - accuracy: 0.8038 - auc: 0.7795 - loss: 0.4179 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3702\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 932ms/step - accuracy: 0.8038 - auc: 0.8732 - loss: 0.4022 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3695\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 958ms/step - accuracy: 0.8038 - auc: 0.7564 - loss: 0.4245 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3692\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.8038 - auc: 0.8135 - loss: 0.4117 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3713\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.8038 - auc: 0.8005 - loss: 0.4137 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3746\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937ms/step - accuracy: 0.8038 - auc: 0.8873 - loss: 0.3979 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3743\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 927ms/step - accuracy: 0.8038 - auc: 0.8689 - loss: 0.4008 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3720\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 899ms/step - accuracy: 0.8038 - auc: 0.7826 - loss: 0.4211 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3705\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 822ms/step - accuracy: 0.8038 - auc: 0.7444 - loss: 0.4261 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3714\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 969ms/step - accuracy: 0.8038 - auc: 0.8329 - loss: 0.4091 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3724\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 900ms/step - accuracy: 0.8038 - auc: 0.7668 - loss: 0.4205 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3719\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 945ms/step - accuracy: 0.8038 - auc: 0.8698 - loss: 0.4086 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3713\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.8038 - auc: 0.8722 - loss: 0.4025 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3713\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 941ms/step - accuracy: 0.8038 - auc: 0.8123 - loss: 0.4089 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3703\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 825ms/step - accuracy: 0.8038 - auc: 0.7616 - loss: 0.4211 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3706\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.8038 - auc: 0.8246 - loss: 0.4059 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3691\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 960ms/step - accuracy: 0.8038 - auc: 0.8015 - loss: 0.4100 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3726\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937ms/step - accuracy: 0.8038 - auc: 0.8228 - loss: 0.4088 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3762\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 864ms/step - accuracy: 0.8038 - auc: 0.8153 - loss: 0.4072 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3775\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 962ms/step - accuracy: 0.8119 - auc: 0.7710 - loss: 0.4190 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3781\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 921ms/step - accuracy: 0.8038 - auc: 0.8209 - loss: 0.4085 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3765\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864ms/step - accuracy: 0.8038 - auc: 0.8821 - loss: 0.4006 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3738\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8038 - auc: 0.7814 - loss: 0.4184 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3729\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 976ms/step - accuracy: 0.8038 - auc: 0.8355 - loss: 0.4058 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3722\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 811ms/step - accuracy: 0.8038 - auc: 0.8752 - loss: 0.4020 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3699\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.8038 - auc: 0.7861 - loss: 0.4175 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3682\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.8038 - auc: 0.7599 - loss: 0.4195 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3687\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.8038 - auc: 0.8788 - loss: 0.4005 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3696\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 915ms/step - accuracy: 0.8038 - auc: 0.7845 - loss: 0.4195 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3711\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.8038 - auc: 0.7874 - loss: 0.4125 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3719\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 849ms/step - accuracy: 0.8038 - auc: 0.8465 - loss: 0.4026 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3717\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 943ms/step - accuracy: 0.8038 - auc: 0.8523 - loss: 0.4050 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3699\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.8038 - auc: 0.8701 - loss: 0.4030 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3686\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8038 - auc: 0.7495 - loss: 0.4196 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3674\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8038 - auc: 0.8483 - loss: 0.4064 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3659\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.8038 - auc: 0.8010 - loss: 0.4128 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3655\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 872ms/step - accuracy: 0.8038 - auc: 0.8239 - loss: 0.4084 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3670\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 990ms/step - accuracy: 0.8038 - auc: 0.8116 - loss: 0.4117 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3776\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 874ms/step - accuracy: 0.8038 - auc: 0.7694 - loss: 0.4183 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3783\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 943ms/step - accuracy: 0.8038 - auc: 0.8642 - loss: 0.4059 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3728\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.8038 - auc: 0.7920 - loss: 0.4178 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3674\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.8038 - auc: 0.8229 - loss: 0.4060 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3648\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 845ms/step - accuracy: 0.8038 - auc: 0.8106 - loss: 0.3999 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3638\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.8038 - auc: 0.8012 - loss: 0.4106 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3638\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 923ms/step - accuracy: 0.8038 - auc: 0.8735 - loss: 0.3960 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3640\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 879ms/step - accuracy: 0.8038 - auc: 0.7871 - loss: 0.4130 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3642\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 929ms/step - accuracy: 0.8038 - auc: 0.8127 - loss: 0.4110 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3641\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.8038 - auc: 0.7938 - loss: 0.4140 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3634\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 892ms/step - accuracy: 0.8038 - auc: 0.8154 - loss: 0.4081 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3641\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.8038 - auc: 0.9011 - loss: 0.3961 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:39:53, 1506.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.4897 - auc: 0.4537 - loss: 0.6978 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 873ms/step - accuracy: 0.5368 - auc: 0.5307 - loss: 0.6791 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 824ms/step - accuracy: 0.6392 - auc: 0.5362 - loss: 0.6911 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 869ms/step - accuracy: 0.3992 - auc: 0.5457 - loss: 0.6911 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.5004 - auc: 0.5978 - loss: 0.6948 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 791ms/step - accuracy: 0.4720 - auc: 0.4432 - loss: 0.6964 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.7160 - auc: 0.6659 - loss: 0.6853 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 824ms/step - accuracy: 0.5611 - auc: 0.5529 - loss: 0.6902 - val_accuracy: 0.5000 - val_auc: 0.5333 - val_loss: 0.6931\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.6888 - auc: 0.6261 - loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 829ms/step - accuracy: 0.5204 - auc: 0.5860 - loss: 0.6917 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 990ms/step - accuracy: 0.5691 - auc: 0.5505 - loss: 0.6919 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.4831 - auc: 0.4429 - loss: 0.6949 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 941ms/step - accuracy: 0.5550 - auc: 0.5970 - loss: 0.6921 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 822ms/step - accuracy: 0.4216 - auc: 0.4927 - loss: 0.6926 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 816ms/step - accuracy: 0.5548 - auc: 0.4348 - loss: 0.6931 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 908ms/step - accuracy: 0.3725 - auc: 0.3843 - loss: 0.6919 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6931\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 808ms/step - accuracy: 0.4497 - auc: 0.5143 - loss: 0.6901 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 924ms/step - accuracy: 0.5471 - auc: 0.4437 - loss: 0.6985 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 807ms/step - accuracy: 0.4228 - auc: 0.4530 - loss: 0.6933 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 790ms/step - accuracy: 0.5401 - auc: 0.4492 - loss: 0.6982 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.4712 - auc: 0.5023 - loss: 0.6940 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 873ms/step - accuracy: 0.4089 - auc: 0.4159 - loss: 0.6987 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 926ms/step - accuracy: 0.5905 - auc: 0.5199 - loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 921ms/step - accuracy: 0.4908 - auc: 0.5752 - loss: 0.6947 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.4358 - auc: 0.4660 - loss: 0.6934 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 886ms/step - accuracy: 0.5179 - auc: 0.4891 - loss: 0.6940 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.5212 - auc: 0.4821 - loss: 0.6935 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 942ms/step - accuracy: 0.5146 - auc: 0.5132 - loss: 0.6930 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 940ms/step - accuracy: 0.5969 - auc: 0.4964 - loss: 0.6927 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 881ms/step - accuracy: 0.6079 - auc: 0.6660 - loss: 0.6918 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 868ms/step - accuracy: 0.4688 - auc: 0.4844 - loss: 0.6941 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 874ms/step - accuracy: 0.4975 - auc: 0.4448 - loss: 0.6946 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.4351 - auc: 0.4533 - loss: 0.6935 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 874ms/step - accuracy: 0.5010 - auc: 0.5164 - loss: 0.6929 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 910ms/step - accuracy: 0.4271 - auc: 0.5270 - loss: 0.6927 - val_accuracy: 0.5333 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 942ms/step - accuracy: 0.4556 - auc: 0.4540 - loss: 0.6941 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 835ms/step - accuracy: 0.4869 - auc: 0.5924 - loss: 0.6926 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6929\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 916ms/step - accuracy: 0.5302 - auc: 0.4155 - loss: 0.6930 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6929\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950ms/step - accuracy: 0.6409 - auc: 0.6953 - loss: 0.6906 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6929\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 926ms/step - accuracy: 0.5167 - auc: 0.4844 - loss: 0.6931 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6928\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 812ms/step - accuracy: 0.5438 - auc: 0.4967 - loss: 0.6928 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6928\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 967ms/step - accuracy: 0.5599 - auc: 0.5844 - loss: 0.6917 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 860ms/step - accuracy: 0.5760 - auc: 0.5314 - loss: 0.6931 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6928\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4628 - auc: 0.4642 - loss: 0.6935 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6928\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 978ms/step - accuracy: 0.5767 - auc: 0.6338 - loss: 0.6919 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6927\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 922ms/step - accuracy: 0.5250 - auc: 0.6431 - loss: 0.6911 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6926\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.4936 - auc: 0.5088 - loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6925\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.5745 - auc: 0.5634 - loss: 0.6916 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6924\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 887ms/step - accuracy: 0.5975 - auc: 0.5201 - loss: 0.6925 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6923\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4568 - auc: 0.4238 - loss: 0.6945 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6922\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.4406 - auc: 0.4466 - loss: 0.6936 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6922\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.5777 - auc: 0.5468 - loss: 0.6914 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6919\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 957ms/step - accuracy: 0.4967 - auc: 0.5085 - loss: 0.6934 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6916\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 910ms/step - accuracy: 0.5485 - auc: 0.5896 - loss: 0.6907 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6913\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.6221 - auc: 0.7171 - loss: 0.6886 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6908\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 922ms/step - accuracy: 0.5325 - auc: 0.5685 - loss: 0.6914 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6902\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 861ms/step - accuracy: 0.5931 - auc: 0.6317 - loss: 0.6881 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6893\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.5516 - auc: 0.6125 - loss: 0.6884 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6886\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.6621 - auc: 0.7834 - loss: 0.6808 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6872\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.6237 - auc: 0.7130 - loss: 0.6779 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6855\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 797ms/step - accuracy: 0.6165 - auc: 0.5823 - loss: 0.6840 - val_accuracy: 0.6000 - val_auc: 0.8000 - val_loss: 0.6795\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 924ms/step - accuracy: 0.6281 - auc: 0.6629 - loss: 0.6820 - val_accuracy: 0.8000 - val_auc: 0.7467 - val_loss: 0.6727\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.8165 - auc: 0.8139 - loss: 0.6560 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.6576\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 930ms/step - accuracy: 0.7969 - auc: 0.8613 - loss: 0.6403 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.6362\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 944ms/step - accuracy: 0.7454 - auc: 0.8498 - loss: 0.6216 - val_accuracy: 0.7333 - val_auc: 0.7067 - val_loss: 0.6429\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 881ms/step - accuracy: 0.8258 - auc: 0.8059 - loss: 0.6097 - val_accuracy: 0.7333 - val_auc: 0.7333 - val_loss: 0.6183\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8041 - auc: 0.8234 - loss: 0.5685 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.5802\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 963ms/step - accuracy: 0.8413 - auc: 0.8510 - loss: 0.5037 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.5474\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 829ms/step - accuracy: 0.8600 - auc: 0.8864 - loss: 0.4330 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4577\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 792ms/step - accuracy: 0.8754 - auc: 0.8175 - loss: 0.4040 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4429\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830ms/step - accuracy: 0.8754 - auc: 0.8756 - loss: 0.3578 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.4788\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.8193 - auc: 0.8540 - loss: 0.3836 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5211\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 909ms/step - accuracy: 0.7523 - auc: 0.8384 - loss: 0.4516 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5232\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 855ms/step - accuracy: 0.8076 - auc: 0.7864 - loss: 0.4513 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4889\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 882ms/step - accuracy: 0.8600 - auc: 0.8595 - loss: 0.3841 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4297\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 861ms/step - accuracy: 0.8754 - auc: 0.8538 - loss: 0.3677 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.6484\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8258 - auc: 0.7835 - loss: 0.6350 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.5442\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 987ms/step - accuracy: 0.8258 - auc: 0.8649 - loss: 0.4119 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4242\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.8196 - auc: 0.8128 - loss: 0.3910 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4219\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.8754 - auc: 0.8500 - loss: 0.3565 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4223\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 835ms/step - accuracy: 0.8754 - auc: 0.8830 - loss: 0.3329 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4223\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867ms/step - accuracy: 0.8754 - auc: 0.8789 - loss: 0.3504 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4221\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 954ms/step - accuracy: 0.8754 - auc: 0.8995 - loss: 0.3363 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4218\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 974ms/step - accuracy: 0.8754 - auc: 0.8528 - loss: 0.3374 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4214\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 978ms/step - accuracy: 0.8413 - auc: 0.8317 - loss: 0.3663 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4207\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 856ms/step - accuracy: 0.8754 - auc: 0.8644 - loss: 0.3469 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4203\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 827ms/step - accuracy: 0.8754 - auc: 0.8895 - loss: 0.3342 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4201\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8754 - auc: 0.8906 - loss: 0.3388 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4202\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 821ms/step - accuracy: 0.8754 - auc: 0.8435 - loss: 0.3594 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4202\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 928ms/step - accuracy: 0.8754 - auc: 0.8224 - loss: 0.3711 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8754 - auc: 0.9065 - loss: 0.3316 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8754 - auc: 0.8289 - loss: 0.3624 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4200\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 866ms/step - accuracy: 0.8754 - auc: 0.8871 - loss: 0.3387 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4202\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 972ms/step - accuracy: 0.8754 - auc: 0.8983 - loss: 0.3328 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4206\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 873ms/step - accuracy: 0.8754 - auc: 0.8878 - loss: 0.3382 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4204\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 978ms/step - accuracy: 0.8754 - auc: 0.7937 - loss: 0.3651 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4201\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.8754 - auc: 0.9145 - loss: 0.3150 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4198\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 887ms/step - accuracy: 0.8754 - auc: 0.8191 - loss: 0.3649 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.8413 - auc: 0.8615 - loss: 0.4531 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4197\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 946ms/step - accuracy: 0.8754 - auc: 0.8947 - loss: 0.3310 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4307\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 959ms/step - accuracy: 0.8356 - auc: 0.8649 - loss: 0.4042 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4572\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 841ms/step - accuracy: 0.7297 - auc: 0.7378 - loss: 0.5106 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5286\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 943ms/step - accuracy: 0.7921 - auc: 0.7539 - loss: 0.4604 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5070\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 930ms/step - accuracy: 0.8301 - auc: 0.9003 - loss: 0.3898 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4215\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 929ms/step - accuracy: 0.8754 - auc: 0.8639 - loss: 0.3525 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4277\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 918ms/step - accuracy: 0.8600 - auc: 0.8338 - loss: 0.4126 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4216\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8754 - auc: 0.8845 - loss: 0.3506 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4206\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 885ms/step - accuracy: 0.8537 - auc: 0.8650 - loss: 0.3689 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 934ms/step - accuracy: 0.8754 - auc: 0.8651 - loss: 0.3565 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4194\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 971ms/step - accuracy: 0.8754 - auc: 0.8749 - loss: 0.3419 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4194\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 914ms/step - accuracy: 0.8754 - auc: 0.9019 - loss: 0.3258 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 967ms/step - accuracy: 0.8754 - auc: 0.8704 - loss: 0.3423 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4198\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8235 - loss: 0.3515 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 846ms/step - accuracy: 0.8754 - auc: 0.8767 - loss: 0.3359 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 997ms/step - accuracy: 0.8754 - auc: 0.8984 - loss: 0.3257 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 865ms/step - accuracy: 0.8754 - auc: 0.8952 - loss: 0.3345 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 917ms/step - accuracy: 0.8754 - auc: 0.8336 - loss: 0.3561 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4197\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 943ms/step - accuracy: 0.8754 - auc: 0.8954 - loss: 0.3342 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4197\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 927ms/step - accuracy: 0.8754 - auc: 0.8212 - loss: 0.3510 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 888ms/step - accuracy: 0.8754 - auc: 0.8604 - loss: 0.3384 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 860ms/step - accuracy: 0.8719 - auc: 0.8732 - loss: 0.3306 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 992ms/step - accuracy: 0.8754 - auc: 0.8348 - loss: 0.3436 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4194\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.8754 - auc: 0.8638 - loss: 0.3379 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.8754 - auc: 0.9094 - loss: 0.3197 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.8754 - auc: 0.8461 - loss: 0.3352 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8754 - auc: 0.9058 - loss: 0.3379 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4192\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 911ms/step - accuracy: 0.8754 - auc: 0.8675 - loss: 0.3373 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 936ms/step - accuracy: 0.8754 - auc: 0.8391 - loss: 0.3442 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8528 - loss: 0.3433 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4191\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 858ms/step - accuracy: 0.8754 - auc: 0.8560 - loss: 0.3471 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 938ms/step - accuracy: 0.8754 - auc: 0.9098 - loss: 0.3298 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 959ms/step - accuracy: 0.8754 - auc: 0.8301 - loss: 0.3497 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 835ms/step - accuracy: 0.8754 - auc: 0.8747 - loss: 0.3411 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8754 - auc: 0.9042 - loss: 0.3320 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4192\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 948ms/step - accuracy: 0.8754 - auc: 0.8375 - loss: 0.3489 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 835ms/step - accuracy: 0.8754 - auc: 0.8688 - loss: 0.3510 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 936ms/step - accuracy: 0.8754 - auc: 0.9238 - loss: 0.3259 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 951ms/step - accuracy: 0.8754 - auc: 0.8651 - loss: 0.3328 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 831ms/step - accuracy: 0.8754 - auc: 0.9217 - loss: 0.3198 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4199\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 922ms/step - accuracy: 0.8754 - auc: 0.8619 - loss: 0.3354 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4202\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 975ms/step - accuracy: 0.8754 - auc: 0.8680 - loss: 0.3299 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4201\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 897ms/step - accuracy: 0.8754 - auc: 0.9039 - loss: 0.3250 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4200\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 947ms/step - accuracy: 0.8600 - auc: 0.9021 - loss: 0.3396 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4199\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 838ms/step - accuracy: 0.8754 - auc: 0.8391 - loss: 0.3355 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4198\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 945ms/step - accuracy: 0.8754 - auc: 0.8735 - loss: 0.3357 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4196\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 933ms/step - accuracy: 0.8754 - auc: 0.8469 - loss: 0.3416 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.8754 - auc: 0.8603 - loss: 0.3400 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4194\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.8754 - auc: 0.8710 - loss: 0.3443 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 957ms/step - accuracy: 0.8754 - auc: 0.8450 - loss: 0.3387 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 790ms/step - accuracy: 0.8754 - auc: 0.8194 - loss: 0.3529 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 782ms/step - accuracy: 0.8754 - auc: 0.8680 - loss: 0.3362 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4191\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 933ms/step - accuracy: 0.8754 - auc: 0.8344 - loss: 0.3434 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 843ms/step - accuracy: 0.8754 - auc: 0.8649 - loss: 0.3405 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 945ms/step - accuracy: 0.8754 - auc: 0.8575 - loss: 0.3429 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 965ms/step - accuracy: 0.8754 - auc: 0.8423 - loss: 0.3453 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 809ms/step - accuracy: 0.8754 - auc: 0.8540 - loss: 0.3478 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 932ms/step - accuracy: 0.8754 - auc: 0.8747 - loss: 0.3350 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 839ms/step - accuracy: 0.8754 - auc: 0.9230 - loss: 0.3207 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.8754 - auc: 0.9005 - loss: 0.3307 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 847ms/step - accuracy: 0.8754 - auc: 0.8538 - loss: 0.3424 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4194\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 834ms/step - accuracy: 0.8754 - auc: 0.8645 - loss: 0.3303 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4194\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 989ms/step - accuracy: 0.8754 - auc: 0.8144 - loss: 0.3550 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8754 - auc: 0.8899 - loss: 0.3336 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 821ms/step - accuracy: 0.8754 - auc: 0.8508 - loss: 0.3415 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 847ms/step - accuracy: 0.8754 - auc: 0.8623 - loss: 0.3395 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 953ms/step - accuracy: 0.8754 - auc: 0.8919 - loss: 0.3351 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 949ms/step - accuracy: 0.8754 - auc: 0.9369 - loss: 0.3157 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 949ms/step - accuracy: 0.8754 - auc: 0.8419 - loss: 0.3392 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 938ms/step - accuracy: 0.8754 - auc: 0.8928 - loss: 0.3285 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 907ms/step - accuracy: 0.8754 - auc: 0.8375 - loss: 0.3440 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 896ms/step - accuracy: 0.8754 - auc: 0.9107 - loss: 0.3239 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 879ms/step - accuracy: 0.8754 - auc: 0.8300 - loss: 0.3395 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8606 - loss: 0.3376 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4191\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 968ms/step - accuracy: 0.8754 - auc: 0.8678 - loss: 0.3373 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 910ms/step - accuracy: 0.8754 - auc: 0.8983 - loss: 0.3351 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 937ms/step - accuracy: 0.8754 - auc: 0.8190 - loss: 0.3510 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.8551 - loss: 0.3412 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4194\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 970ms/step - accuracy: 0.8754 - auc: 0.9124 - loss: 0.3244 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 976ms/step - accuracy: 0.8754 - auc: 0.8305 - loss: 0.3455 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 830ms/step - accuracy: 0.8754 - auc: 0.9099 - loss: 0.3283 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 963ms/step - accuracy: 0.8754 - auc: 0.8378 - loss: 0.3491 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 944ms/step - accuracy: 0.8754 - auc: 0.8970 - loss: 0.3256 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.8754 - auc: 0.8988 - loss: 0.3302 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4197\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 950ms/step - accuracy: 0.8754 - auc: 0.8930 - loss: 0.3259 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4198\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 947ms/step - accuracy: 0.8754 - auc: 0.8529 - loss: 0.3467 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4197\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950ms/step - accuracy: 0.8754 - auc: 0.8950 - loss: 0.3279 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4196\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 901ms/step - accuracy: 0.8754 - auc: 0.8751 - loss: 0.3393 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4194\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.8754 - auc: 0.8960 - loss: 0.3315 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4194\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.8754 - auc: 0.8679 - loss: 0.3442 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.8754 - auc: 0.8995 - loss: 0.3308 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 837ms/step - accuracy: 0.8754 - auc: 0.8654 - loss: 0.3335 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.8754 - auc: 0.8543 - loss: 0.3516 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 793ms/step - accuracy: 0.8754 - auc: 0.8699 - loss: 0.3351 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.8754 - auc: 0.8269 - loss: 0.3482 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 788ms/step - accuracy: 0.8754 - auc: 0.9104 - loss: 0.3273 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4196\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 884ms/step - accuracy: 0.8754 - auc: 0.8532 - loss: 0.3373 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4196\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 921ms/step - accuracy: 0.8754 - auc: 0.8285 - loss: 0.3460 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4197\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 897ms/step - accuracy: 0.8754 - auc: 0.8734 - loss: 0.3267 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4196\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 884ms/step - accuracy: 0.8754 - auc: 0.8137 - loss: 0.3419 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4194\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.8754 - auc: 0.8689 - loss: 0.3326 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [2:05:43, 1508.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 35min 27s, sys: 1h 1min 28s, total: 4h 36min 55s\n",
      "Wall time: 2h 5min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_acc = []\n",
    "all_loss = []\n",
    "all_auc = []\n",
    "\n",
    "all_val_acc = []\n",
    "all_val_loss = []\n",
    "all_val_auc = []\n",
    "\n",
    "for j, seed in tqdm(enumerate(np.arange(NUM_EXPERIMENTS) + INIT_SEED)):\n",
    "    np.random.seed(int(seed))\n",
    "    random.seed(int(seed))\n",
    "    tf.random.set_seed(int(seed))\n",
    "\n",
    "    train_id = np.random.choice(np.unique(np.ravel(data[USER])), 7, replace=False)\n",
    "    train_index = np.isin(data[USER], train_id)\n",
    "\n",
    "    train = data.iloc[train_index]\n",
    "    test = data.iloc[~train_index]\n",
    "\n",
    "    X_train, y_train = reshape_dataset(train)\n",
    "    X_test, y_test = reshape_dataset(test)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = create_model(X_train)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=10,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    auc = history.history['auc']\n",
    "\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_auc = history.history['val_auc']\n",
    "\n",
    "    all_acc.append(acc)\n",
    "    all_loss.append(loss)\n",
    "    all_auc.append(auc)\n",
    "\n",
    "    all_val_acc.append(val_acc)\n",
    "    all_val_loss.append(val_loss)\n",
    "    all_val_auc.append(val_auc)\n",
    "\n",
    "epoch_acc = np.mean(all_acc, axis=0)\n",
    "epoch_loss = np.mean(all_loss, axis=0)\n",
    "epoch_auc = np.mean(all_auc, axis=0)\n",
    "\n",
    "epoch_val_acc = np.mean(all_val_acc, axis=0)\n",
    "epoch_val_loss = np.mean(all_val_loss, axis=0)\n",
    "epoch_val_auc = np.mean(all_val_auc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: TRAIN Accuracy = 0.503 Loss = 0.702 AUC = 0.537\n",
      "Epoch 1: VAL Accuracy = 0.5 Loss = 0.696 AUC = 0.62\n",
      "Epoch 2: TRAIN Accuracy = 0.46 Loss = 0.703 AUC = 0.48\n",
      "Epoch 2: VAL Accuracy = 0.52 Loss = 0.692 AUC = 0.547\n",
      "Epoch 3: TRAIN Accuracy = 0.546 Loss = 0.691 AUC = 0.545\n",
      "Epoch 3: VAL Accuracy = 0.52 Loss = 0.692 AUC = 0.573\n",
      "Epoch 4: TRAIN Accuracy = 0.471 Loss = 0.696 AUC = 0.484\n",
      "Epoch 4: VAL Accuracy = 0.52 Loss = 0.692 AUC = 0.573\n",
      "Epoch 5: TRAIN Accuracy = 0.511 Loss = 0.695 AUC = 0.516\n",
      "Epoch 5: VAL Accuracy = 0.5 Loss = 0.691 AUC = 0.573\n",
      "Epoch 6: TRAIN Accuracy = 0.483 Loss = 0.698 AUC = 0.478\n",
      "Epoch 6: VAL Accuracy = 0.5 Loss = 0.691 AUC = 0.593\n",
      "Epoch 7: TRAIN Accuracy = 0.554 Loss = 0.693 AUC = 0.546\n",
      "Epoch 7: VAL Accuracy = 0.527 Loss = 0.689 AUC = 0.593\n",
      "Epoch 8: TRAIN Accuracy = 0.517 Loss = 0.693 AUC = 0.513\n",
      "Epoch 8: VAL Accuracy = 0.547 Loss = 0.689 AUC = 0.58\n",
      "Epoch 9: TRAIN Accuracy = 0.554 Loss = 0.687 AUC = 0.552\n",
      "Epoch 9: VAL Accuracy = 0.547 Loss = 0.688 AUC = 0.547\n",
      "Epoch 10: TRAIN Accuracy = 0.523 Loss = 0.689 AUC = 0.538\n",
      "Epoch 10: VAL Accuracy = 0.52 Loss = 0.686 AUC = 0.547\n",
      "Epoch 11: TRAIN Accuracy = 0.537 Loss = 0.684 AUC = 0.571\n",
      "Epoch 11: VAL Accuracy = 0.493 Loss = 0.684 AUC = 0.593\n",
      "Epoch 12: TRAIN Accuracy = 0.549 Loss = 0.685 AUC = 0.573\n",
      "Epoch 12: VAL Accuracy = 0.52 Loss = 0.681 AUC = 0.613\n",
      "Epoch 13: TRAIN Accuracy = 0.469 Loss = 0.697 AUC = 0.484\n",
      "Epoch 13: VAL Accuracy = 0.593 Loss = 0.677 AUC = 0.64\n",
      "Epoch 14: TRAIN Accuracy = 0.491 Loss = 0.687 AUC = 0.517\n",
      "Epoch 14: VAL Accuracy = 0.613 Loss = 0.671 AUC = 0.64\n",
      "Epoch 15: TRAIN Accuracy = 0.56 Loss = 0.675 AUC = 0.575\n",
      "Epoch 15: VAL Accuracy = 0.56 Loss = 0.67 AUC = 0.63\n",
      "Epoch 16: TRAIN Accuracy = 0.557 Loss = 0.67 AUC = 0.588\n",
      "Epoch 16: VAL Accuracy = 0.6 Loss = 0.651 AUC = 0.671\n",
      "Epoch 17: TRAIN Accuracy = 0.603 Loss = 0.654 AUC = 0.644\n",
      "Epoch 17: VAL Accuracy = 0.607 Loss = 0.634 AUC = 0.651\n",
      "Epoch 18: TRAIN Accuracy = 0.623 Loss = 0.641 AUC = 0.613\n",
      "Epoch 18: VAL Accuracy = 0.627 Loss = 0.617 AUC = 0.646\n",
      "Epoch 19: TRAIN Accuracy = 0.626 Loss = 0.614 AUC = 0.661\n",
      "Epoch 19: VAL Accuracy = 0.653 Loss = 0.6 AUC = 0.673\n",
      "Epoch 20: TRAIN Accuracy = 0.654 Loss = 0.605 AUC = 0.66\n",
      "Epoch 20: VAL Accuracy = 0.653 Loss = 0.592 AUC = 0.696\n",
      "Epoch 21: TRAIN Accuracy = 0.629 Loss = 0.613 AUC = 0.611\n",
      "Epoch 21: VAL Accuracy = 0.673 Loss = 0.586 AUC = 0.673\n",
      "Epoch 22: TRAIN Accuracy = 0.64 Loss = 0.595 AUC = 0.663\n",
      "Epoch 22: VAL Accuracy = 0.68 Loss = 0.583 AUC = 0.676\n",
      "Epoch 23: TRAIN Accuracy = 0.623 Loss = 0.606 AUC = 0.658\n",
      "Epoch 23: VAL Accuracy = 0.68 Loss = 0.575 AUC = 0.697\n",
      "Epoch 24: TRAIN Accuracy = 0.614 Loss = 0.593 AUC = 0.635\n",
      "Epoch 24: VAL Accuracy = 0.713 Loss = 0.576 AUC = 0.693\n",
      "Epoch 25: TRAIN Accuracy = 0.583 Loss = 0.599 AUC = 0.598\n",
      "Epoch 25: VAL Accuracy = 0.72 Loss = 0.577 AUC = 0.716\n",
      "Epoch 26: TRAIN Accuracy = 0.677 Loss = 0.594 AUC = 0.682\n",
      "Epoch 26: VAL Accuracy = 0.74 Loss = 0.567 AUC = 0.722\n",
      "Epoch 27: TRAIN Accuracy = 0.674 Loss = 0.584 AUC = 0.679\n",
      "Epoch 27: VAL Accuracy = 0.74 Loss = 0.554 AUC = 0.715\n",
      "Epoch 28: TRAIN Accuracy = 0.651 Loss = 0.581 AUC = 0.653\n",
      "Epoch 28: VAL Accuracy = 0.733 Loss = 0.549 AUC = 0.724\n",
      "Epoch 29: TRAIN Accuracy = 0.68 Loss = 0.568 AUC = 0.682\n",
      "Epoch 29: VAL Accuracy = 0.74 Loss = 0.535 AUC = 0.738\n",
      "Epoch 30: TRAIN Accuracy = 0.697 Loss = 0.551 AUC = 0.74\n",
      "Epoch 30: VAL Accuracy = 0.74 Loss = 0.524 AUC = 0.74\n",
      "Epoch 31: TRAIN Accuracy = 0.723 Loss = 0.546 AUC = 0.733\n",
      "Epoch 31: VAL Accuracy = 0.693 Loss = 0.524 AUC = 0.751\n",
      "Epoch 32: TRAIN Accuracy = 0.686 Loss = 0.54 AUC = 0.695\n",
      "Epoch 32: VAL Accuracy = 0.78 Loss = 0.505 AUC = 0.753\n",
      "Epoch 33: TRAIN Accuracy = 0.714 Loss = 0.537 AUC = 0.704\n",
      "Epoch 33: VAL Accuracy = 0.767 Loss = 0.502 AUC = 0.756\n",
      "Epoch 34: TRAIN Accuracy = 0.731 Loss = 0.525 AUC = 0.742\n",
      "Epoch 34: VAL Accuracy = 0.767 Loss = 0.495 AUC = 0.753\n",
      "Epoch 35: TRAIN Accuracy = 0.711 Loss = 0.522 AUC = 0.738\n",
      "Epoch 35: VAL Accuracy = 0.767 Loss = 0.484 AUC = 0.751\n",
      "Epoch 36: TRAIN Accuracy = 0.731 Loss = 0.528 AUC = 0.693\n",
      "Epoch 36: VAL Accuracy = 0.767 Loss = 0.489 AUC = 0.748\n",
      "Epoch 37: TRAIN Accuracy = 0.743 Loss = 0.507 AUC = 0.764\n",
      "Epoch 37: VAL Accuracy = 0.76 Loss = 0.474 AUC = 0.757\n",
      "Epoch 38: TRAIN Accuracy = 0.737 Loss = 0.508 AUC = 0.728\n",
      "Epoch 38: VAL Accuracy = 0.76 Loss = 0.47 AUC = 0.762\n",
      "Epoch 39: TRAIN Accuracy = 0.76 Loss = 0.512 AUC = 0.744\n",
      "Epoch 39: VAL Accuracy = 0.76 Loss = 0.467 AUC = 0.778\n",
      "Epoch 40: TRAIN Accuracy = 0.746 Loss = 0.497 AUC = 0.745\n",
      "Epoch 40: VAL Accuracy = 0.76 Loss = 0.464 AUC = 0.771\n",
      "Epoch 41: TRAIN Accuracy = 0.734 Loss = 0.499 AUC = 0.729\n",
      "Epoch 41: VAL Accuracy = 0.76 Loss = 0.461 AUC = 0.777\n",
      "Epoch 42: TRAIN Accuracy = 0.72 Loss = 0.494 AUC = 0.765\n",
      "Epoch 42: VAL Accuracy = 0.76 Loss = 0.463 AUC = 0.753\n",
      "Epoch 43: TRAIN Accuracy = 0.74 Loss = 0.511 AUC = 0.717\n",
      "Epoch 43: VAL Accuracy = 0.76 Loss = 0.458 AUC = 0.771\n",
      "Epoch 44: TRAIN Accuracy = 0.729 Loss = 0.498 AUC = 0.745\n",
      "Epoch 44: VAL Accuracy = 0.76 Loss = 0.457 AUC = 0.78\n",
      "Epoch 45: TRAIN Accuracy = 0.751 Loss = 0.486 AUC = 0.798\n",
      "Epoch 45: VAL Accuracy = 0.74 Loss = 0.475 AUC = 0.776\n",
      "Epoch 46: TRAIN Accuracy = 0.723 Loss = 0.502 AUC = 0.756\n",
      "Epoch 46: VAL Accuracy = 0.76 Loss = 0.464 AUC = 0.773\n",
      "Epoch 47: TRAIN Accuracy = 0.72 Loss = 0.53 AUC = 0.695\n",
      "Epoch 47: VAL Accuracy = 0.74 Loss = 0.479 AUC = 0.757\n",
      "Epoch 48: TRAIN Accuracy = 0.703 Loss = 0.523 AUC = 0.744\n",
      "Epoch 48: VAL Accuracy = 0.76 Loss = 0.479 AUC = 0.751\n",
      "Epoch 49: TRAIN Accuracy = 0.72 Loss = 0.502 AUC = 0.754\n",
      "Epoch 49: VAL Accuracy = 0.76 Loss = 0.476 AUC = 0.74\n",
      "Epoch 50: TRAIN Accuracy = 0.711 Loss = 0.513 AUC = 0.702\n",
      "Epoch 50: VAL Accuracy = 0.76 Loss = 0.474 AUC = 0.78\n",
      "Epoch 51: TRAIN Accuracy = 0.717 Loss = 0.511 AUC = 0.703\n",
      "Epoch 51: VAL Accuracy = 0.78 Loss = 0.472 AUC = 0.777\n",
      "Epoch 52: TRAIN Accuracy = 0.731 Loss = 0.508 AUC = 0.731\n",
      "Epoch 52: VAL Accuracy = 0.78 Loss = 0.459 AUC = 0.78\n",
      "Epoch 53: TRAIN Accuracy = 0.729 Loss = 0.496 AUC = 0.733\n",
      "Epoch 53: VAL Accuracy = 0.78 Loss = 0.453 AUC = 0.78\n",
      "Epoch 54: TRAIN Accuracy = 0.74 Loss = 0.477 AUC = 0.764\n",
      "Epoch 54: VAL Accuracy = 0.767 Loss = 0.457 AUC = 0.775\n",
      "Epoch 55: TRAIN Accuracy = 0.746 Loss = 0.488 AUC = 0.772\n",
      "Epoch 55: VAL Accuracy = 0.767 Loss = 0.474 AUC = 0.777\n",
      "Epoch 56: TRAIN Accuracy = 0.726 Loss = 0.51 AUC = 0.74\n",
      "Epoch 56: VAL Accuracy = 0.76 Loss = 0.47 AUC = 0.784\n",
      "Epoch 57: TRAIN Accuracy = 0.751 Loss = 0.493 AUC = 0.757\n",
      "Epoch 57: VAL Accuracy = 0.78 Loss = 0.451 AUC = 0.782\n",
      "Epoch 58: TRAIN Accuracy = 0.751 Loss = 0.481 AUC = 0.784\n",
      "Epoch 58: VAL Accuracy = 0.78 Loss = 0.45 AUC = 0.778\n",
      "Epoch 59: TRAIN Accuracy = 0.766 Loss = 0.472 AUC = 0.81\n",
      "Epoch 59: VAL Accuracy = 0.78 Loss = 0.45 AUC = 0.782\n",
      "Epoch 60: TRAIN Accuracy = 0.763 Loss = 0.476 AUC = 0.771\n",
      "Epoch 60: VAL Accuracy = 0.773 Loss = 0.45 AUC = 0.798\n",
      "Epoch 61: TRAIN Accuracy = 0.763 Loss = 0.473 AUC = 0.774\n",
      "Epoch 61: VAL Accuracy = 0.78 Loss = 0.447 AUC = 0.818\n",
      "Epoch 62: TRAIN Accuracy = 0.76 Loss = 0.477 AUC = 0.759\n",
      "Epoch 62: VAL Accuracy = 0.82 Loss = 0.444 AUC = 0.807\n",
      "Epoch 63: TRAIN Accuracy = 0.789 Loss = 0.474 AUC = 0.782\n",
      "Epoch 63: VAL Accuracy = 0.82 Loss = 0.442 AUC = 0.81\n",
      "Epoch 64: TRAIN Accuracy = 0.783 Loss = 0.472 AUC = 0.79\n",
      "Epoch 64: VAL Accuracy = 0.82 Loss = 0.438 AUC = 0.812\n",
      "Epoch 65: TRAIN Accuracy = 0.789 Loss = 0.464 AUC = 0.802\n",
      "Epoch 65: VAL Accuracy = 0.807 Loss = 0.439 AUC = 0.799\n",
      "Epoch 66: TRAIN Accuracy = 0.797 Loss = 0.462 AUC = 0.805\n",
      "Epoch 66: VAL Accuracy = 0.807 Loss = 0.434 AUC = 0.804\n",
      "Epoch 67: TRAIN Accuracy = 0.797 Loss = 0.462 AUC = 0.781\n",
      "Epoch 67: VAL Accuracy = 0.807 Loss = 0.426 AUC = 0.812\n",
      "Epoch 68: TRAIN Accuracy = 0.803 Loss = 0.446 AUC = 0.8\n",
      "Epoch 68: VAL Accuracy = 0.807 Loss = 0.419 AUC = 0.812\n",
      "Epoch 69: TRAIN Accuracy = 0.803 Loss = 0.432 AUC = 0.807\n",
      "Epoch 69: VAL Accuracy = 0.82 Loss = 0.401 AUC = 0.82\n",
      "Epoch 70: TRAIN Accuracy = 0.806 Loss = 0.439 AUC = 0.766\n",
      "Epoch 70: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.812\n",
      "Epoch 71: TRAIN Accuracy = 0.806 Loss = 0.426 AUC = 0.786\n",
      "Epoch 71: VAL Accuracy = 0.807 Loss = 0.405 AUC = 0.815\n",
      "Epoch 72: TRAIN Accuracy = 0.791 Loss = 0.436 AUC = 0.776\n",
      "Epoch 72: VAL Accuracy = 0.8 Loss = 0.414 AUC = 0.822\n",
      "Epoch 73: TRAIN Accuracy = 0.786 Loss = 0.44 AUC = 0.787\n",
      "Epoch 73: VAL Accuracy = 0.8 Loss = 0.415 AUC = 0.822\n",
      "Epoch 74: TRAIN Accuracy = 0.786 Loss = 0.446 AUC = 0.791\n",
      "Epoch 74: VAL Accuracy = 0.8 Loss = 0.425 AUC = 0.824\n",
      "Epoch 75: TRAIN Accuracy = 0.783 Loss = 0.454 AUC = 0.773\n",
      "Epoch 75: VAL Accuracy = 0.8 Loss = 0.416 AUC = 0.812\n",
      "Epoch 76: TRAIN Accuracy = 0.791 Loss = 0.437 AUC = 0.793\n",
      "Epoch 76: VAL Accuracy = 0.807 Loss = 0.443 AUC = 0.815\n",
      "Epoch 77: TRAIN Accuracy = 0.8 Loss = 0.453 AUC = 0.791\n",
      "Epoch 77: VAL Accuracy = 0.807 Loss = 0.419 AUC = 0.812\n",
      "Epoch 78: TRAIN Accuracy = 0.8 Loss = 0.428 AUC = 0.796\n",
      "Epoch 78: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.812\n",
      "Epoch 79: TRAIN Accuracy = 0.8 Loss = 0.424 AUC = 0.791\n",
      "Epoch 79: VAL Accuracy = 0.813 Loss = 0.406 AUC = 0.81\n",
      "Epoch 80: TRAIN Accuracy = 0.797 Loss = 0.449 AUC = 0.788\n",
      "Epoch 80: VAL Accuracy = 0.8 Loss = 0.418 AUC = 0.812\n",
      "Epoch 81: TRAIN Accuracy = 0.78 Loss = 0.446 AUC = 0.778\n",
      "Epoch 81: VAL Accuracy = 0.8 Loss = 0.429 AUC = 0.792\n",
      "Epoch 82: TRAIN Accuracy = 0.771 Loss = 0.463 AUC = 0.765\n",
      "Epoch 82: VAL Accuracy = 0.8 Loss = 0.421 AUC = 0.775\n",
      "Epoch 83: TRAIN Accuracy = 0.783 Loss = 0.441 AUC = 0.785\n",
      "Epoch 83: VAL Accuracy = 0.8 Loss = 0.416 AUC = 0.795\n",
      "Epoch 84: TRAIN Accuracy = 0.786 Loss = 0.446 AUC = 0.763\n",
      "Epoch 84: VAL Accuracy = 0.8 Loss = 0.415 AUC = 0.815\n",
      "Epoch 85: TRAIN Accuracy = 0.794 Loss = 0.427 AUC = 0.81\n",
      "Epoch 85: VAL Accuracy = 0.82 Loss = 0.399 AUC = 0.819\n",
      "Epoch 86: TRAIN Accuracy = 0.8 Loss = 0.423 AUC = 0.813\n",
      "Epoch 86: VAL Accuracy = 0.8 Loss = 0.413 AUC = 0.824\n",
      "Epoch 87: TRAIN Accuracy = 0.789 Loss = 0.438 AUC = 0.789\n",
      "Epoch 87: VAL Accuracy = 0.8 Loss = 0.413 AUC = 0.82\n",
      "Epoch 88: TRAIN Accuracy = 0.789 Loss = 0.427 AUC = 0.839\n",
      "Epoch 88: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.819\n",
      "Epoch 89: TRAIN Accuracy = 0.806 Loss = 0.423 AUC = 0.809\n",
      "Epoch 89: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.816\n",
      "Epoch 90: TRAIN Accuracy = 0.797 Loss = 0.429 AUC = 0.806\n",
      "Epoch 90: VAL Accuracy = 0.82 Loss = 0.402 AUC = 0.819\n",
      "Epoch 91: TRAIN Accuracy = 0.791 Loss = 0.432 AUC = 0.8\n",
      "Epoch 91: VAL Accuracy = 0.8 Loss = 0.414 AUC = 0.819\n",
      "Epoch 92: TRAIN Accuracy = 0.789 Loss = 0.442 AUC = 0.767\n",
      "Epoch 92: VAL Accuracy = 0.8 Loss = 0.411 AUC = 0.817\n",
      "Epoch 93: TRAIN Accuracy = 0.794 Loss = 0.421 AUC = 0.835\n",
      "Epoch 93: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.817\n",
      "Epoch 94: TRAIN Accuracy = 0.806 Loss = 0.421 AUC = 0.795\n",
      "Epoch 94: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.819\n",
      "Epoch 95: TRAIN Accuracy = 0.803 Loss = 0.42 AUC = 0.793\n",
      "Epoch 95: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.816\n",
      "Epoch 96: TRAIN Accuracy = 0.806 Loss = 0.421 AUC = 0.779\n",
      "Epoch 96: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.816\n",
      "Epoch 97: TRAIN Accuracy = 0.8 Loss = 0.427 AUC = 0.797\n",
      "Epoch 97: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.824\n",
      "Epoch 98: TRAIN Accuracy = 0.806 Loss = 0.426 AUC = 0.774\n",
      "Epoch 98: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.819\n",
      "Epoch 99: TRAIN Accuracy = 0.794 Loss = 0.449 AUC = 0.785\n",
      "Epoch 99: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.822\n",
      "Epoch 100: TRAIN Accuracy = 0.791 Loss = 0.442 AUC = 0.781\n",
      "Epoch 100: VAL Accuracy = 0.78 Loss = 0.45 AUC = 0.779\n",
      "Epoch 101: TRAIN Accuracy = 0.78 Loss = 0.454 AUC = 0.778\n",
      "Epoch 101: VAL Accuracy = 0.82 Loss = 0.408 AUC = 0.822\n",
      "Epoch 102: TRAIN Accuracy = 0.774 Loss = 0.465 AUC = 0.743\n",
      "Epoch 102: VAL Accuracy = 0.8 Loss = 0.419 AUC = 0.822\n",
      "Epoch 103: TRAIN Accuracy = 0.789 Loss = 0.442 AUC = 0.776\n",
      "Epoch 103: VAL Accuracy = 0.787 Loss = 0.426 AUC = 0.808\n",
      "Epoch 104: TRAIN Accuracy = 0.786 Loss = 0.432 AUC = 0.826\n",
      "Epoch 104: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.822\n",
      "Epoch 105: TRAIN Accuracy = 0.806 Loss = 0.428 AUC = 0.774\n",
      "Epoch 105: VAL Accuracy = 0.82 Loss = 0.406 AUC = 0.816\n",
      "Epoch 106: TRAIN Accuracy = 0.8 Loss = 0.433 AUC = 0.81\n",
      "Epoch 106: VAL Accuracy = 0.82 Loss = 0.4 AUC = 0.816\n",
      "Epoch 107: TRAIN Accuracy = 0.803 Loss = 0.425 AUC = 0.783\n",
      "Epoch 107: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.822\n",
      "Epoch 108: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.831\n",
      "Epoch 108: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.815\n",
      "Epoch 109: TRAIN Accuracy = 0.797 Loss = 0.421 AUC = 0.796\n",
      "Epoch 109: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.822\n",
      "Epoch 110: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.792\n",
      "Epoch 110: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.819\n",
      "Epoch 111: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.818\n",
      "Epoch 111: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.815\n",
      "Epoch 112: TRAIN Accuracy = 0.806 Loss = 0.422 AUC = 0.79\n",
      "Epoch 112: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.815\n",
      "Epoch 113: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.801\n",
      "Epoch 113: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.822\n",
      "Epoch 114: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.808\n",
      "Epoch 114: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.815\n",
      "Epoch 115: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.819\n",
      "Epoch 115: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.816\n",
      "Epoch 116: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.806\n",
      "Epoch 116: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.819\n",
      "Epoch 117: TRAIN Accuracy = 0.809 Loss = 0.415 AUC = 0.795\n",
      "Epoch 117: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.82\n",
      "Epoch 118: TRAIN Accuracy = 0.806 Loss = 0.422 AUC = 0.778\n",
      "Epoch 118: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.819\n",
      "Epoch 119: TRAIN Accuracy = 0.803 Loss = 0.421 AUC = 0.785\n",
      "Epoch 119: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.819\n",
      "Epoch 120: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.803\n",
      "Epoch 120: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.824\n",
      "Epoch 121: TRAIN Accuracy = 0.803 Loss = 0.419 AUC = 0.789\n",
      "Epoch 121: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.824\n",
      "Epoch 122: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.819\n",
      "Epoch 122: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.815\n",
      "Epoch 123: TRAIN Accuracy = 0.809 Loss = 0.417 AUC = 0.784\n",
      "Epoch 123: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.819\n",
      "Epoch 124: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.796\n",
      "Epoch 124: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.822\n",
      "Epoch 125: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.792\n",
      "Epoch 125: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.822\n",
      "Epoch 126: TRAIN Accuracy = 0.803 Loss = 0.415 AUC = 0.82\n",
      "Epoch 126: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.822\n",
      "Epoch 127: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.803\n",
      "Epoch 127: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.824\n",
      "Epoch 128: TRAIN Accuracy = 0.809 Loss = 0.42 AUC = 0.785\n",
      "Epoch 128: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.829\n",
      "Epoch 129: TRAIN Accuracy = 0.809 Loss = 0.408 AUC = 0.831\n",
      "Epoch 129: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.822\n",
      "Epoch 130: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.819\n",
      "Epoch 130: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 131: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.826\n",
      "Epoch 131: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 132: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.803\n",
      "Epoch 132: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 133: TRAIN Accuracy = 0.803 Loss = 0.416 AUC = 0.815\n",
      "Epoch 133: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.827\n",
      "Epoch 134: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.814\n",
      "Epoch 134: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.824\n",
      "Epoch 135: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.803\n",
      "Epoch 135: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.827\n",
      "Epoch 136: TRAIN Accuracy = 0.809 Loss = 0.409 AUC = 0.836\n",
      "Epoch 136: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.827\n",
      "Epoch 137: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.828\n",
      "Epoch 137: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.828\n",
      "Epoch 138: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.791\n",
      "Epoch 138: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 139: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.803\n",
      "Epoch 139: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 140: TRAIN Accuracy = 0.806 Loss = 0.421 AUC = 0.764\n",
      "Epoch 140: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 141: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.816\n",
      "Epoch 141: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.824\n",
      "Epoch 142: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.789\n",
      "Epoch 142: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.827\n",
      "Epoch 143: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.794\n",
      "Epoch 143: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 144: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.783\n",
      "Epoch 144: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.824\n",
      "Epoch 145: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.812\n",
      "Epoch 145: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 146: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.81\n",
      "Epoch 146: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 147: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.789\n",
      "Epoch 147: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.824\n",
      "Epoch 148: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.809\n",
      "Epoch 148: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.824\n",
      "Epoch 149: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.798\n",
      "Epoch 149: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.82\n",
      "Epoch 150: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.796\n",
      "Epoch 150: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 151: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.812\n",
      "Epoch 151: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.824\n",
      "Epoch 152: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.816\n",
      "Epoch 152: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 153: TRAIN Accuracy = 0.803 Loss = 0.421 AUC = 0.787\n",
      "Epoch 153: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 154: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.808\n",
      "Epoch 154: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 155: TRAIN Accuracy = 0.803 Loss = 0.417 AUC = 0.812\n",
      "Epoch 155: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.834\n",
      "Epoch 156: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.8\n",
      "Epoch 156: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.827\n",
      "Epoch 157: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.811\n",
      "Epoch 157: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 158: TRAIN Accuracy = 0.809 Loss = 0.413 AUC = 0.805\n",
      "Epoch 158: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 159: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.807\n",
      "Epoch 159: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.824\n",
      "Epoch 160: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.83\n",
      "Epoch 160: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 161: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.789\n",
      "Epoch 161: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.825\n",
      "Epoch 162: TRAIN Accuracy = 0.803 Loss = 0.424 AUC = 0.779\n",
      "Epoch 162: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.824\n",
      "Epoch 163: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.815\n",
      "Epoch 163: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.828\n",
      "Epoch 164: TRAIN Accuracy = 0.794 Loss = 0.433 AUC = 0.768\n",
      "Epoch 164: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 165: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.784\n",
      "Epoch 165: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.825\n",
      "Epoch 166: TRAIN Accuracy = 0.8 Loss = 0.426 AUC = 0.804\n",
      "Epoch 166: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 167: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.798\n",
      "Epoch 167: VAL Accuracy = 0.8 Loss = 0.418 AUC = 0.782\n",
      "Epoch 168: TRAIN Accuracy = 0.791 Loss = 0.437 AUC = 0.769\n",
      "Epoch 168: VAL Accuracy = 0.8 Loss = 0.414 AUC = 0.827\n",
      "Epoch 169: TRAIN Accuracy = 0.8 Loss = 0.419 AUC = 0.818\n",
      "Epoch 169: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.822\n",
      "Epoch 170: TRAIN Accuracy = 0.809 Loss = 0.416 AUC = 0.787\n",
      "Epoch 170: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.824\n",
      "Epoch 171: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.836\n",
      "Epoch 171: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.824\n",
      "Epoch 172: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.795\n",
      "Epoch 172: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 173: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.792\n",
      "Epoch 173: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.824\n",
      "Epoch 174: TRAIN Accuracy = 0.803 Loss = 0.413 AUC = 0.818\n",
      "Epoch 174: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 175: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.817\n",
      "Epoch 175: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 176: TRAIN Accuracy = 0.803 Loss = 0.421 AUC = 0.778\n",
      "Epoch 176: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.824\n",
      "Epoch 177: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.799\n",
      "Epoch 177: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 178: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.838\n",
      "Epoch 178: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 179: TRAIN Accuracy = 0.803 Loss = 0.42 AUC = 0.774\n",
      "Epoch 179: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.834\n",
      "Epoch 180: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.819\n",
      "Epoch 180: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 181: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.82\n",
      "Epoch 181: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 182: TRAIN Accuracy = 0.803 Loss = 0.413 AUC = 0.809\n",
      "Epoch 182: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.824\n",
      "Epoch 183: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.822\n",
      "Epoch 183: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.834\n",
      "Epoch 184: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.809\n",
      "Epoch 184: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 185: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.815\n",
      "Epoch 185: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 186: TRAIN Accuracy = 0.806 Loss = 0.407 AUC = 0.836\n",
      "Epoch 186: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.829\n",
      "Epoch 187: TRAIN Accuracy = 0.806 Loss = 0.42 AUC = 0.773\n",
      "Epoch 187: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.829\n",
      "Epoch 188: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.816\n",
      "Epoch 188: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 189: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.824\n",
      "Epoch 189: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 190: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.824\n",
      "Epoch 190: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.829\n",
      "Epoch 191: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.796\n",
      "Epoch 191: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 192: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.788\n",
      "Epoch 192: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.829\n",
      "Epoch 193: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.795\n",
      "Epoch 193: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.828\n",
      "Epoch 194: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.782\n",
      "Epoch 194: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.824\n",
      "Epoch 195: TRAIN Accuracy = 0.809 Loss = 0.406 AUC = 0.835\n",
      "Epoch 195: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 196: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.793\n",
      "Epoch 196: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 197: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.79\n",
      "Epoch 197: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 198: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.797\n",
      "Epoch 198: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.834\n",
      "Epoch 199: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.795\n",
      "Epoch 199: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.829\n",
      "Epoch 200: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.821\n",
      "Epoch 200: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.829\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {(i + 1)}: TRAIN Accuracy = {np.round(epoch_acc[i], 3)} Loss = {np.round(epoch_loss[i], 3)} AUC = {np.round(epoch_auc[i], 3)}\")\n",
    "    print(f\"Epoch {(i + 1)}: VAL Accuracy = {np.round(epoch_val_acc[i], 3)} Loss = {np.round(epoch_val_loss[i], 3)} AUC = {np.round(epoch_val_auc[i], 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-signals-_5HxkjSc-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
