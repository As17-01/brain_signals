{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 17:04:46.816294: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-21 17:04:46.820399: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-21 17:04:46.833603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742565886.863627  887945 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742565886.870641  887945 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-21 17:04:46.903871: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GRU, Input, BatchNormalization, Dropout, TimeDistributed\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.keras import LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "NUM_EXPERIMENTS = 5\n",
    "\n",
    "def create_model(train):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train.shape[1], train.shape[2])))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(32, activation='relu')))\n",
    "\n",
    "    model.add(LTC(AutoNCP(32, 25), return_sequences=True))\n",
    "    model.add(LTC(AutoNCP(25, 16), return_sequences=False))\n",
    "\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.003), loss='binary_crossentropy', metrics=[\"accuracy\", AUC(name=\"auc\")])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = [\"ID\"]\n",
    "USER = [\"SubjectID\"]\n",
    "IDS = [\"SubjectID\", \"VideoID\"]\n",
    "TARGET = [\"predefinedlabel\"]\n",
    "FEATURES = [\"Raw\", \"Delta\", \"Theta\", \"Alpha1\", \"Alpha2\", \"Beta1\", \"Beta2\", \"Gamma1\", \"Gamma2\"]\n",
    "LAGS = [2]\n",
    "INIT_SEED = 5412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>...</th>\n",
       "      <th>Raw_2</th>\n",
       "      <th>Delta_2</th>\n",
       "      <th>Theta_2</th>\n",
       "      <th>Alpha1_2</th>\n",
       "      <th>Alpha2_2</th>\n",
       "      <th>Beta1_2</th>\n",
       "      <th>Beta2_2</th>\n",
       "      <th>Gamma1_2</th>\n",
       "      <th>Gamma2_2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>...</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SubjectID    Raw     Delta     Theta    Alpha1   Alpha2    Beta1  \\\n",
       "0   0        0.0  278.0  301963.0   90612.0   33735.0  23991.0  27946.0   \n",
       "1   0        0.0  -50.0   73787.0   28083.0    1439.0   2240.0   2746.0   \n",
       "2   0        0.0  101.0  758353.0  383745.0  201999.0  62107.0  36293.0   \n",
       "\n",
       "      Beta2   Gamma1  ...  Raw_2   Delta_2  Theta_2  Alpha1_2  Alpha2_2  \\\n",
       "0   45097.0  33228.0  ...    0.0       0.0      0.0       0.0       0.0   \n",
       "1    3687.0   5293.0  ...    0.0       0.0      0.0       0.0       0.0   \n",
       "2  130536.0  57243.0  ...  278.0  301963.0  90612.0   33735.0   23991.0   \n",
       "\n",
       "   Beta1_2  Beta2_2  Gamma1_2  Gamma2_2  predefinedlabel  \n",
       "0      0.0      0.0       0.0       0.0              0.0  \n",
       "1      0.0      0.0       0.0       0.0              0.0  \n",
       "2  27946.0  45097.0   33228.0    8293.0              0.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"/home/aseliverstov/projects/brain_signals/data\")\n",
    "data = pd.read_csv(data_dir / \"EEG_data.csv\")\n",
    "\n",
    "new_features = []\n",
    "for lag in LAGS:\n",
    "    for feature_name in FEATURES:\n",
    "        new_feature_name = f\"{feature_name}_{lag}\"\n",
    "        new_features.append(new_feature_name)\n",
    "        data[new_feature_name] = data.groupby(IDS)[feature_name].shift(lag).fillna(0)\n",
    "FEATURES.extend(new_features)\n",
    "\n",
    "data[\"ID\"] = (len(np.unique(data[\"VideoID\"])) * data[\"SubjectID\"] + data[\"VideoID\"]).astype(\"int\")\n",
    "data = data[ID + USER + FEATURES + TARGET]\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(data):\n",
    "    features = []\n",
    "    target = []\n",
    "    for cur_id in np.unique(data[ID].to_numpy()):\n",
    "        cur_id_data = data[data[ID].to_numpy() == cur_id]\n",
    "        target.append(np.mean(cur_id_data[TARGET].to_numpy()).astype(\"int\"))\n",
    "        features.append(cur_id_data[FEATURES].to_numpy())\n",
    "\n",
    "    features = pad_sequences(features)\n",
    "    return np.array(features), np.array(target)\n",
    "\n",
    "def pad_sequences(arrays, pad_value=0):\n",
    "    max_length = max(arr.shape[0] for arr in arrays)\n",
    "    padded_arrays = [\n",
    "        np.pad(\n",
    "            arr,\n",
    "            ((0, max_length - arr.shape[0]), (0, 0)),\n",
    "            mode='constant',\n",
    "            constant_values=pad_value)\n",
    "            for arr in arrays\n",
    "        ]\n",
    "    return np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-21 17:04:49.749139: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">608</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,402</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,157</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │           \u001b[38;5;34m608\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc (\u001b[38;5;33mLTC\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m25\u001b[0m)        │         \u001b[38;5;34m8,402\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_1 (\u001b[38;5;33mLTC\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m5,157\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,456</span> (56.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,456\u001b[0m (56.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,456</span> (56.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,456\u001b[0m (56.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, _ = reshape_dataset(data)\n",
    "model = create_model(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.5335 - auc: 0.4357 - loss: 0.6926 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6949\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5335 - auc: 0.5902 - loss: 0.6906 - val_accuracy: 0.5000 - val_auc: 0.7667 - val_loss: 0.6922\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.5335 - auc: 0.6518 - loss: 0.6888 - val_accuracy: 0.5000 - val_auc: 0.8222 - val_loss: 0.6848\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.5335 - auc: 0.7413 - loss: 0.6829 - val_accuracy: 0.5000 - val_auc: 0.8556 - val_loss: 0.6770\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.5371 - auc: 0.7406 - loss: 0.6766 - val_accuracy: 0.7333 - val_auc: 0.8822 - val_loss: 0.6665\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7130 - auc: 0.7310 - loss: 0.6670 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.6446\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7555 - loss: 0.6501 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.6237\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7415 - loss: 0.6335 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.5970\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7455 - loss: 0.6142 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.5659\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7683 - loss: 0.5930 - val_accuracy: 0.8333 - val_auc: 0.8822 - val_loss: 0.5306\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7320 - loss: 0.5695 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4946\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7254 - loss: 0.5489 - val_accuracy: 0.8333 - val_auc: 0.8000 - val_loss: 0.4645\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6785 - loss: 0.5304 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4413\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6719 - loss: 0.5167 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4215\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6833 - loss: 0.5046 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4065\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6821 - loss: 0.4976 - val_accuracy: 0.8333 - val_auc: 0.8822 - val_loss: 0.3979\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6612 - loss: 0.4936 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3925\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6733 - loss: 0.4907 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3888\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6824 - loss: 0.4884 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3858\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.6984 - loss: 0.4867 - val_accuracy: 0.8333 - val_auc: 0.9089 - val_loss: 0.3832\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7248 - loss: 0.4849 - val_accuracy: 0.8333 - val_auc: 0.9089 - val_loss: 0.3807\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7163 - loss: 0.4832 - val_accuracy: 0.8333 - val_auc: 0.8956 - val_loss: 0.3781\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7230 - loss: 0.4814 - val_accuracy: 0.8333 - val_auc: 0.9133 - val_loss: 0.3753\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7632 - loss: 0.4796 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3723\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7766 - loss: 0.4779 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3692\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7943 - loss: 0.4762 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3660\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7957 - loss: 0.4743 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3624\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7927 - loss: 0.4721 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3581\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7915 - loss: 0.4698 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3531\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7954 - loss: 0.4672 - val_accuracy: 0.8333 - val_auc: 0.9333 - val_loss: 0.3475\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7987 - loss: 0.4646 - val_accuracy: 0.8333 - val_auc: 0.9378 - val_loss: 0.3413\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8005 - loss: 0.4623 - val_accuracy: 0.8333 - val_auc: 0.9378 - val_loss: 0.3350\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7995 - loss: 0.4601 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.3291\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8038 - loss: 0.4582 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.3238\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8065 - loss: 0.4560 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.3186\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8081 - loss: 0.4546 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.3139\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8035 - loss: 0.4526 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.3095\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8012 - loss: 0.4513 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.3056\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8033 - loss: 0.4492 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3015\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8117 - loss: 0.4479 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.2978\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8023 - loss: 0.4460 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.2941\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8026 - loss: 0.4438 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.2899\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8110 - loss: 0.4426 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.2867\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8099 - loss: 0.4395 - val_accuracy: 0.8333 - val_auc: 0.9378 - val_loss: 0.2828\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8104 - loss: 0.4372 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.2799\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8035 - loss: 0.4352 - val_accuracy: 0.8333 - val_auc: 0.9378 - val_loss: 0.2794\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7992 - loss: 0.4307 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.2799\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8024 - loss: 0.4274 - val_accuracy: 0.8000 - val_auc: 0.9156 - val_loss: 0.2877\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.7995 - loss: 0.4257 - val_accuracy: 0.8000 - val_auc: 0.9156 - val_loss: 0.2860\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8091 - loss: 0.4215 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.2706\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8139 - loss: 0.4162 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.2670\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7266 - auc: 0.8149 - loss: 0.4165 - val_accuracy: 0.8333 - val_auc: 0.9178 - val_loss: 0.2687\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8224 - loss: 0.4158 - val_accuracy: 0.8333 - val_auc: 0.9378 - val_loss: 0.2658\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8198 - loss: 0.4068 - val_accuracy: 0.8000 - val_auc: 0.9156 - val_loss: 0.2720\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7339 - auc: 0.8080 - loss: 0.4086 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.2977\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8115 - loss: 0.4149 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.2784\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8236 - loss: 0.4015 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.2741\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.6905 - auc: 0.8172 - loss: 0.4020 - val_accuracy: 0.8000 - val_auc: 0.9156 - val_loss: 0.3234\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7068 - auc: 0.8075 - loss: 0.4007 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.3221\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8197 - loss: 0.4075 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.3462\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7451 - auc: 0.8302 - loss: 0.3960 - val_accuracy: 0.8000 - val_auc: 0.9022 - val_loss: 0.4169\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.6587 - auc: 0.8041 - loss: 0.4153 - val_accuracy: 0.8333 - val_auc: 0.9178 - val_loss: 0.3008\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8458 - loss: 0.4030 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.3741\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7314 - auc: 0.8081 - loss: 0.4073 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.4136\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7398 - auc: 0.8237 - loss: 0.4033 - val_accuracy: 0.8000 - val_auc: 0.9244 - val_loss: 0.4052\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8186 - loss: 0.3898 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.4249\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7339 - auc: 0.8186 - loss: 0.4028 - val_accuracy: 0.8000 - val_auc: 0.9200 - val_loss: 0.4102\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8463 - loss: 0.3864 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.4226\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7339 - auc: 0.8210 - loss: 0.3935 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.4258\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8226 - loss: 0.3879 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.4204\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8260 - loss: 0.3853 - val_accuracy: 0.8000 - val_auc: 0.9289 - val_loss: 0.4183\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7339 - auc: 0.8360 - loss: 0.3893 - val_accuracy: 0.8000 - val_auc: 0.9511 - val_loss: 0.4034\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8465 - loss: 0.3798 - val_accuracy: 0.8000 - val_auc: 0.9356 - val_loss: 0.4044\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7420 - auc: 0.8443 - loss: 0.3835 - val_accuracy: 0.8000 - val_auc: 0.9711 - val_loss: 0.3981\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8692 - loss: 0.3808 - val_accuracy: 0.8000 - val_auc: 0.9756 - val_loss: 0.3865\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8670 - loss: 0.3745 - val_accuracy: 0.8000 - val_auc: 0.9533 - val_loss: 0.3921\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7195 - auc: 0.8650 - loss: 0.3796 - val_accuracy: 0.8000 - val_auc: 0.9756 - val_loss: 0.3802\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8836 - loss: 0.3738 - val_accuracy: 0.8000 - val_auc: 0.9711 - val_loss: 0.3724\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.8823 - loss: 0.3691 - val_accuracy: 0.8333 - val_auc: 0.9756 - val_loss: 0.3766\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7762 - auc: 0.8739 - loss: 0.3748 - val_accuracy: 0.8000 - val_auc: 0.9756 - val_loss: 0.3569\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7696 - auc: 0.9025 - loss: 0.3673 - val_accuracy: 0.8000 - val_auc: 0.9756 - val_loss: 0.3532\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7564 - auc: 0.8902 - loss: 0.3636 - val_accuracy: 0.9000 - val_auc: 0.9756 - val_loss: 0.3560\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7746 - auc: 0.9014 - loss: 0.3686 - val_accuracy: 0.8000 - val_auc: 0.9756 - val_loss: 0.3318\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7696 - auc: 0.9107 - loss: 0.3602 - val_accuracy: 0.8667 - val_auc: 0.9733 - val_loss: 0.3324\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7664 - auc: 0.9035 - loss: 0.3569 - val_accuracy: 0.9000 - val_auc: 0.9756 - val_loss: 0.3324\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7823 - auc: 0.9111 - loss: 0.3611 - val_accuracy: 0.8000 - val_auc: 0.9667 - val_loss: 0.3072\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.9095 - loss: 0.3537 - val_accuracy: 0.9000 - val_auc: 0.9756 - val_loss: 0.3086\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7689 - auc: 0.9135 - loss: 0.3477 - val_accuracy: 0.9000 - val_auc: 0.9756 - val_loss: 0.3069\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7975 - auc: 0.9150 - loss: 0.3429 - val_accuracy: 0.8667 - val_auc: 0.9756 - val_loss: 0.2995\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8228 - auc: 0.9168 - loss: 0.3556 - val_accuracy: 0.8667 - val_auc: 0.9622 - val_loss: 0.2897\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7658 - auc: 0.9135 - loss: 0.3433 - val_accuracy: 0.9000 - val_auc: 0.9756 - val_loss: 0.2860\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8000 - auc: 0.9212 - loss: 0.3361 - val_accuracy: 0.9000 - val_auc: 0.9778 - val_loss: 0.2813\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7669 - auc: 0.9237 - loss: 0.3340 - val_accuracy: 0.8667 - val_auc: 0.9756 - val_loss: 0.2821\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7823 - auc: 0.9161 - loss: 0.3477 - val_accuracy: 0.8333 - val_auc: 0.9622 - val_loss: 0.2741\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7694 - auc: 0.9198 - loss: 0.3359 - val_accuracy: 0.9000 - val_auc: 0.9778 - val_loss: 0.2686\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9204 - loss: 0.3308 - val_accuracy: 0.9000 - val_auc: 0.9778 - val_loss: 0.2675\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9201 - loss: 0.3357 - val_accuracy: 0.8667 - val_auc: 0.9644 - val_loss: 0.2586\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7750 - auc: 0.9241 - loss: 0.3292 - val_accuracy: 0.9000 - val_auc: 0.9733 - val_loss: 0.2541\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8190 - auc: 0.9273 - loss: 0.3231 - val_accuracy: 0.9000 - val_auc: 0.9778 - val_loss: 0.2493\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8154 - auc: 0.9350 - loss: 0.3182 - val_accuracy: 0.9000 - val_auc: 0.9733 - val_loss: 0.2438\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8154 - auc: 0.9375 - loss: 0.3165 - val_accuracy: 0.9000 - val_auc: 0.9778 - val_loss: 0.2433\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8190 - auc: 0.9342 - loss: 0.3166 - val_accuracy: 0.9000 - val_auc: 0.9778 - val_loss: 0.2460\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9267 - loss: 0.3214 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2420\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9267 - loss: 0.3214 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2388\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9319 - loss: 0.3154 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2387\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9298 - loss: 0.3138 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2369\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9298 - loss: 0.3125 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2357\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9322 - loss: 0.3096 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2350\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9364 - loss: 0.3060 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2345\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8190 - auc: 0.9389 - loss: 0.3029 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2351\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8190 - auc: 0.9432 - loss: 0.3002 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2338\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8407 - auc: 0.9443 - loss: 0.2976 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2222\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8346 - auc: 0.9474 - loss: 0.3044 - val_accuracy: 0.9000 - val_auc: 0.9867 - val_loss: 0.2041\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8063 - auc: 0.9322 - loss: 0.3338 - val_accuracy: 0.9333 - val_auc: 0.9956 - val_loss: 0.1736\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8011 - auc: 0.9323 - loss: 0.3140 - val_accuracy: 0.9000 - val_auc: 0.9867 - val_loss: 0.1971\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8228 - auc: 0.9316 - loss: 0.3233 - val_accuracy: 0.8667 - val_auc: 0.9778 - val_loss: 0.2134\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8340 - auc: 0.9395 - loss: 0.3014 - val_accuracy: 0.9333 - val_auc: 0.9733 - val_loss: 0.2501\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8247 - auc: 0.9399 - loss: 0.3038 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2732\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9295 - loss: 0.3112 - val_accuracy: 0.8667 - val_auc: 0.9644 - val_loss: 0.2783\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7990 - auc: 0.9407 - loss: 0.2957 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2942\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8247 - auc: 0.9413 - loss: 0.2972 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.3018\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8165 - auc: 0.9303 - loss: 0.3105 - val_accuracy: 0.8667 - val_auc: 0.9644 - val_loss: 0.2866\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8092 - auc: 0.9388 - loss: 0.2964 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2858\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8201 - auc: 0.9451 - loss: 0.2903 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2899\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8589 - auc: 0.9407 - loss: 0.2949 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2875\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8247 - auc: 0.9376 - loss: 0.2945 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2886\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8201 - auc: 0.9430 - loss: 0.2891 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2936\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8507 - auc: 0.9440 - loss: 0.2868 - val_accuracy: 0.8667 - val_auc: 0.9689 - val_loss: 0.2968\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8201 - auc: 0.9457 - loss: 0.2853 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2993\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8599 - auc: 0.9457 - loss: 0.2836 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.3004\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8599 - auc: 0.9456 - loss: 0.2805 - val_accuracy: 0.9000 - val_auc: 0.9667 - val_loss: 0.2994\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8873 - auc: 0.9469 - loss: 0.2763 - val_accuracy: 0.9000 - val_auc: 0.9644 - val_loss: 0.2922\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8837 - auc: 0.9483 - loss: 0.2755 - val_accuracy: 0.8667 - val_auc: 0.9556 - val_loss: 0.2500\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8616 - auc: 0.9494 - loss: 0.3164 - val_accuracy: 0.9000 - val_auc: 0.9822 - val_loss: 0.1872\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.7379 - auc: 0.8955 - loss: 0.4268 - val_accuracy: 0.7333 - val_auc: 0.8756 - val_loss: 0.3993\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7542 - auc: 0.8332 - loss: 0.4472 - val_accuracy: 0.8667 - val_auc: 0.9556 - val_loss: 0.3636\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7368 - auc: 0.8857 - loss: 0.3557 - val_accuracy: 0.7333 - val_auc: 0.8867 - val_loss: 0.4583\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.6738 - auc: 0.8340 - loss: 0.4370 - val_accuracy: 0.8000 - val_auc: 0.9556 - val_loss: 0.4191\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.9319 - loss: 0.3676 - val_accuracy: 0.8000 - val_auc: 0.9511 - val_loss: 0.3751\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.7533 - auc: 0.8902 - loss: 0.3744 - val_accuracy: 0.8000 - val_auc: 0.9400 - val_loss: 0.3114\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7846 - auc: 0.8951 - loss: 0.4188 - val_accuracy: 0.8333 - val_auc: 0.9844 - val_loss: 0.2457\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7615 - auc: 0.9336 - loss: 0.3623 - val_accuracy: 0.8000 - val_auc: 0.9778 - val_loss: 0.2711\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7651 - auc: 0.8911 - loss: 0.3499 - val_accuracy: 0.9000 - val_auc: 0.9778 - val_loss: 0.2742\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7840 - auc: 0.9187 - loss: 0.3695 - val_accuracy: 0.8000 - val_auc: 0.9689 - val_loss: 0.2887\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7788 - auc: 0.9238 - loss: 0.3373 - val_accuracy: 0.8667 - val_auc: 0.9600 - val_loss: 0.2920\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8616 - auc: 0.9478 - loss: 0.3151 - val_accuracy: 0.9333 - val_auc: 0.9556 - val_loss: 0.3612\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8076 - auc: 0.9179 - loss: 0.3094 - val_accuracy: 0.8667 - val_auc: 0.9644 - val_loss: 0.3502\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8652 - auc: 0.9496 - loss: 0.2893 - val_accuracy: 0.8667 - val_auc: 0.9467 - val_loss: 0.3606\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8320 - auc: 0.9409 - loss: 0.2857 - val_accuracy: 0.9000 - val_auc: 0.9467 - val_loss: 0.3615\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8418 - auc: 0.9387 - loss: 0.2935 - val_accuracy: 0.9000 - val_auc: 0.9467 - val_loss: 0.3668\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8489 - auc: 0.9507 - loss: 0.2743 - val_accuracy: 0.9000 - val_auc: 0.9467 - val_loss: 0.3646\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8816 - auc: 0.9484 - loss: 0.2760 - val_accuracy: 0.9000 - val_auc: 0.9467 - val_loss: 0.3577\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8589 - auc: 0.9336 - loss: 0.2972 - val_accuracy: 0.9000 - val_auc: 0.9467 - val_loss: 0.3461\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8329 - auc: 0.9447 - loss: 0.2772 - val_accuracy: 0.9000 - val_auc: 0.9467 - val_loss: 0.3401\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8985 - auc: 0.9499 - loss: 0.2697 - val_accuracy: 0.9000 - val_auc: 0.9467 - val_loss: 0.3379\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8816 - auc: 0.9494 - loss: 0.2701 - val_accuracy: 0.9000 - val_auc: 0.9467 - val_loss: 0.3350\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8599 - auc: 0.9501 - loss: 0.2759 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.3238\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9414 - loss: 0.2703 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.3241\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8929 - auc: 0.9502 - loss: 0.2676 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.3225\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8929 - auc: 0.9425 - loss: 0.2667 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.3175\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8929 - auc: 0.9503 - loss: 0.2665 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.3105\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8929 - auc: 0.9503 - loss: 0.2668 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.3034\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8929 - auc: 0.9497 - loss: 0.2673 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2970\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9497 - loss: 0.2665 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2923\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9503 - loss: 0.2644 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2882\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8985 - auc: 0.9507 - loss: 0.2630 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2812\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8985 - auc: 0.9505 - loss: 0.2626 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2690\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8985 - auc: 0.9496 - loss: 0.2634 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2594\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9417 - loss: 0.2662 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2551\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8599 - auc: 0.9403 - loss: 0.2746 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2300\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8985 - auc: 0.9479 - loss: 0.2597 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2388\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8985 - auc: 0.9428 - loss: 0.2635 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2469\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9429 - loss: 0.2671 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2346\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9422 - loss: 0.2635 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2382\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9425 - loss: 0.2596 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2474\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9434 - loss: 0.2598 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2499\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9436 - loss: 0.2595 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2486\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9436 - loss: 0.2592 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2461\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9436 - loss: 0.2589 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2435\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9436 - loss: 0.2587 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2414\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9436 - loss: 0.2586 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2399\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9434 - loss: 0.2582 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2388\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9434 - loss: 0.2577 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2380\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9434 - loss: 0.2571 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2373\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9434 - loss: 0.2568 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2363\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9431 - loss: 0.2567 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2353\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9431 - loss: 0.2569 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2342\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9354 - loss: 0.2572 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2326\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9433 - loss: 0.2570 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2306\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9431 - loss: 0.2557 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2300\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9436 - loss: 0.2549 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2296\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9436 - loss: 0.2547 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2290\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9439 - loss: 0.2549 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2286\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9440 - loss: 0.2555 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2286\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9440 - loss: 0.2564 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2264\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9440 - loss: 0.2555 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2252\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9440 - loss: 0.2538 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2268\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9448 - loss: 0.2534 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2277\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9451 - loss: 0.2535 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2282\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9451 - loss: 0.2541 - val_accuracy: 0.9000 - val_auc: 0.9689 - val_loss: 0.2281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [29:25, 1765.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 2s/step - accuracy: 0.5494 - auc: 0.3219 - loss: 0.6943 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6940\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.5494 - auc: 0.5326 - loss: 0.6894 - val_accuracy: 0.5000 - val_auc: 0.7000 - val_loss: 0.6925\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5494 - auc: 0.5978 - loss: 0.6895 - val_accuracy: 0.5000 - val_auc: 0.7800 - val_loss: 0.6893\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5494 - auc: 0.6966 - loss: 0.6872 - val_accuracy: 0.5000 - val_auc: 0.7867 - val_loss: 0.6796\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.5203 - auc: 0.7412 - loss: 0.6769 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.6647\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7667 - auc: 0.7755 - loss: 0.6637 - val_accuracy: 0.7667 - val_auc: 0.7600 - val_loss: 0.6390\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7287 - auc: 0.7331 - loss: 0.6362 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.6077\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7441 - auc: 0.7681 - loss: 0.6014 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.5677\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7287 - auc: 0.7621 - loss: 0.5620 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.5274\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7554 - auc: 0.7882 - loss: 0.5209 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4920\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7554 - auc: 0.7894 - loss: 0.4894 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4643\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7667 - auc: 0.7894 - loss: 0.4672 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4446\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7667 - auc: 0.7892 - loss: 0.4555 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4332\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7667 - auc: 0.7938 - loss: 0.4520 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4279\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7667 - auc: 0.7996 - loss: 0.4527 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4255\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7667 - auc: 0.7655 - loss: 0.4540 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4237\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.7667 - auc: 0.7864 - loss: 0.4536 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4223\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783ms/step - accuracy: 0.7667 - auc: 0.7741 - loss: 0.4520 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4214\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.7667 - auc: 0.7885 - loss: 0.4503 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4212\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 751ms/step - accuracy: 0.7667 - auc: 0.7673 - loss: 0.4492 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4199\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.7667 - auc: 0.7938 - loss: 0.4479 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4196\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.7667 - auc: 0.7951 - loss: 0.4473 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4191\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.7667 - auc: 0.8238 - loss: 0.4470 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.4187\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 747ms/step - accuracy: 0.7667 - auc: 0.7946 - loss: 0.4471 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4188\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.7667 - auc: 0.8006 - loss: 0.4471 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.4178\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 732ms/step - accuracy: 0.7667 - auc: 0.8099 - loss: 0.4463 - val_accuracy: 0.8000 - val_auc: 0.8400 - val_loss: 0.4175\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 746ms/step - accuracy: 0.7667 - auc: 0.8099 - loss: 0.4457 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.4170\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.7667 - auc: 0.8242 - loss: 0.4454 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.4165\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.7667 - auc: 0.8170 - loss: 0.4453 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.4165\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.7667 - auc: 0.8147 - loss: 0.4452 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.4156\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 742ms/step - accuracy: 0.7667 - auc: 0.8296 - loss: 0.4442 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.4152\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 742ms/step - accuracy: 0.7667 - auc: 0.7918 - loss: 0.4436 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.4147\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.7667 - auc: 0.8357 - loss: 0.4434 - val_accuracy: 0.8000 - val_auc: 0.8733 - val_loss: 0.4142\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.7667 - auc: 0.8225 - loss: 0.4434 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.4139\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 738ms/step - accuracy: 0.7667 - auc: 0.8340 - loss: 0.4432 - val_accuracy: 0.8000 - val_auc: 0.8867 - val_loss: 0.4131\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 738ms/step - accuracy: 0.7667 - auc: 0.8131 - loss: 0.4423 - val_accuracy: 0.8000 - val_auc: 0.9111 - val_loss: 0.4125\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7667 - auc: 0.8302 - loss: 0.4415 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.4126\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.7667 - auc: 0.8289 - loss: 0.4414 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.4114\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 742ms/step - accuracy: 0.7667 - auc: 0.8335 - loss: 0.4405 - val_accuracy: 0.8000 - val_auc: 0.9200 - val_loss: 0.4111\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.7667 - auc: 0.8303 - loss: 0.4401 - val_accuracy: 0.8000 - val_auc: 0.9000 - val_loss: 0.4105\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.7667 - auc: 0.8214 - loss: 0.4402 - val_accuracy: 0.8000 - val_auc: 0.9200 - val_loss: 0.4100\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 721ms/step - accuracy: 0.7667 - auc: 0.8333 - loss: 0.4402 - val_accuracy: 0.8000 - val_auc: 0.9200 - val_loss: 0.4097\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765ms/step - accuracy: 0.7667 - auc: 0.8388 - loss: 0.4394 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.4084\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.7667 - auc: 0.8440 - loss: 0.4381 - val_accuracy: 0.8000 - val_auc: 0.9200 - val_loss: 0.4077\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.7667 - auc: 0.8366 - loss: 0.4373 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.4082\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.7667 - auc: 0.8388 - loss: 0.4377 - val_accuracy: 0.8000 - val_auc: 0.9200 - val_loss: 0.4065\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 720ms/step - accuracy: 0.7667 - auc: 0.8320 - loss: 0.4363 - val_accuracy: 0.8000 - val_auc: 0.9200 - val_loss: 0.4061\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 713ms/step - accuracy: 0.7667 - auc: 0.8387 - loss: 0.4357 - val_accuracy: 0.8000 - val_auc: 0.9200 - val_loss: 0.4053\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 711ms/step - accuracy: 0.7667 - auc: 0.8431 - loss: 0.4357 - val_accuracy: 0.8000 - val_auc: 0.9022 - val_loss: 0.4043\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 712ms/step - accuracy: 0.7667 - auc: 0.8384 - loss: 0.4356 - val_accuracy: 0.8000 - val_auc: 0.9200 - val_loss: 0.4045\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.7667 - auc: 0.8297 - loss: 0.4348 - val_accuracy: 0.8000 - val_auc: 0.9022 - val_loss: 0.4023\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.7667 - auc: 0.8379 - loss: 0.4323 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.4016\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.7667 - auc: 0.8379 - loss: 0.4312 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.4005\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 721ms/step - accuracy: 0.7667 - auc: 0.8366 - loss: 0.4314 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.3998\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7667 - auc: 0.8290 - loss: 0.4320 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.3981\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 720ms/step - accuracy: 0.7667 - auc: 0.8380 - loss: 0.4296 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.3968\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.7667 - auc: 0.8421 - loss: 0.4280 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3963\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.7667 - auc: 0.8417 - loss: 0.4273 - val_accuracy: 0.8000 - val_auc: 0.9222 - val_loss: 0.3942\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.7667 - auc: 0.8357 - loss: 0.4260 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.3940\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.7667 - auc: 0.8305 - loss: 0.4261 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.3917\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.7667 - auc: 0.8434 - loss: 0.4239 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3907\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7667 - auc: 0.8405 - loss: 0.4231 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3896\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.7667 - auc: 0.8367 - loss: 0.4241 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.3885\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7667 - auc: 0.8363 - loss: 0.4223 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.3875\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7667 - auc: 0.8379 - loss: 0.4209 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.3844\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 747ms/step - accuracy: 0.7667 - auc: 0.8398 - loss: 0.4183 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.3835\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 732ms/step - accuracy: 0.7667 - auc: 0.8378 - loss: 0.4189 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3844\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.7667 - auc: 0.8322 - loss: 0.4205 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3799\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 766ms/step - accuracy: 0.7667 - auc: 0.8421 - loss: 0.4143 - val_accuracy: 0.8000 - val_auc: 0.9111 - val_loss: 0.3784\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.7667 - auc: 0.8370 - loss: 0.4156 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.3807\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 749ms/step - accuracy: 0.7667 - auc: 0.8364 - loss: 0.4207 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.3749\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 743ms/step - accuracy: 0.7667 - auc: 0.8440 - loss: 0.4099 - val_accuracy: 0.8000 - val_auc: 0.9156 - val_loss: 0.3757\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.7667 - auc: 0.8398 - loss: 0.4134 - val_accuracy: 0.8000 - val_auc: 0.9156 - val_loss: 0.3743\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.7667 - auc: 0.8456 - loss: 0.4148 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.3707\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.7667 - auc: 0.8456 - loss: 0.4106 - val_accuracy: 0.8000 - val_auc: 0.9044 - val_loss: 0.3779\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.7667 - auc: 0.8389 - loss: 0.4145 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3676\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.7667 - auc: 0.8473 - loss: 0.4033 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4013\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.7667 - auc: 0.8406 - loss: 0.4171 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3658\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.7667 - auc: 0.8533 - loss: 0.3995 - val_accuracy: 0.7667 - val_auc: 0.8800 - val_loss: 0.5215\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 721ms/step - accuracy: 0.7610 - auc: 0.8313 - loss: 0.4291 - val_accuracy: 0.8000 - val_auc: 0.9111 - val_loss: 0.3683\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7667 - auc: 0.8574 - loss: 0.3982 - val_accuracy: 0.7667 - val_auc: 0.8800 - val_loss: 0.4284\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.7513 - auc: 0.8371 - loss: 0.4250 - val_accuracy: 0.8000 - val_auc: 0.9111 - val_loss: 0.3690\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.7667 - auc: 0.8566 - loss: 0.4150 - val_accuracy: 0.8000 - val_auc: 0.9111 - val_loss: 0.3689\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7667 - auc: 0.8495 - loss: 0.4081 - val_accuracy: 0.8000 - val_auc: 0.9111 - val_loss: 0.3686\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.7667 - auc: 0.8567 - loss: 0.4102 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3659\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 717ms/step - accuracy: 0.7667 - auc: 0.8575 - loss: 0.4072 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3638\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.7667 - auc: 0.8553 - loss: 0.4048 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3634\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7667 - auc: 0.8550 - loss: 0.4051 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3651\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.7667 - auc: 0.8524 - loss: 0.4050 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.3654\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7667 - auc: 0.8526 - loss: 0.4028 - val_accuracy: 0.8000 - val_auc: 0.9111 - val_loss: 0.3642\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7667 - auc: 0.8540 - loss: 0.4016 - val_accuracy: 0.8000 - val_auc: 0.9089 - val_loss: 0.3659\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.7667 - auc: 0.8549 - loss: 0.4016 - val_accuracy: 0.8000 - val_auc: 0.9022 - val_loss: 0.3680\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7667 - auc: 0.8557 - loss: 0.3997 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.3736\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 803ms/step - accuracy: 0.7585 - auc: 0.8556 - loss: 0.3977 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.3744\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 738ms/step - accuracy: 0.7585 - auc: 0.8651 - loss: 0.3955 - val_accuracy: 0.8000 - val_auc: 0.8956 - val_loss: 0.3779\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 748ms/step - accuracy: 0.7368 - auc: 0.8659 - loss: 0.3950 - val_accuracy: 0.8000 - val_auc: 0.8867 - val_loss: 0.3771\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.7368 - auc: 0.8667 - loss: 0.3895 - val_accuracy: 0.8000 - val_auc: 0.8756 - val_loss: 0.3961\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.7523 - auc: 0.8718 - loss: 0.3910 - val_accuracy: 0.8000 - val_auc: 0.8733 - val_loss: 0.3891\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7523 - auc: 0.8752 - loss: 0.3811 - val_accuracy: 0.8000 - val_auc: 0.8444 - val_loss: 0.4404\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.7790 - auc: 0.8679 - loss: 0.3892 - val_accuracy: 0.8000 - val_auc: 0.8689 - val_loss: 0.3933\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 716ms/step - accuracy: 0.7448 - auc: 0.8746 - loss: 0.3700 - val_accuracy: 0.7667 - val_auc: 0.8422 - val_loss: 0.5170\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7734 - auc: 0.8680 - loss: 0.3982 - val_accuracy: 0.8000 - val_auc: 0.8889 - val_loss: 0.3737\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.7335 - auc: 0.8838 - loss: 0.3626 - val_accuracy: 0.7667 - val_auc: 0.8444 - val_loss: 0.5861\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7585 - auc: 0.8667 - loss: 0.4015 - val_accuracy: 0.8000 - val_auc: 0.8711 - val_loss: 0.3918\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.7677 - auc: 0.8854 - loss: 0.3621 - val_accuracy: 0.7667 - val_auc: 0.8400 - val_loss: 0.5411\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 712ms/step - accuracy: 0.7523 - auc: 0.8721 - loss: 0.3770 - val_accuracy: 0.8000 - val_auc: 0.8444 - val_loss: 0.4857\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 715ms/step - accuracy: 0.7511 - auc: 0.8737 - loss: 0.3617 - val_accuracy: 0.8000 - val_auc: 0.8467 - val_loss: 0.5233\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 713ms/step - accuracy: 0.7454 - auc: 0.8701 - loss: 0.3660 - val_accuracy: 0.8000 - val_auc: 0.8444 - val_loss: 0.5106\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 750ms/step - accuracy: 0.7511 - auc: 0.8725 - loss: 0.3582 - val_accuracy: 0.7667 - val_auc: 0.8422 - val_loss: 0.5554\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.7454 - auc: 0.8707 - loss: 0.3621 - val_accuracy: 0.7667 - val_auc: 0.8422 - val_loss: 0.5271\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 718ms/step - accuracy: 0.7511 - auc: 0.8750 - loss: 0.3540 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.5976\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 717ms/step - accuracy: 0.7454 - auc: 0.8734 - loss: 0.3609 - val_accuracy: 0.7667 - val_auc: 0.8422 - val_loss: 0.5462\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 716ms/step - accuracy: 0.7511 - auc: 0.8758 - loss: 0.3512 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.6244\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 717ms/step - accuracy: 0.7454 - auc: 0.8728 - loss: 0.3590 - val_accuracy: 0.7667 - val_auc: 0.8378 - val_loss: 0.5681\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 717ms/step - accuracy: 0.7511 - auc: 0.8758 - loss: 0.3493 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.6395\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 714ms/step - accuracy: 0.7454 - auc: 0.8732 - loss: 0.3562 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.5929\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7511 - auc: 0.8747 - loss: 0.3484 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.6460\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 744ms/step - accuracy: 0.7454 - auc: 0.8748 - loss: 0.3530 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.6201\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 718ms/step - accuracy: 0.7511 - auc: 0.8749 - loss: 0.3480 - val_accuracy: 0.7667 - val_auc: 0.8244 - val_loss: 0.6510\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.7454 - auc: 0.8737 - loss: 0.3500 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.6447\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.7454 - auc: 0.8747 - loss: 0.3476 - val_accuracy: 0.7667 - val_auc: 0.8222 - val_loss: 0.6586\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.7454 - auc: 0.8747 - loss: 0.3477 - val_accuracy: 0.7667 - val_auc: 0.8244 - val_loss: 0.6635\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 732ms/step - accuracy: 0.7454 - auc: 0.8754 - loss: 0.3468 - val_accuracy: 0.7667 - val_auc: 0.8244 - val_loss: 0.6708\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783ms/step - accuracy: 0.7454 - auc: 0.8754 - loss: 0.3462 - val_accuracy: 0.7667 - val_auc: 0.8222 - val_loss: 0.6767\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.7300 - auc: 0.8773 - loss: 0.3456 - val_accuracy: 0.7667 - val_auc: 0.8156 - val_loss: 0.6834\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.7300 - auc: 0.8771 - loss: 0.3451 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.6909\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.7300 - auc: 0.8771 - loss: 0.3446 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.6972\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.7300 - auc: 0.8780 - loss: 0.3441 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.7058\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 745ms/step - accuracy: 0.7300 - auc: 0.8783 - loss: 0.3438 - val_accuracy: 0.7667 - val_auc: 0.8156 - val_loss: 0.7101\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 738ms/step - accuracy: 0.7300 - auc: 0.8785 - loss: 0.3431 - val_accuracy: 0.7667 - val_auc: 0.8156 - val_loss: 0.7200\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7300 - auc: 0.8791 - loss: 0.3430 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.7235\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 727ms/step - accuracy: 0.7300 - auc: 0.8788 - loss: 0.3422 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.7331\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.7300 - auc: 0.8795 - loss: 0.3421 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.7368\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.7300 - auc: 0.8839 - loss: 0.3414 - val_accuracy: 0.7667 - val_auc: 0.8156 - val_loss: 0.7447\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.7300 - auc: 0.8839 - loss: 0.3412 - val_accuracy: 0.7667 - val_auc: 0.8156 - val_loss: 0.7498\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 732ms/step - accuracy: 0.7300 - auc: 0.8891 - loss: 0.3406 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.7566\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.7300 - auc: 0.8852 - loss: 0.3403 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.7635\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.7300 - auc: 0.8879 - loss: 0.3399 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.7685\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.7300 - auc: 0.8855 - loss: 0.3393 - val_accuracy: 0.7667 - val_auc: 0.8156 - val_loss: 0.7752\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.7300 - auc: 0.8820 - loss: 0.3389 - val_accuracy: 0.7667 - val_auc: 0.8156 - val_loss: 0.7781\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.7300 - auc: 0.8821 - loss: 0.3381 - val_accuracy: 0.7667 - val_auc: 0.7956 - val_loss: 0.7855\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 720ms/step - accuracy: 0.7300 - auc: 0.8835 - loss: 0.3377 - val_accuracy: 0.7667 - val_auc: 0.7956 - val_loss: 0.7909\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.7300 - auc: 0.8830 - loss: 0.3370 - val_accuracy: 0.7667 - val_auc: 0.8000 - val_loss: 0.7957\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.7300 - auc: 0.8834 - loss: 0.3362 - val_accuracy: 0.7667 - val_auc: 0.8067 - val_loss: 0.8030\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.7300 - auc: 0.8821 - loss: 0.3356 - val_accuracy: 0.7667 - val_auc: 0.8067 - val_loss: 0.8067\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.7300 - auc: 0.8825 - loss: 0.3345 - val_accuracy: 0.7667 - val_auc: 0.8022 - val_loss: 0.8155\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 720ms/step - accuracy: 0.7381 - auc: 0.8876 - loss: 0.3339 - val_accuracy: 0.7667 - val_auc: 0.8022 - val_loss: 0.8168\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.7723 - auc: 0.8911 - loss: 0.3325 - val_accuracy: 0.7667 - val_auc: 0.8022 - val_loss: 0.8248\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 750ms/step - accuracy: 0.7723 - auc: 0.8909 - loss: 0.3318 - val_accuracy: 0.7667 - val_auc: 0.7956 - val_loss: 0.8305\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7723 - auc: 0.8907 - loss: 0.3308 - val_accuracy: 0.7667 - val_auc: 0.7933 - val_loss: 0.8358\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 743ms/step - accuracy: 0.7878 - auc: 0.8981 - loss: 0.3297 - val_accuracy: 0.7667 - val_auc: 0.7933 - val_loss: 0.8430\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.7878 - auc: 0.8968 - loss: 0.3288 - val_accuracy: 0.7667 - val_auc: 0.7956 - val_loss: 0.8471\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7878 - auc: 0.8991 - loss: 0.3275 - val_accuracy: 0.7667 - val_auc: 0.7956 - val_loss: 0.8539\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 724ms/step - accuracy: 0.7878 - auc: 0.9074 - loss: 0.3266 - val_accuracy: 0.7667 - val_auc: 0.7956 - val_loss: 0.8607\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8107 - auc: 0.9084 - loss: 0.3256 - val_accuracy: 0.7667 - val_auc: 0.7956 - val_loss: 0.8668\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.8107 - auc: 0.9112 - loss: 0.3246 - val_accuracy: 0.7667 - val_auc: 0.7956 - val_loss: 0.8743\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 716ms/step - accuracy: 0.8107 - auc: 0.9120 - loss: 0.3237 - val_accuracy: 0.8000 - val_auc: 0.7956 - val_loss: 0.8805\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 744ms/step - accuracy: 0.8107 - auc: 0.9128 - loss: 0.3227 - val_accuracy: 0.8000 - val_auc: 0.7956 - val_loss: 0.8880\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 718ms/step - accuracy: 0.8449 - auc: 0.9128 - loss: 0.3219 - val_accuracy: 0.8000 - val_auc: 0.7978 - val_loss: 0.8945\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.8485 - auc: 0.9140 - loss: 0.3210 - val_accuracy: 0.8000 - val_auc: 0.7978 - val_loss: 0.9019\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 756ms/step - accuracy: 0.8485 - auc: 0.9161 - loss: 0.3202 - val_accuracy: 0.8000 - val_auc: 0.7911 - val_loss: 0.9084\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.8485 - auc: 0.9153 - loss: 0.3194 - val_accuracy: 0.8000 - val_auc: 0.7911 - val_loss: 0.9156\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 721ms/step - accuracy: 0.8485 - auc: 0.9162 - loss: 0.3186 - val_accuracy: 0.8000 - val_auc: 0.7911 - val_loss: 0.9218\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.8566 - auc: 0.9162 - loss: 0.3178 - val_accuracy: 0.8000 - val_auc: 0.7911 - val_loss: 0.9288\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.8566 - auc: 0.9182 - loss: 0.3172 - val_accuracy: 0.8000 - val_auc: 0.7933 - val_loss: 0.9345\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.8566 - auc: 0.9200 - loss: 0.3164 - val_accuracy: 0.8000 - val_auc: 0.7933 - val_loss: 0.9413\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.8566 - auc: 0.9231 - loss: 0.3158 - val_accuracy: 0.8000 - val_auc: 0.7956 - val_loss: 0.9463\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.8566 - auc: 0.9245 - loss: 0.3151 - val_accuracy: 0.8000 - val_auc: 0.7956 - val_loss: 0.9528\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.8566 - auc: 0.9245 - loss: 0.3145 - val_accuracy: 0.8000 - val_auc: 0.7956 - val_loss: 0.9569\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.8566 - auc: 0.9260 - loss: 0.3138 - val_accuracy: 0.8000 - val_auc: 0.7956 - val_loss: 0.9636\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.8566 - auc: 0.9260 - loss: 0.3134 - val_accuracy: 0.8000 - val_auc: 0.7978 - val_loss: 0.9666\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 721ms/step - accuracy: 0.8566 - auc: 0.9261 - loss: 0.3125 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.9740\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8566 - auc: 0.9261 - loss: 0.3122 - val_accuracy: 0.8000 - val_auc: 0.8022 - val_loss: 0.9753\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 718ms/step - accuracy: 0.8566 - auc: 0.9261 - loss: 0.3113 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.9843\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8566 - auc: 0.9269 - loss: 0.3112 - val_accuracy: 0.8000 - val_auc: 0.8022 - val_loss: 0.9828\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.8566 - auc: 0.9268 - loss: 0.3100 - val_accuracy: 0.8000 - val_auc: 0.7911 - val_loss: 0.9952\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.8566 - auc: 0.9269 - loss: 0.3103 - val_accuracy: 0.8000 - val_auc: 0.8022 - val_loss: 0.9904\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.8679 - auc: 0.9276 - loss: 0.3089 - val_accuracy: 0.8000 - val_auc: 0.7889 - val_loss: 1.0077\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.8679 - auc: 0.9279 - loss: 0.3097 - val_accuracy: 0.8000 - val_auc: 0.8022 - val_loss: 0.9954\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.8679 - auc: 0.9279 - loss: 0.3076 - val_accuracy: 0.8000 - val_auc: 0.7911 - val_loss: 1.0217\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 718ms/step - accuracy: 0.8679 - auc: 0.9285 - loss: 0.3094 - val_accuracy: 0.8000 - val_auc: 0.8044 - val_loss: 0.9966\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.8679 - auc: 0.9278 - loss: 0.3059 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 1.0403\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.8679 - auc: 0.9285 - loss: 0.3097 - val_accuracy: 0.8000 - val_auc: 0.8044 - val_loss: 0.9911\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 727ms/step - accuracy: 0.8679 - auc: 0.9300 - loss: 0.3038 - val_accuracy: 0.8000 - val_auc: 0.8044 - val_loss: 1.0653\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8679 - auc: 0.9289 - loss: 0.3109 - val_accuracy: 0.8000 - val_auc: 0.8089 - val_loss: 0.9756\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.8679 - auc: 0.9312 - loss: 0.3010 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 1.0969\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.8622 - auc: 0.9242 - loss: 0.3135 - val_accuracy: 0.8000 - val_auc: 0.8067 - val_loss: 0.9463\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 743ms/step - accuracy: 0.8566 - auc: 0.9350 - loss: 0.2979 - val_accuracy: 0.8000 - val_auc: 0.7956 - val_loss: 1.1245\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.8587 - auc: 0.9222 - loss: 0.3163 - val_accuracy: 0.8000 - val_auc: 0.8067 - val_loss: 0.9218\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 715ms/step - accuracy: 0.8783 - auc: 0.9390 - loss: 0.2960 - val_accuracy: 0.8000 - val_auc: 0.8022 - val_loss: 1.1245\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792ms/step - accuracy: 0.8622 - auc: 0.9228 - loss: 0.3157 - val_accuracy: 0.8000 - val_auc: 0.8044 - val_loss: 0.9324\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.8566 - auc: 0.9366 - loss: 0.2960 - val_accuracy: 0.8000 - val_auc: 0.8044 - val_loss: 1.1015\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 721ms/step - accuracy: 0.8679 - auc: 0.9214 - loss: 0.3107 - val_accuracy: 0.8000 - val_auc: 0.8111 - val_loss: 0.9798\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8566 - auc: 0.9337 - loss: 0.2966 - val_accuracy: 0.8000 - val_auc: 0.8067 - val_loss: 1.0862\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8679 - auc: 0.9212 - loss: 0.3058 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.9939\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 743ms/step - accuracy: 0.8566 - auc: 0.9302 - loss: 0.2943 - val_accuracy: 0.8000 - val_auc: 0.8111 - val_loss: 1.0949\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.8622 - auc: 0.9217 - loss: 0.3023 - val_accuracy: 0.8000 - val_auc: 0.8022 - val_loss: 1.0008\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.8566 - auc: 0.9346 - loss: 0.2901 - val_accuracy: 0.8000 - val_auc: 0.8067 - val_loss: 1.1434\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.8474 - auc: 0.9219 - loss: 0.3047 - val_accuracy: 0.8000 - val_auc: 0.8111 - val_loss: 0.9659\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8554 - auc: 0.9403 - loss: 0.2854 - val_accuracy: 0.8000 - val_auc: 0.8022 - val_loss: 1.2292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [47:43, 1373.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 974ms/step - accuracy: 0.4979 - auc: 0.4517 - loss: 0.6938 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6945\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.5663 - auc: 0.4862 - loss: 0.6876 - val_accuracy: 0.5000 - val_auc: 0.8333 - val_loss: 0.6933\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.5663 - auc: 0.5756 - loss: 0.6887 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6921\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.5663 - auc: 0.6940 - loss: 0.6894 - val_accuracy: 0.5000 - val_auc: 0.8333 - val_loss: 0.6901\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.7430 - auc: 0.7631 - loss: 0.6886 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.6851\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 768ms/step - accuracy: 0.7841 - auc: 0.7364 - loss: 0.6843 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.6734\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 754ms/step - accuracy: 0.7841 - auc: 0.7592 - loss: 0.6718 - val_accuracy: 0.7667 - val_auc: 0.7889 - val_loss: 0.6515\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.7841 - auc: 0.7237 - loss: 0.6477 - val_accuracy: 0.7667 - val_auc: 0.7889 - val_loss: 0.6161\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7841 - auc: 0.7303 - loss: 0.6152 - val_accuracy: 0.7667 - val_auc: 0.7578 - val_loss: 0.5761\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.7841 - auc: 0.7437 - loss: 0.5796 - val_accuracy: 0.7667 - val_auc: 0.7889 - val_loss: 0.5363\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.7841 - auc: 0.7169 - loss: 0.5454 - val_accuracy: 0.7667 - val_auc: 0.7489 - val_loss: 0.4956\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.7841 - auc: 0.7220 - loss: 0.5103 - val_accuracy: 0.7667 - val_auc: 0.7889 - val_loss: 0.4581\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 746ms/step - accuracy: 0.7954 - auc: 0.7341 - loss: 0.4762 - val_accuracy: 0.8333 - val_auc: 0.7889 - val_loss: 0.4314\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 727ms/step - accuracy: 0.8171 - auc: 0.7335 - loss: 0.4539 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4167\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8171 - auc: 0.7477 - loss: 0.4425 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4080\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8171 - auc: 0.7293 - loss: 0.4363 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4021\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.8171 - auc: 0.7684 - loss: 0.4326 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3972\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.8001 - loss: 0.4300 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3926\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 743ms/step - accuracy: 0.8171 - auc: 0.8204 - loss: 0.4278 - val_accuracy: 0.8333 - val_auc: 0.8644 - val_loss: 0.3881\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 738ms/step - accuracy: 0.8171 - auc: 0.8075 - loss: 0.4258 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3850\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 732ms/step - accuracy: 0.8171 - auc: 0.8070 - loss: 0.4244 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3844\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.8171 - auc: 0.8164 - loss: 0.4233 - val_accuracy: 0.8333 - val_auc: 0.8667 - val_loss: 0.3818\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.8171 - auc: 0.8436 - loss: 0.4218 - val_accuracy: 0.8333 - val_auc: 0.8733 - val_loss: 0.3794\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 732ms/step - accuracy: 0.8171 - auc: 0.8502 - loss: 0.4203 - val_accuracy: 0.8333 - val_auc: 0.8978 - val_loss: 0.3777\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 753ms/step - accuracy: 0.8171 - auc: 0.8636 - loss: 0.4189 - val_accuracy: 0.8333 - val_auc: 0.9111 - val_loss: 0.3768\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 745ms/step - accuracy: 0.8171 - auc: 0.8753 - loss: 0.4177 - val_accuracy: 0.8333 - val_auc: 0.9178 - val_loss: 0.3751\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.8171 - auc: 0.8652 - loss: 0.4167 - val_accuracy: 0.8333 - val_auc: 0.9178 - val_loss: 0.3735\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8171 - auc: 0.8668 - loss: 0.4160 - val_accuracy: 0.8333 - val_auc: 0.9133 - val_loss: 0.3738\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 747ms/step - accuracy: 0.8171 - auc: 0.8528 - loss: 0.4152 - val_accuracy: 0.8333 - val_auc: 0.9133 - val_loss: 0.3707\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 749ms/step - accuracy: 0.8171 - auc: 0.8713 - loss: 0.4143 - val_accuracy: 0.8333 - val_auc: 0.9178 - val_loss: 0.3695\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 750ms/step - accuracy: 0.8171 - auc: 0.8707 - loss: 0.4133 - val_accuracy: 0.8333 - val_auc: 0.9200 - val_loss: 0.3698\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.8171 - auc: 0.8776 - loss: 0.4122 - val_accuracy: 0.8333 - val_auc: 0.9133 - val_loss: 0.3674\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.8171 - auc: 0.8688 - loss: 0.4115 - val_accuracy: 0.8333 - val_auc: 0.9133 - val_loss: 0.3667\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.8171 - auc: 0.8864 - loss: 0.4106 - val_accuracy: 0.8333 - val_auc: 0.9244 - val_loss: 0.3673\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.8790 - loss: 0.4097 - val_accuracy: 0.8333 - val_auc: 0.9200 - val_loss: 0.3636\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.8171 - auc: 0.8750 - loss: 0.4089 - val_accuracy: 0.8333 - val_auc: 0.9089 - val_loss: 0.3624\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8171 - auc: 0.8881 - loss: 0.4078 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.3620\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.8171 - auc: 0.8737 - loss: 0.4065 - val_accuracy: 0.8333 - val_auc: 0.9222 - val_loss: 0.3621\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.8879 - loss: 0.4056 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3587\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 720ms/step - accuracy: 0.8171 - auc: 0.8789 - loss: 0.4051 - val_accuracy: 0.8333 - val_auc: 0.9333 - val_loss: 0.3574\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.8171 - auc: 0.8791 - loss: 0.4038 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3571\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 723ms/step - accuracy: 0.8171 - auc: 0.8774 - loss: 0.4022 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3603\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8171 - auc: 0.8818 - loss: 0.4017 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3535\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 715ms/step - accuracy: 0.8171 - auc: 0.8809 - loss: 0.4009 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3521\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 720ms/step - accuracy: 0.8171 - auc: 0.8804 - loss: 0.3996 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.3518\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.8862 - loss: 0.3976 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3538\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.8872 - loss: 0.3968 - val_accuracy: 0.8333 - val_auc: 0.9222 - val_loss: 0.3485\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.8171 - auc: 0.8868 - loss: 0.3962 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3477\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.8171 - auc: 0.8826 - loss: 0.3945 - val_accuracy: 0.8333 - val_auc: 0.9222 - val_loss: 0.3497\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.8171 - auc: 0.8864 - loss: 0.3930 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.3445\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.8859 - loss: 0.3924 - val_accuracy: 0.8333 - val_auc: 0.9244 - val_loss: 0.3440\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.8881 - loss: 0.3898 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.3399\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.8171 - auc: 0.8847 - loss: 0.3848 - val_accuracy: 0.8333 - val_auc: 0.9244 - val_loss: 0.3315\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.8171 - auc: 0.8814 - loss: 0.3786 - val_accuracy: 0.8333 - val_auc: 0.9222 - val_loss: 0.3398\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.8171 - auc: 0.8871 - loss: 0.3771 - val_accuracy: 0.8333 - val_auc: 0.9222 - val_loss: 0.3261\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.8171 - auc: 0.8879 - loss: 0.3740 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.3253\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.8171 - auc: 0.8894 - loss: 0.3686 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3451\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.8889 - loss: 0.3677 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.3821\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.8171 - auc: 0.8891 - loss: 0.3645 - val_accuracy: 0.8333 - val_auc: 0.9044 - val_loss: 0.3376\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 732ms/step - accuracy: 0.8171 - auc: 0.8896 - loss: 0.3598 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.3908\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.8171 - auc: 0.8860 - loss: 0.3583 - val_accuracy: 0.7667 - val_auc: 0.8800 - val_loss: 0.5551\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.7784 - auc: 0.8377 - loss: 0.4449 - val_accuracy: 0.8333 - val_auc: 0.9222 - val_loss: 0.3249\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8171 - auc: 0.8802 - loss: 0.3689 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.8216\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.7841 - auc: 0.8478 - loss: 0.5996 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.7065\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774ms/step - accuracy: 0.7841 - auc: 0.8679 - loss: 0.4983 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3310\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 741ms/step - accuracy: 0.8171 - auc: 0.8845 - loss: 0.3787 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3325\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 732ms/step - accuracy: 0.8171 - auc: 0.8862 - loss: 0.3720 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3210\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.8878 - loss: 0.3663 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3189\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.8171 - auc: 0.8915 - loss: 0.3636 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.3185\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 732ms/step - accuracy: 0.8171 - auc: 0.8930 - loss: 0.3564 - val_accuracy: 0.8333 - val_auc: 0.9133 - val_loss: 0.3350\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 801ms/step - accuracy: 0.8171 - auc: 0.8935 - loss: 0.3529 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.3658\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 779ms/step - accuracy: 0.8171 - auc: 0.8912 - loss: 0.3532 - val_accuracy: 0.7667 - val_auc: 0.8889 - val_loss: 0.3874\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.8908 - loss: 0.3518 - val_accuracy: 0.7667 - val_auc: 0.8822 - val_loss: 0.3886\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.8171 - auc: 0.8912 - loss: 0.3493 - val_accuracy: 0.7667 - val_auc: 0.8844 - val_loss: 0.3868\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.8171 - auc: 0.8908 - loss: 0.3471 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.3946\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.8171 - auc: 0.8920 - loss: 0.3449 - val_accuracy: 0.7667 - val_auc: 0.8844 - val_loss: 0.4071\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 767ms/step - accuracy: 0.8171 - auc: 0.8891 - loss: 0.3441 - val_accuracy: 0.7667 - val_auc: 0.8844 - val_loss: 0.4324\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.8900 - loss: 0.3408 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4460\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.8171 - auc: 0.8915 - loss: 0.3376 - val_accuracy: 0.7667 - val_auc: 0.8800 - val_loss: 0.4528\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.8171 - auc: 0.8927 - loss: 0.3356 - val_accuracy: 0.7667 - val_auc: 0.8844 - val_loss: 0.4716\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.8930 - loss: 0.3307 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4735\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.8171 - auc: 0.8929 - loss: 0.3288 - val_accuracy: 0.7667 - val_auc: 0.8844 - val_loss: 0.4708\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.8171 - auc: 0.8921 - loss: 0.3282 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4810\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.8171 - auc: 0.8940 - loss: 0.3227 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4837\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 749ms/step - accuracy: 0.8171 - auc: 0.8931 - loss: 0.3265 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4886\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 754ms/step - accuracy: 0.8171 - auc: 0.8935 - loss: 0.3264 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4926\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 742ms/step - accuracy: 0.8171 - auc: 0.8943 - loss: 0.3202 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4874\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 728ms/step - accuracy: 0.8171 - auc: 0.8933 - loss: 0.3199 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4852\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.8171 - auc: 0.8937 - loss: 0.3258 - val_accuracy: 0.7667 - val_auc: 0.8844 - val_loss: 0.5028\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8171 - auc: 0.8949 - loss: 0.3167 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4926\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 725ms/step - accuracy: 0.8171 - auc: 0.8948 - loss: 0.3176 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4949\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8171 - auc: 0.8951 - loss: 0.3200 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5042\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.8171 - auc: 0.8951 - loss: 0.3161 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5131\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 719ms/step - accuracy: 0.8171 - auc: 0.8954 - loss: 0.3125 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5049\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.8171 - auc: 0.8948 - loss: 0.3125 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5061\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 754ms/step - accuracy: 0.8171 - auc: 0.8948 - loss: 0.3142 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5198\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 760ms/step - accuracy: 0.8171 - auc: 0.8959 - loss: 0.3112 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5216\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.8171 - auc: 0.8950 - loss: 0.3098 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5216\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 722ms/step - accuracy: 0.8171 - auc: 0.8959 - loss: 0.3096 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5367\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8171 - auc: 0.8959 - loss: 0.3064 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5387\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 743ms/step - accuracy: 0.8171 - auc: 0.8963 - loss: 0.3050 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5309\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 753ms/step - accuracy: 0.8171 - auc: 0.8980 - loss: 0.3101 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5543\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.8171 - auc: 0.8965 - loss: 0.3024 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5522\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 778ms/step - accuracy: 0.8171 - auc: 0.8984 - loss: 0.3042 - val_accuracy: 0.7667 - val_auc: 0.8822 - val_loss: 0.5762\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8171 - auc: 0.9013 - loss: 0.3011 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.5609\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.8967 - loss: 0.3039 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.5869\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 756ms/step - accuracy: 0.8171 - auc: 0.8994 - loss: 0.2991 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.5864\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 745ms/step - accuracy: 0.8171 - auc: 0.8983 - loss: 0.3053 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.6320\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.8171 - auc: 0.8967 - loss: 0.2979 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.5266\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 752ms/step - accuracy: 0.8171 - auc: 0.8989 - loss: 0.3064 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.5517\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8171 - auc: 0.8978 - loss: 0.2987 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.5780\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.8171 - auc: 0.9005 - loss: 0.3006 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.6520\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 748ms/step - accuracy: 0.8171 - auc: 0.9027 - loss: 0.2922 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.6051\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8171 - auc: 0.9044 - loss: 0.2994 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.6640\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 747ms/step - accuracy: 0.8171 - auc: 0.9016 - loss: 0.2939 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.6465\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 745ms/step - accuracy: 0.8171 - auc: 0.9036 - loss: 0.3029 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.7487\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8171 - auc: 0.9003 - loss: 0.2946 - val_accuracy: 0.8000 - val_auc: 0.8956 - val_loss: 0.4082\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 741ms/step - accuracy: 0.8171 - auc: 0.9038 - loss: 0.3051 - val_accuracy: 0.8000 - val_auc: 0.8911 - val_loss: 0.3973\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8171 - auc: 0.9026 - loss: 0.2971 - val_accuracy: 0.8000 - val_auc: 0.8911 - val_loss: 0.4019\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8171 - auc: 0.9061 - loss: 0.3020 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.5789\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.8171 - auc: 0.9074 - loss: 0.2864 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.6014\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 751ms/step - accuracy: 0.8171 - auc: 0.9062 - loss: 0.2937 - val_accuracy: 0.7667 - val_auc: 0.8244 - val_loss: 0.7524\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.8171 - auc: 0.9020 - loss: 0.2882 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.5838\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.8171 - auc: 0.9050 - loss: 0.2993 - val_accuracy: 0.7667 - val_auc: 0.8244 - val_loss: 0.7323\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.8171 - auc: 0.9016 - loss: 0.2893 - val_accuracy: 0.7333 - val_auc: 0.8778 - val_loss: 0.5796\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.8171 - auc: 0.9041 - loss: 0.3006 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.7737\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 726ms/step - accuracy: 0.8171 - auc: 0.9042 - loss: 0.2929 - val_accuracy: 0.8000 - val_auc: 0.9133 - val_loss: 0.3352\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.9038 - loss: 0.3117 - val_accuracy: 0.8333 - val_auc: 0.9022 - val_loss: 0.3681\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 761ms/step - accuracy: 0.8171 - auc: 0.8996 - loss: 0.2948 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.3240\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.9067 - loss: 0.3209 - val_accuracy: 0.7667 - val_auc: 0.8778 - val_loss: 0.4313\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.8171 - auc: 0.9127 - loss: 0.2820 - val_accuracy: 0.7667 - val_auc: 0.8756 - val_loss: 0.6311\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.8171 - auc: 0.9075 - loss: 0.2785 - val_accuracy: 0.7667 - val_auc: 0.8622 - val_loss: 0.6724\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.9045 - loss: 0.2829 - val_accuracy: 0.7667 - val_auc: 0.8178 - val_loss: 0.8436\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step - accuracy: 0.8171 - auc: 0.9026 - loss: 0.2872 - val_accuracy: 0.8333 - val_auc: 0.9089 - val_loss: 0.3461\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 745ms/step - accuracy: 0.8171 - auc: 0.9057 - loss: 0.2877 - val_accuracy: 0.8333 - val_auc: 0.9067 - val_loss: 0.3562\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 744ms/step - accuracy: 0.8171 - auc: 0.9019 - loss: 0.2830 - val_accuracy: 0.8000 - val_auc: 0.9178 - val_loss: 0.3272\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 753ms/step - accuracy: 0.8089 - auc: 0.9058 - loss: 0.2925 - val_accuracy: 0.7667 - val_auc: 0.8911 - val_loss: 0.3860\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8089 - auc: 0.9068 - loss: 0.2758 - val_accuracy: 0.7667 - val_auc: 0.8911 - val_loss: 0.4077\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 736ms/step - accuracy: 0.7747 - auc: 0.9048 - loss: 0.2792 - val_accuracy: 0.7333 - val_auc: 0.8667 - val_loss: 0.6451\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8089 - auc: 0.9028 - loss: 0.2718 - val_accuracy: 0.7333 - val_auc: 0.8378 - val_loss: 0.7077\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.7747 - auc: 0.9098 - loss: 0.2743 - val_accuracy: 0.7333 - val_auc: 0.8178 - val_loss: 0.8560\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step - accuracy: 0.7670 - auc: 0.9076 - loss: 0.2795 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4068\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 745ms/step - accuracy: 0.7747 - auc: 0.9131 - loss: 0.2739 - val_accuracy: 0.7667 - val_auc: 0.8822 - val_loss: 0.4486\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 735ms/step - accuracy: 0.7670 - auc: 0.9070 - loss: 0.2684 - val_accuracy: 0.7667 - val_auc: 0.8911 - val_loss: 0.3916\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 739ms/step - accuracy: 0.8012 - auc: 0.9126 - loss: 0.2728 - val_accuracy: 0.7333 - val_auc: 0.8600 - val_loss: 0.5875\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8012 - auc: 0.9066 - loss: 0.2661 - val_accuracy: 0.7667 - val_auc: 0.8800 - val_loss: 0.4473\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 743ms/step - accuracy: 0.7516 - auc: 0.9135 - loss: 0.2745 - val_accuracy: 0.7333 - val_auc: 0.8400 - val_loss: 0.7858\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 716ms/step - accuracy: 0.7858 - auc: 0.9086 - loss: 0.2728 - val_accuracy: 0.8333 - val_auc: 0.8756 - val_loss: 0.4165\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 716ms/step - accuracy: 0.7868 - auc: 0.9155 - loss: 0.2899 - val_accuracy: 0.7333 - val_auc: 0.8600 - val_loss: 0.6926\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 777ms/step - accuracy: 0.7597 - auc: 0.9059 - loss: 0.2600 - val_accuracy: 0.8000 - val_auc: 0.8644 - val_loss: 0.5409\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 760ms/step - accuracy: 0.7485 - auc: 0.9136 - loss: 0.2646 - val_accuracy: 0.8000 - val_auc: 0.8644 - val_loss: 0.6090\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 873ms/step - accuracy: 0.7826 - auc: 0.9125 - loss: 0.2561 - val_accuracy: 0.8000 - val_auc: 0.8756 - val_loss: 0.5425\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.8338 - auc: 0.9121 - loss: 0.2681 - val_accuracy: 0.8000 - val_auc: 0.8378 - val_loss: 0.8541\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.7755 - auc: 0.9112 - loss: 0.2580 - val_accuracy: 0.8000 - val_auc: 0.8956 - val_loss: 0.4634\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8338 - auc: 0.9153 - loss: 0.2670 - val_accuracy: 0.8000 - val_auc: 0.8422 - val_loss: 0.7455\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.7910 - auc: 0.9078 - loss: 0.2562 - val_accuracy: 0.7667 - val_auc: 0.8956 - val_loss: 0.4470\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.8363 - auc: 0.9141 - loss: 0.2641 - val_accuracy: 0.7667 - val_auc: 0.8556 - val_loss: 0.6420\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8451 - auc: 0.9129 - loss: 0.2541 - val_accuracy: 0.7667 - val_auc: 0.8556 - val_loss: 0.6718\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8363 - auc: 0.9125 - loss: 0.2515 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.5279\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8281 - auc: 0.9212 - loss: 0.2488 - val_accuracy: 0.8000 - val_auc: 0.8889 - val_loss: 0.5296\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830ms/step - accuracy: 0.8374 - auc: 0.9198 - loss: 0.2478 - val_accuracy: 0.8000 - val_auc: 0.8733 - val_loss: 0.6851\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8202 - auc: 0.9188 - loss: 0.2503 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.5229\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.8281 - auc: 0.9306 - loss: 0.2482 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.6875\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8269 - auc: 0.9291 - loss: 0.2445 - val_accuracy: 0.7333 - val_auc: 0.8222 - val_loss: 0.8604\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8146 - auc: 0.9090 - loss: 0.3017 - val_accuracy: 0.7667 - val_auc: 0.8489 - val_loss: 0.7749\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8225 - auc: 0.9182 - loss: 0.2700 - val_accuracy: 0.7333 - val_auc: 0.8311 - val_loss: 0.9351\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.7465 - auc: 0.8730 - loss: 0.3796 - val_accuracy: 0.8333 - val_auc: 0.9378 - val_loss: 0.3311\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.7732 - auc: 0.9217 - loss: 0.3193 - val_accuracy: 0.8333 - val_auc: 0.8911 - val_loss: 0.4662\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.7849 - auc: 0.9120 - loss: 0.2933 - val_accuracy: 0.8333 - val_auc: 0.9067 - val_loss: 0.4205\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.7782 - auc: 0.8967 - loss: 0.2953 - val_accuracy: 0.7667 - val_auc: 0.8889 - val_loss: 0.5411\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8054 - auc: 0.9053 - loss: 0.2823 - val_accuracy: 0.7667 - val_auc: 0.8844 - val_loss: 0.5175\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.8054 - auc: 0.9099 - loss: 0.2798 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.4196\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.8054 - auc: 0.9198 - loss: 0.2809 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.4394\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.7403 - auc: 0.9022 - loss: 0.2757 - val_accuracy: 0.8333 - val_auc: 0.9067 - val_loss: 0.4080\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.8240 - auc: 0.9114 - loss: 0.2762 - val_accuracy: 0.8000 - val_auc: 0.9067 - val_loss: 0.4274\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8090 - auc: 0.9122 - loss: 0.2690 - val_accuracy: 0.8333 - val_auc: 0.9089 - val_loss: 0.4175\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.8240 - auc: 0.9124 - loss: 0.2694 - val_accuracy: 0.8333 - val_auc: 0.9044 - val_loss: 0.4208\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8085 - auc: 0.9141 - loss: 0.2677 - val_accuracy: 0.8000 - val_auc: 0.8978 - val_loss: 0.4395\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.8085 - auc: 0.9130 - loss: 0.2672 - val_accuracy: 0.8000 - val_auc: 0.8978 - val_loss: 0.4840\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8085 - auc: 0.9125 - loss: 0.2652 - val_accuracy: 0.8000 - val_auc: 0.8756 - val_loss: 0.5397\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.8394 - auc: 0.9152 - loss: 0.2658 - val_accuracy: 0.7667 - val_auc: 0.8578 - val_loss: 0.6150\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.7743 - auc: 0.9055 - loss: 0.2614 - val_accuracy: 0.7667 - val_auc: 0.8578 - val_loss: 0.6618\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8394 - auc: 0.9162 - loss: 0.2616 - val_accuracy: 0.7667 - val_auc: 0.8556 - val_loss: 0.7557\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8173 - auc: 0.9246 - loss: 0.2570 - val_accuracy: 0.7667 - val_auc: 0.8556 - val_loss: 0.7959\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8281 - auc: 0.9113 - loss: 0.2580 - val_accuracy: 0.7667 - val_auc: 0.8400 - val_loss: 0.8876\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8281 - auc: 0.9113 - loss: 0.2550 - val_accuracy: 0.7667 - val_auc: 0.8467 - val_loss: 0.9444\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 861ms/step - accuracy: 0.8281 - auc: 0.9119 - loss: 0.2527 - val_accuracy: 0.7667 - val_auc: 0.8400 - val_loss: 0.9722\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8317 - auc: 0.9356 - loss: 0.2525 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.9786\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8281 - auc: 0.9356 - loss: 0.2510 - val_accuracy: 0.7667 - val_auc: 0.8400 - val_loss: 0.9179\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8419 - auc: 0.9404 - loss: 0.2554 - val_accuracy: 0.7667 - val_auc: 0.8222 - val_loss: 0.9088\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.8281 - auc: 0.9369 - loss: 0.2495 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.9055\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8363 - auc: 0.9316 - loss: 0.2493 - val_accuracy: 0.7667 - val_auc: 0.8200 - val_loss: 0.8868\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8363 - auc: 0.9213 - loss: 0.2466 - val_accuracy: 0.7667 - val_auc: 0.8200 - val_loss: 0.8930\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8419 - auc: 0.9257 - loss: 0.2461 - val_accuracy: 0.7667 - val_auc: 0.8200 - val_loss: 0.8832\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8363 - auc: 0.9129 - loss: 0.2447 - val_accuracy: 0.7667 - val_auc: 0.8200 - val_loss: 0.8967\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8338 - auc: 0.9095 - loss: 0.2436 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.8118\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8419 - auc: 0.9309 - loss: 0.2461 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.8568\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8202 - auc: 0.9294 - loss: 0.2414 - val_accuracy: 0.7667 - val_auc: 0.8556 - val_loss: 0.8029\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8363 - auc: 0.9385 - loss: 0.2420 - val_accuracy: 0.7667 - val_auc: 0.8556 - val_loss: 0.8266\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.8419 - auc: 0.9363 - loss: 0.2416 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.8740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [1:05:28, 1232.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 1s/step - accuracy: 0.5113 - auc: 0.4915 - loss: 0.6938 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6943\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.5113 - auc: 0.4870 - loss: 0.6933 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 856ms/step - accuracy: 0.4888 - auc: 0.4890 - loss: 0.6935 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.4888 - auc: 0.4753 - loss: 0.6938 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.4888 - auc: 0.4808 - loss: 0.6935 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.4703 - auc: 0.5149 - loss: 0.6929 - val_accuracy: 0.5000 - val_auc: 0.7000 - val_loss: 0.6923\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.5605 - auc: 0.6250 - loss: 0.6922 - val_accuracy: 0.5000 - val_auc: 0.8333 - val_loss: 0.6910\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.7012 - auc: 0.7192 - loss: 0.6905 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.6869\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.7925 - auc: 0.8018 - loss: 0.6856 - val_accuracy: 0.8333 - val_auc: 0.7667 - val_loss: 0.6779\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854ms/step - accuracy: 0.8038 - auc: 0.7622 - loss: 0.6749 - val_accuracy: 0.8333 - val_auc: 0.7667 - val_loss: 0.6596\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865ms/step - accuracy: 0.8038 - auc: 0.7754 - loss: 0.6539 - val_accuracy: 0.8333 - val_auc: 0.7667 - val_loss: 0.6268\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 856ms/step - accuracy: 0.8038 - auc: 0.7888 - loss: 0.6182 - val_accuracy: 0.8333 - val_auc: 0.7667 - val_loss: 0.5759\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.8038 - auc: 0.7908 - loss: 0.5709 - val_accuracy: 0.8333 - val_auc: 0.7222 - val_loss: 0.5259\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8038 - auc: 0.7578 - loss: 0.5311 - val_accuracy: 0.8333 - val_auc: 0.7667 - val_loss: 0.4850\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8038 - auc: 0.7792 - loss: 0.4924 - val_accuracy: 0.8333 - val_auc: 0.7667 - val_loss: 0.4534\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8038 - auc: 0.7624 - loss: 0.4631 - val_accuracy: 0.8333 - val_auc: 0.7667 - val_loss: 0.4331\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8038 - auc: 0.7736 - loss: 0.4447 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4181\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8038 - auc: 0.7735 - loss: 0.4340 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4085\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.8038 - auc: 0.7680 - loss: 0.4278 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4037\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.8038 - auc: 0.7680 - loss: 0.4238 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3996\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8038 - auc: 0.7725 - loss: 0.4215 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3961\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8038 - auc: 0.7822 - loss: 0.4198 - val_accuracy: 0.8333 - val_auc: 0.8644 - val_loss: 0.3937\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.8038 - auc: 0.7737 - loss: 0.4186 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3918\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8038 - auc: 0.7904 - loss: 0.4176 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3900\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8038 - auc: 0.7904 - loss: 0.4168 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3885\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.8038 - auc: 0.7955 - loss: 0.4161 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3872\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 983ms/step - accuracy: 0.8038 - auc: 0.7955 - loss: 0.4156 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3860\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 970ms/step - accuracy: 0.8038 - auc: 0.7904 - loss: 0.4151 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3851\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 907ms/step - accuracy: 0.8038 - auc: 0.7902 - loss: 0.4146 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3841\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.8038 - auc: 0.7902 - loss: 0.4142 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3833\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8038 - auc: 0.7866 - loss: 0.4139 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3826\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.8038 - auc: 0.8055 - loss: 0.4136 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3819\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 856ms/step - accuracy: 0.8038 - auc: 0.8016 - loss: 0.4133 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3812\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 956ms/step - accuracy: 0.8038 - auc: 0.8067 - loss: 0.4130 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3806\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8038 - auc: 0.8092 - loss: 0.4127 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3800\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8038 - auc: 0.8083 - loss: 0.4125 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3795\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8038 - auc: 0.8084 - loss: 0.4122 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.8038 - auc: 0.8122 - loss: 0.4120 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883ms/step - accuracy: 0.8038 - auc: 0.8122 - loss: 0.4118 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8038 - auc: 0.8116 - loss: 0.4116 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3772\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8038 - auc: 0.8261 - loss: 0.4113 - val_accuracy: 0.8333 - val_auc: 0.9000 - val_loss: 0.3764\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854ms/step - accuracy: 0.8038 - auc: 0.8212 - loss: 0.4110 - val_accuracy: 0.8333 - val_auc: 0.9400 - val_loss: 0.3749\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.8038 - auc: 0.8365 - loss: 0.4104 - val_accuracy: 0.8333 - val_auc: 0.9489 - val_loss: 0.3727\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864ms/step - accuracy: 0.8038 - auc: 0.8388 - loss: 0.4096 - val_accuracy: 0.8333 - val_auc: 0.9222 - val_loss: 0.3709\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8038 - auc: 0.8285 - loss: 0.4090 - val_accuracy: 0.8333 - val_auc: 0.9444 - val_loss: 0.3689\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8038 - auc: 0.8447 - loss: 0.4084 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3666\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8038 - auc: 0.8447 - loss: 0.4077 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3642\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.8038 - auc: 0.8569 - loss: 0.4069 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3618\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.8038 - auc: 0.8530 - loss: 0.4062 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3592\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 872ms/step - accuracy: 0.8038 - auc: 0.8554 - loss: 0.4054 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3565\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.8038 - auc: 0.8538 - loss: 0.4045 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3537\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8038 - auc: 0.8567 - loss: 0.4037 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3508\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8038 - auc: 0.8596 - loss: 0.4028 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3478\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8038 - auc: 0.8665 - loss: 0.4019 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3450\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8038 - auc: 0.8701 - loss: 0.4010 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3420\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.8038 - auc: 0.8672 - loss: 0.4001 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3391\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.8038 - auc: 0.8591 - loss: 0.3993 - val_accuracy: 0.8333 - val_auc: 0.9333 - val_loss: 0.3364\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.8038 - auc: 0.8629 - loss: 0.3985 - val_accuracy: 0.8333 - val_auc: 0.9333 - val_loss: 0.3337\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8038 - auc: 0.8635 - loss: 0.3977 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3313\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8038 - auc: 0.8717 - loss: 0.3970 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3289\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8038 - auc: 0.8641 - loss: 0.3963 - val_accuracy: 0.8333 - val_auc: 0.9356 - val_loss: 0.3267\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865ms/step - accuracy: 0.8038 - auc: 0.8673 - loss: 0.3955 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3247\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883ms/step - accuracy: 0.8038 - auc: 0.8645 - loss: 0.3949 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3227\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.8038 - auc: 0.8742 - loss: 0.3942 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3211\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8038 - auc: 0.8671 - loss: 0.3937 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3192\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8038 - auc: 0.8675 - loss: 0.3930 - val_accuracy: 0.8333 - val_auc: 0.9333 - val_loss: 0.3170\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8038 - auc: 0.8702 - loss: 0.3926 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3156\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8038 - auc: 0.8683 - loss: 0.3918 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3148\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.8038 - auc: 0.8681 - loss: 0.3919 - val_accuracy: 0.8333 - val_auc: 0.9311 - val_loss: 0.3139\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8038 - auc: 0.8755 - loss: 0.3909 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3127\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854ms/step - accuracy: 0.8038 - auc: 0.8764 - loss: 0.3906 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3128\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.8038 - auc: 0.8744 - loss: 0.3903 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3119\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8038 - auc: 0.8708 - loss: 0.3899 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3112\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8038 - auc: 0.8656 - loss: 0.3896 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3103\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.8038 - auc: 0.8662 - loss: 0.3892 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3096\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.8038 - auc: 0.8721 - loss: 0.3890 - val_accuracy: 0.8333 - val_auc: 0.9267 - val_loss: 0.3093\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8038 - auc: 0.8740 - loss: 0.3885 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3085\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8038 - auc: 0.8644 - loss: 0.3885 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3096\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.8038 - auc: 0.8740 - loss: 0.3879 - val_accuracy: 0.8333 - val_auc: 0.9289 - val_loss: 0.3120\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 881ms/step - accuracy: 0.8038 - auc: 0.8741 - loss: 0.3878 - val_accuracy: 0.8333 - val_auc: 0.9089 - val_loss: 0.3208\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8038 - auc: 0.8744 - loss: 0.3876 - val_accuracy: 0.8000 - val_auc: 0.9022 - val_loss: 0.3401\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8038 - auc: 0.8689 - loss: 0.3872 - val_accuracy: 0.8000 - val_auc: 0.8911 - val_loss: 0.3674\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8038 - auc: 0.8746 - loss: 0.3870 - val_accuracy: 0.7667 - val_auc: 0.8756 - val_loss: 0.4104\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8038 - auc: 0.8738 - loss: 0.3867 - val_accuracy: 0.7667 - val_auc: 0.8756 - val_loss: 0.4685\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.8038 - auc: 0.8719 - loss: 0.3865 - val_accuracy: 0.7667 - val_auc: 0.8756 - val_loss: 0.5084\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8038 - auc: 0.8720 - loss: 0.3864 - val_accuracy: 0.7667 - val_auc: 0.8578 - val_loss: 0.5795\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8038 - auc: 0.8730 - loss: 0.3857 - val_accuracy: 0.7667 - val_auc: 0.8578 - val_loss: 0.6553\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.7981 - auc: 0.8638 - loss: 0.3854 - val_accuracy: 0.7667 - val_auc: 0.8578 - val_loss: 0.6851\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.8038 - auc: 0.8692 - loss: 0.3857 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.7055\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8038 - auc: 0.8679 - loss: 0.3853 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.7237\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.7981 - auc: 0.8690 - loss: 0.3841 - val_accuracy: 0.7667 - val_auc: 0.8378 - val_loss: 0.7137\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8038 - auc: 0.8605 - loss: 0.3841 - val_accuracy: 0.7667 - val_auc: 0.8400 - val_loss: 0.7166\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867ms/step - accuracy: 0.8038 - auc: 0.8672 - loss: 0.3822 - val_accuracy: 0.7667 - val_auc: 0.8444 - val_loss: 0.7117\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.7981 - auc: 0.8622 - loss: 0.3822 - val_accuracy: 0.7667 - val_auc: 0.8644 - val_loss: 0.6877\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.8038 - auc: 0.8636 - loss: 0.3813 - val_accuracy: 0.7667 - val_auc: 0.8622 - val_loss: 0.6879\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7981 - auc: 0.8619 - loss: 0.3827 - val_accuracy: 0.7667 - val_auc: 0.8622 - val_loss: 0.5575\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.7981 - auc: 0.8676 - loss: 0.3795 - val_accuracy: 0.7667 - val_auc: 0.8644 - val_loss: 0.6043\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.7981 - auc: 0.8685 - loss: 0.3795 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.5156\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 826ms/step - accuracy: 0.8038 - auc: 0.8673 - loss: 0.3768 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.5140\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8038 - auc: 0.8693 - loss: 0.3773 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.5089\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8038 - auc: 0.8683 - loss: 0.3741 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.5118\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.7981 - auc: 0.8704 - loss: 0.3776 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.5070\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8038 - auc: 0.8693 - loss: 0.3741 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.5055\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8038 - auc: 0.8709 - loss: 0.3766 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.5026\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8038 - auc: 0.8704 - loss: 0.3720 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.4987\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8038 - auc: 0.8691 - loss: 0.3726 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.4991\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.8038 - auc: 0.8712 - loss: 0.3692 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.4974\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8038 - auc: 0.8702 - loss: 0.3696 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.4957\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.7981 - auc: 0.8750 - loss: 0.3673 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.4929\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.7981 - auc: 0.8719 - loss: 0.3672 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.4893\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8038 - auc: 0.8749 - loss: 0.3658 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.4862\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 866ms/step - accuracy: 0.8038 - auc: 0.8775 - loss: 0.3645 - val_accuracy: 0.8000 - val_auc: 0.8800 - val_loss: 0.4844\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 889ms/step - accuracy: 0.8038 - auc: 0.8812 - loss: 0.3634 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.4822\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.7981 - auc: 0.8842 - loss: 0.3633 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.4819\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8038 - auc: 0.8834 - loss: 0.3612 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.4759\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.8038 - auc: 0.8868 - loss: 0.3595 - val_accuracy: 0.8000 - val_auc: 0.8778 - val_loss: 0.4805\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.8038 - auc: 0.8870 - loss: 0.3576 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.4710\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.7981 - auc: 0.8899 - loss: 0.3592 - val_accuracy: 0.7000 - val_auc: 0.8511 - val_loss: 0.5437\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 888ms/step - accuracy: 0.8038 - auc: 0.8795 - loss: 0.3598 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.4873\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.7956 - auc: 0.8812 - loss: 0.3703 - val_accuracy: 0.7333 - val_auc: 0.7778 - val_loss: 0.8411\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.7771 - auc: 0.8410 - loss: 0.4531 - val_accuracy: 0.7000 - val_auc: 0.8022 - val_loss: 0.6142\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.6660 - auc: 0.8041 - loss: 0.5932 - val_accuracy: 0.7667 - val_auc: 0.8044 - val_loss: 0.4798\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8038 - auc: 0.7926 - loss: 0.4736 - val_accuracy: 0.7667 - val_auc: 0.7622 - val_loss: 0.4482\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8038 - auc: 0.7918 - loss: 0.4219 - val_accuracy: 0.8000 - val_auc: 0.7511 - val_loss: 0.4596\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.7899 - auc: 0.7854 - loss: 0.4190 - val_accuracy: 0.8000 - val_auc: 0.7622 - val_loss: 0.4972\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8002 - auc: 0.7959 - loss: 0.4317 - val_accuracy: 0.8000 - val_auc: 0.7844 - val_loss: 0.4993\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7981 - auc: 0.8058 - loss: 0.4163 - val_accuracy: 0.7667 - val_auc: 0.7533 - val_loss: 0.6039\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.8038 - auc: 0.7959 - loss: 0.4164 - val_accuracy: 0.8000 - val_auc: 0.8044 - val_loss: 0.5467\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8038 - auc: 0.7905 - loss: 0.4132 - val_accuracy: 0.7667 - val_auc: 0.8489 - val_loss: 0.5422\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8038 - auc: 0.8081 - loss: 0.4093 - val_accuracy: 0.7667 - val_auc: 0.7844 - val_loss: 0.5412\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.8038 - auc: 0.8611 - loss: 0.3986 - val_accuracy: 0.7667 - val_auc: 0.8511 - val_loss: 0.5687\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8038 - auc: 0.8649 - loss: 0.3938 - val_accuracy: 0.7667 - val_auc: 0.8222 - val_loss: 0.6012\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8038 - auc: 0.8721 - loss: 0.3907 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.5951\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8038 - auc: 0.8723 - loss: 0.3855 - val_accuracy: 0.7667 - val_auc: 0.8511 - val_loss: 0.5599\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8038 - auc: 0.8734 - loss: 0.3744 - val_accuracy: 0.7667 - val_auc: 0.8667 - val_loss: 0.5412\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8038 - auc: 0.8797 - loss: 0.3700 - val_accuracy: 0.7667 - val_auc: 0.8733 - val_loss: 0.5322\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.7981 - auc: 0.8758 - loss: 0.3711 - val_accuracy: 0.7667 - val_auc: 0.8711 - val_loss: 0.5395\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.8038 - auc: 0.8735 - loss: 0.3766 - val_accuracy: 0.7667 - val_auc: 0.8711 - val_loss: 0.5315\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8038 - auc: 0.8782 - loss: 0.3675 - val_accuracy: 0.7667 - val_auc: 0.8889 - val_loss: 0.5197\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7981 - auc: 0.8841 - loss: 0.3653 - val_accuracy: 0.7333 - val_auc: 0.8889 - val_loss: 0.5179\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.7868 - auc: 0.8758 - loss: 0.3688 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5144\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8038 - auc: 0.8754 - loss: 0.3679 - val_accuracy: 0.8000 - val_auc: 0.8889 - val_loss: 0.5151\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.8038 - auc: 0.8821 - loss: 0.3630 - val_accuracy: 0.8000 - val_auc: 0.8911 - val_loss: 0.5143\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.7981 - auc: 0.8829 - loss: 0.3680 - val_accuracy: 0.7333 - val_auc: 0.8844 - val_loss: 0.5202\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8038 - auc: 0.8811 - loss: 0.3680 - val_accuracy: 0.8000 - val_auc: 0.8889 - val_loss: 0.5054\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7981 - auc: 0.8776 - loss: 0.3663 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.5061\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.7868 - auc: 0.8873 - loss: 0.3606 - val_accuracy: 0.7333 - val_auc: 0.8844 - val_loss: 0.5017\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.7981 - auc: 0.8827 - loss: 0.3623 - val_accuracy: 0.7667 - val_auc: 0.8867 - val_loss: 0.4967\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.8038 - auc: 0.8803 - loss: 0.3592 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.4934\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8038 - auc: 0.8761 - loss: 0.3585 - val_accuracy: 0.8000 - val_auc: 0.8889 - val_loss: 0.4920\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8038 - auc: 0.8761 - loss: 0.3574 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.4932\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7981 - auc: 0.8895 - loss: 0.3561 - val_accuracy: 0.7667 - val_auc: 0.8911 - val_loss: 0.4938\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.7981 - auc: 0.8811 - loss: 0.3553 - val_accuracy: 0.7667 - val_auc: 0.8911 - val_loss: 0.4990\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8038 - auc: 0.8862 - loss: 0.3544 - val_accuracy: 0.7667 - val_auc: 0.8933 - val_loss: 0.4976\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7981 - auc: 0.8814 - loss: 0.3546 - val_accuracy: 0.7667 - val_auc: 0.8756 - val_loss: 0.5082\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7981 - auc: 0.8941 - loss: 0.3532 - val_accuracy: 0.7667 - val_auc: 0.8933 - val_loss: 0.5029\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.7832 - auc: 0.8896 - loss: 0.3585 - val_accuracy: 0.7000 - val_auc: 0.8733 - val_loss: 0.5305\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8038 - auc: 0.8890 - loss: 0.3641 - val_accuracy: 0.7667 - val_auc: 0.8733 - val_loss: 0.5150\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.8038 - auc: 0.8953 - loss: 0.3514 - val_accuracy: 0.7667 - val_auc: 0.8756 - val_loss: 0.5132\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8038 - auc: 0.9039 - loss: 0.3474 - val_accuracy: 0.7667 - val_auc: 0.8756 - val_loss: 0.5060\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809ms/step - accuracy: 0.7853 - auc: 0.9019 - loss: 0.3496 - val_accuracy: 0.7333 - val_auc: 0.8733 - val_loss: 0.5254\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 819ms/step - accuracy: 0.7666 - auc: 0.8967 - loss: 0.3502 - val_accuracy: 0.7000 - val_auc: 0.8756 - val_loss: 0.5244\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.7987 - auc: 0.8946 - loss: 0.3512 - val_accuracy: 0.7000 - val_auc: 0.8622 - val_loss: 0.5577\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.7868 - auc: 0.8978 - loss: 0.3483 - val_accuracy: 0.7000 - val_auc: 0.8711 - val_loss: 0.5491\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.8043 - auc: 0.9038 - loss: 0.3513 - val_accuracy: 0.7333 - val_auc: 0.8467 - val_loss: 0.5893\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.7589 - auc: 0.9010 - loss: 0.3518 - val_accuracy: 0.7000 - val_auc: 0.8489 - val_loss: 0.5788\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.7868 - auc: 0.8957 - loss: 0.3497 - val_accuracy: 0.7000 - val_auc: 0.8422 - val_loss: 0.5925\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.7797 - auc: 0.9011 - loss: 0.3433 - val_accuracy: 0.7000 - val_auc: 0.8467 - val_loss: 0.5972\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 796ms/step - accuracy: 0.7806 - auc: 0.8992 - loss: 0.3443 - val_accuracy: 0.7000 - val_auc: 0.8489 - val_loss: 0.5920\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.7797 - auc: 0.8979 - loss: 0.3402 - val_accuracy: 0.7333 - val_auc: 0.8489 - val_loss: 0.6004\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.7722 - auc: 0.9045 - loss: 0.3399 - val_accuracy: 0.8000 - val_auc: 0.8511 - val_loss: 0.6231\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 808ms/step - accuracy: 0.7722 - auc: 0.9077 - loss: 0.3403 - val_accuracy: 0.7333 - val_auc: 0.8511 - val_loss: 0.6304\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 884ms/step - accuracy: 0.7574 - auc: 0.9004 - loss: 0.3388 - val_accuracy: 0.7000 - val_auc: 0.8489 - val_loss: 0.6420\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882ms/step - accuracy: 0.7791 - auc: 0.9054 - loss: 0.3369 - val_accuracy: 0.7667 - val_auc: 0.8489 - val_loss: 0.6409\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.7804 - auc: 0.9059 - loss: 0.3358 - val_accuracy: 0.8333 - val_auc: 0.8400 - val_loss: 0.6680\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.7904 - auc: 0.9098 - loss: 0.3399 - val_accuracy: 0.7333 - val_auc: 0.8400 - val_loss: 0.6533\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.7610 - auc: 0.9006 - loss: 0.3353 - val_accuracy: 0.8000 - val_auc: 0.8422 - val_loss: 0.6781\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7722 - auc: 0.9134 - loss: 0.3372 - val_accuracy: 0.7667 - val_auc: 0.8378 - val_loss: 0.6641\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.7804 - auc: 0.9055 - loss: 0.3326 - val_accuracy: 0.8333 - val_auc: 0.8422 - val_loss: 0.6832\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.7687 - auc: 0.9038 - loss: 0.3370 - val_accuracy: 0.7667 - val_auc: 0.8422 - val_loss: 0.6662\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.7722 - auc: 0.9131 - loss: 0.3306 - val_accuracy: 0.8333 - val_auc: 0.8356 - val_loss: 0.6944\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.7967 - auc: 0.9087 - loss: 0.3357 - val_accuracy: 0.8000 - val_auc: 0.8422 - val_loss: 0.6788\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.7722 - auc: 0.9123 - loss: 0.3301 - val_accuracy: 0.8333 - val_auc: 0.8244 - val_loss: 0.6947\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.7687 - auc: 0.9068 - loss: 0.3349 - val_accuracy: 0.7333 - val_auc: 0.8378 - val_loss: 0.6747\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 880ms/step - accuracy: 0.7829 - auc: 0.9126 - loss: 0.3279 - val_accuracy: 0.7667 - val_auc: 0.8156 - val_loss: 0.7246\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 869ms/step - accuracy: 0.7904 - auc: 0.9183 - loss: 0.3464 - val_accuracy: 0.7333 - val_auc: 0.8222 - val_loss: 0.6887\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 811ms/step - accuracy: 0.7597 - auc: 0.9070 - loss: 0.3349 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.7422\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7785 - auc: 0.9218 - loss: 0.3531 - val_accuracy: 0.7000 - val_auc: 0.8289 - val_loss: 0.7119\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 812ms/step - accuracy: 0.7904 - auc: 0.9121 - loss: 0.3354 - val_accuracy: 0.8000 - val_auc: 0.8422 - val_loss: 0.7174\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.8127 - auc: 0.9354 - loss: 0.3329 - val_accuracy: 0.7667 - val_auc: 0.8511 - val_loss: 0.6986\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787ms/step - accuracy: 0.8029 - auc: 0.9120 - loss: 0.3320 - val_accuracy: 0.7667 - val_auc: 0.8556 - val_loss: 0.6964\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.8365 - auc: 0.9219 - loss: 0.3270 - val_accuracy: 0.7667 - val_auc: 0.8444 - val_loss: 0.7014\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.8146 - auc: 0.9180 - loss: 0.3286 - val_accuracy: 0.7667 - val_auc: 0.8400 - val_loss: 0.7191\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 796ms/step - accuracy: 0.8422 - auc: 0.9352 - loss: 0.3243 - val_accuracy: 0.7667 - val_auc: 0.8467 - val_loss: 0.7382\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 791ms/step - accuracy: 0.8146 - auc: 0.9213 - loss: 0.3252 - val_accuracy: 0.8000 - val_auc: 0.8444 - val_loss: 0.7444\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.8535 - auc: 0.9370 - loss: 0.3267 - val_accuracy: 0.7667 - val_auc: 0.8467 - val_loss: 0.7293\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 826ms/step - accuracy: 0.8227 - auc: 0.9195 - loss: 0.3220 - val_accuracy: 0.8000 - val_auc: 0.8533 - val_loss: 0.7204\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792ms/step - accuracy: 0.8535 - auc: 0.9350 - loss: 0.3249 - val_accuracy: 0.7667 - val_auc: 0.8578 - val_loss: 0.6971\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8227 - auc: 0.9255 - loss: 0.3210 - val_accuracy: 0.8000 - val_auc: 0.8578 - val_loss: 0.6955\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.8751 - auc: 0.9375 - loss: 0.3244 - val_accuracy: 0.7667 - val_auc: 0.8667 - val_loss: 0.6856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:25:16, 1214.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 1s/step - accuracy: 0.5346 - auc: 0.5129 - loss: 0.6949 - val_accuracy: 0.5000 - val_auc: 0.7000 - val_loss: 0.6942\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867ms/step - accuracy: 0.5346 - auc: 0.6363 - loss: 0.6879 - val_accuracy: 0.8000 - val_auc: 0.7333 - val_loss: 0.6906\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8012 - auc: 0.7531 - loss: 0.6890 - val_accuracy: 0.5000 - val_auc: 0.7733 - val_loss: 0.6867\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.5346 - auc: 0.7981 - loss: 0.6808 - val_accuracy: 0.5000 - val_auc: 0.7467 - val_loss: 0.6760\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 810ms/step - accuracy: 0.6736 - auc: 0.8326 - loss: 0.6607 - val_accuracy: 0.7333 - val_auc: 0.7467 - val_loss: 0.6573\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8258 - auc: 0.8064 - loss: 0.6411 - val_accuracy: 0.8000 - val_auc: 0.7067 - val_loss: 0.6326\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.8754 - auc: 0.7991 - loss: 0.6011 - val_accuracy: 0.7333 - val_auc: 0.7267 - val_loss: 0.6086\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.8600 - auc: 0.7957 - loss: 0.5644 - val_accuracy: 0.7333 - val_auc: 0.7111 - val_loss: 0.5803\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 852ms/step - accuracy: 0.8258 - auc: 0.7920 - loss: 0.5243 - val_accuracy: 0.7333 - val_auc: 0.7000 - val_loss: 0.5532\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.8258 - auc: 0.7907 - loss: 0.4881 - val_accuracy: 0.7333 - val_auc: 0.6933 - val_loss: 0.5288\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 797ms/step - accuracy: 0.8258 - auc: 0.7862 - loss: 0.4496 - val_accuracy: 0.7333 - val_auc: 0.7067 - val_loss: 0.5117\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 799ms/step - accuracy: 0.8258 - auc: 0.7884 - loss: 0.4214 - val_accuracy: 0.7333 - val_auc: 0.7222 - val_loss: 0.4993\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8258 - auc: 0.7922 - loss: 0.4046 - val_accuracy: 0.7333 - val_auc: 0.7400 - val_loss: 0.4895\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 804ms/step - accuracy: 0.8258 - auc: 0.7983 - loss: 0.3934 - val_accuracy: 0.7333 - val_auc: 0.7133 - val_loss: 0.4802\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783ms/step - accuracy: 0.8258 - auc: 0.7792 - loss: 0.3847 - val_accuracy: 0.7333 - val_auc: 0.6933 - val_loss: 0.4730\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 790ms/step - accuracy: 0.8258 - auc: 0.8130 - loss: 0.3780 - val_accuracy: 0.7333 - val_auc: 0.7200 - val_loss: 0.4668\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.8258 - auc: 0.8025 - loss: 0.3719 - val_accuracy: 0.7333 - val_auc: 0.7267 - val_loss: 0.4614\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792ms/step - accuracy: 0.8600 - auc: 0.7984 - loss: 0.3661 - val_accuracy: 0.7667 - val_auc: 0.7200 - val_loss: 0.4566\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 803ms/step - accuracy: 0.8754 - auc: 0.7948 - loss: 0.3609 - val_accuracy: 0.8000 - val_auc: 0.7467 - val_loss: 0.4519\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 797ms/step - accuracy: 0.8754 - auc: 0.8095 - loss: 0.3564 - val_accuracy: 0.8000 - val_auc: 0.7467 - val_loss: 0.4474\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.8754 - auc: 0.8095 - loss: 0.3525 - val_accuracy: 0.8000 - val_auc: 0.7467 - val_loss: 0.4434\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 793ms/step - accuracy: 0.8754 - auc: 0.8198 - loss: 0.3495 - val_accuracy: 0.8000 - val_auc: 0.7644 - val_loss: 0.4407\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792ms/step - accuracy: 0.8754 - auc: 0.8532 - loss: 0.3471 - val_accuracy: 0.8000 - val_auc: 0.8067 - val_loss: 0.4377\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.8754 - auc: 0.8601 - loss: 0.3444 - val_accuracy: 0.8000 - val_auc: 0.8067 - val_loss: 0.4340\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 790ms/step - accuracy: 0.8754 - auc: 0.8658 - loss: 0.3419 - val_accuracy: 0.8000 - val_auc: 0.8200 - val_loss: 0.4327\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830ms/step - accuracy: 0.8754 - auc: 0.8698 - loss: 0.3405 - val_accuracy: 0.8000 - val_auc: 0.8200 - val_loss: 0.4296\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 797ms/step - accuracy: 0.8754 - auc: 0.8745 - loss: 0.3384 - val_accuracy: 0.8000 - val_auc: 0.8200 - val_loss: 0.4282\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854ms/step - accuracy: 0.8754 - auc: 0.8742 - loss: 0.3372 - val_accuracy: 0.8000 - val_auc: 0.8200 - val_loss: 0.4256\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.8754 - auc: 0.8819 - loss: 0.3352 - val_accuracy: 0.8000 - val_auc: 0.8067 - val_loss: 0.4244\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 777ms/step - accuracy: 0.8754 - auc: 0.8819 - loss: 0.3336 - val_accuracy: 0.8000 - val_auc: 0.8200 - val_loss: 0.4218\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 779ms/step - accuracy: 0.8754 - auc: 0.8994 - loss: 0.3318 - val_accuracy: 0.8000 - val_auc: 0.8200 - val_loss: 0.4201\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 786ms/step - accuracy: 0.8754 - auc: 0.9018 - loss: 0.3303 - val_accuracy: 0.8000 - val_auc: 0.8200 - val_loss: 0.4182\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 794ms/step - accuracy: 0.8754 - auc: 0.9215 - loss: 0.3287 - val_accuracy: 0.8000 - val_auc: 0.8533 - val_loss: 0.4155\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 786ms/step - accuracy: 0.8754 - auc: 0.9374 - loss: 0.3272 - val_accuracy: 0.8000 - val_auc: 0.8578 - val_loss: 0.4143\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.8754 - auc: 0.9343 - loss: 0.3258 - val_accuracy: 0.8000 - val_auc: 0.8600 - val_loss: 0.4123\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 782ms/step - accuracy: 0.8754 - auc: 0.9346 - loss: 0.3242 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.4099\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787ms/step - accuracy: 0.8754 - auc: 0.9323 - loss: 0.3227 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.4080\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 790ms/step - accuracy: 0.8754 - auc: 0.9320 - loss: 0.3211 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.4062\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 793ms/step - accuracy: 0.8754 - auc: 0.9348 - loss: 0.3195 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.4041\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 804ms/step - accuracy: 0.8754 - auc: 0.9329 - loss: 0.3179 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.4019\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 790ms/step - accuracy: 0.8754 - auc: 0.9352 - loss: 0.3158 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.3996\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 785ms/step - accuracy: 0.8754 - auc: 0.9351 - loss: 0.3138 - val_accuracy: 0.8000 - val_auc: 0.8911 - val_loss: 0.3965\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.8754 - auc: 0.9336 - loss: 0.3109 - val_accuracy: 0.8000 - val_auc: 0.8867 - val_loss: 0.3931\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.8754 - auc: 0.9399 - loss: 0.3061 - val_accuracy: 0.8000 - val_auc: 0.8867 - val_loss: 0.3902\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 798ms/step - accuracy: 0.8754 - auc: 0.9400 - loss: 0.3064 - val_accuracy: 0.8000 - val_auc: 0.8867 - val_loss: 0.3883\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 799ms/step - accuracy: 0.8754 - auc: 0.9392 - loss: 0.3074 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.3872\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787ms/step - accuracy: 0.8754 - auc: 0.9327 - loss: 0.3028 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.3856\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 798ms/step - accuracy: 0.8754 - auc: 0.9452 - loss: 0.2979 - val_accuracy: 0.8000 - val_auc: 0.8889 - val_loss: 0.3825\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.8754 - auc: 0.9419 - loss: 0.3018 - val_accuracy: 0.8000 - val_auc: 0.8933 - val_loss: 0.3817\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.8754 - auc: 0.9367 - loss: 0.3000 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.3823\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 985ms/step - accuracy: 0.8754 - auc: 0.9402 - loss: 0.2933 - val_accuracy: 0.8000 - val_auc: 0.8889 - val_loss: 0.3791\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9444 - loss: 0.2925 - val_accuracy: 0.8000 - val_auc: 0.8867 - val_loss: 0.3767\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9441 - loss: 0.2951 - val_accuracy: 0.8000 - val_auc: 0.8889 - val_loss: 0.3768\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8754 - auc: 0.9428 - loss: 0.2917 - val_accuracy: 0.8000 - val_auc: 0.8867 - val_loss: 0.3768\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.8754 - auc: 0.9451 - loss: 0.2889 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.3753\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 939ms/step - accuracy: 0.8754 - auc: 0.9445 - loss: 0.2874 - val_accuracy: 0.8000 - val_auc: 0.8889 - val_loss: 0.3741\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9470 - loss: 0.2867 - val_accuracy: 0.8000 - val_auc: 0.8844 - val_loss: 0.3737\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9427 - loss: 0.2854 - val_accuracy: 0.8000 - val_auc: 0.8756 - val_loss: 0.3742\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9480 - loss: 0.2833 - val_accuracy: 0.8000 - val_auc: 0.8756 - val_loss: 0.3734\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8754 - auc: 0.9425 - loss: 0.2830 - val_accuracy: 0.8000 - val_auc: 0.8822 - val_loss: 0.3742\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9454 - loss: 0.2811 - val_accuracy: 0.8000 - val_auc: 0.8778 - val_loss: 0.3731\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 999ms/step - accuracy: 0.8754 - auc: 0.9418 - loss: 0.2823 - val_accuracy: 0.8000 - val_auc: 0.8689 - val_loss: 0.3792\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9437 - loss: 0.2778 - val_accuracy: 0.8000 - val_auc: 0.8733 - val_loss: 0.3778\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 968ms/step - accuracy: 0.8754 - auc: 0.9402 - loss: 0.2776 - val_accuracy: 0.8000 - val_auc: 0.8644 - val_loss: 0.3819\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 979ms/step - accuracy: 0.8754 - auc: 0.9443 - loss: 0.2760 - val_accuracy: 0.8000 - val_auc: 0.8644 - val_loss: 0.3818\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9403 - loss: 0.2762 - val_accuracy: 0.7667 - val_auc: 0.8400 - val_loss: 0.3970\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9446 - loss: 0.2737 - val_accuracy: 0.8000 - val_auc: 0.8444 - val_loss: 0.3899\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9417 - loss: 0.2744 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4199\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9447 - loss: 0.2707 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.4045\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8754 - auc: 0.9421 - loss: 0.2720 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4410\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 939ms/step - accuracy: 0.8754 - auc: 0.9444 - loss: 0.2690 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4267\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 918ms/step - accuracy: 0.8754 - auc: 0.9435 - loss: 0.2703 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4522\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 917ms/step - accuracy: 0.8754 - auc: 0.9432 - loss: 0.2687 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4738\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 870ms/step - accuracy: 0.8754 - auc: 0.9441 - loss: 0.2671 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4703\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.8754 - auc: 0.9427 - loss: 0.2666 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4510\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865ms/step - accuracy: 0.8754 - auc: 0.9457 - loss: 0.2666 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4555\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8754 - auc: 0.9438 - loss: 0.2668 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4932\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867ms/step - accuracy: 0.8754 - auc: 0.9471 - loss: 0.2639 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4591\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.8754 - auc: 0.9437 - loss: 0.2671 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.5244\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 868ms/step - accuracy: 0.8754 - auc: 0.9452 - loss: 0.2613 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4338\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.8754 - auc: 0.9457 - loss: 0.2660 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4453\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.8754 - auc: 0.9430 - loss: 0.2654 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.5053\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 950ms/step - accuracy: 0.8754 - auc: 0.9472 - loss: 0.2595 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4331\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 936ms/step - accuracy: 0.8754 - auc: 0.9443 - loss: 0.2651 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4926\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.8673 - auc: 0.9475 - loss: 0.2595 - val_accuracy: 0.7667 - val_auc: 0.8356 - val_loss: 0.4454\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 866ms/step - accuracy: 0.8673 - auc: 0.9450 - loss: 0.2637 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.4934\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 912ms/step - accuracy: 0.8673 - auc: 0.9471 - loss: 0.2587 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.4355\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 985ms/step - accuracy: 0.8673 - auc: 0.9449 - loss: 0.2631 - val_accuracy: 0.7667 - val_auc: 0.8289 - val_loss: 0.4785\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8673 - auc: 0.9458 - loss: 0.2602 - val_accuracy: 0.7667 - val_auc: 0.8289 - val_loss: 0.4837\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 956ms/step - accuracy: 0.8673 - auc: 0.9453 - loss: 0.2601 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.4517\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890ms/step - accuracy: 0.8673 - auc: 0.9461 - loss: 0.2601 - val_accuracy: 0.7667 - val_auc: 0.8289 - val_loss: 0.4465\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8673 - auc: 0.9453 - loss: 0.2602 - val_accuracy: 0.7667 - val_auc: 0.8289 - val_loss: 0.4771\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875ms/step - accuracy: 0.8673 - auc: 0.9463 - loss: 0.2585 - val_accuracy: 0.7667 - val_auc: 0.8289 - val_loss: 0.4587\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 986ms/step - accuracy: 0.8673 - auc: 0.9446 - loss: 0.2593 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.4505\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 934ms/step - accuracy: 0.8591 - auc: 0.9461 - loss: 0.2589 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.4577\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.8673 - auc: 0.9454 - loss: 0.2587 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.4398\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.8591 - auc: 0.9475 - loss: 0.2587 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.4435\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 911ms/step - accuracy: 0.8673 - auc: 0.9457 - loss: 0.2584 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.4319\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 888ms/step - accuracy: 0.8591 - auc: 0.9479 - loss: 0.2567 - val_accuracy: 0.8000 - val_auc: 0.8267 - val_loss: 0.4058\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 921ms/step - accuracy: 0.8673 - auc: 0.9460 - loss: 0.2591 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.4375\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.8591 - auc: 0.9484 - loss: 0.2547 - val_accuracy: 0.8000 - val_auc: 0.8311 - val_loss: 0.4034\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 891ms/step - accuracy: 0.8591 - auc: 0.9461 - loss: 0.2585 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.4314\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 940ms/step - accuracy: 0.8591 - auc: 0.9483 - loss: 0.2558 - val_accuracy: 0.7667 - val_auc: 0.8267 - val_loss: 0.4212\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900ms/step - accuracy: 0.8591 - auc: 0.9464 - loss: 0.2564 - val_accuracy: 0.8000 - val_auc: 0.8533 - val_loss: 0.3904\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 992ms/step - accuracy: 0.8591 - auc: 0.9470 - loss: 0.2565 - val_accuracy: 0.8000 - val_auc: 0.8578 - val_loss: 0.3900\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.8673 - auc: 0.9454 - loss: 0.2553 - val_accuracy: 0.8000 - val_auc: 0.8489 - val_loss: 0.3929\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.8591 - auc: 0.9480 - loss: 0.2538 - val_accuracy: 0.8000 - val_auc: 0.8533 - val_loss: 0.3913\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 961ms/step - accuracy: 0.8673 - auc: 0.9469 - loss: 0.2542 - val_accuracy: 0.8000 - val_auc: 0.8533 - val_loss: 0.3833\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 908ms/step - accuracy: 0.8673 - auc: 0.9466 - loss: 0.2537 - val_accuracy: 0.8000 - val_auc: 0.8556 - val_loss: 0.3829\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883ms/step - accuracy: 0.8673 - auc: 0.9490 - loss: 0.2506 - val_accuracy: 0.8000 - val_auc: 0.8533 - val_loss: 0.3829\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 872ms/step - accuracy: 0.8591 - auc: 0.9484 - loss: 0.2501 - val_accuracy: 0.8000 - val_auc: 0.8533 - val_loss: 0.3847\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.8591 - auc: 0.9477 - loss: 0.2466 - val_accuracy: 0.8000 - val_auc: 0.8533 - val_loss: 0.3817\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8673 - auc: 0.9476 - loss: 0.2477 - val_accuracy: 0.8000 - val_auc: 0.8578 - val_loss: 0.3816\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.8479 - auc: 0.9468 - loss: 0.2487 - val_accuracy: 0.8000 - val_auc: 0.8556 - val_loss: 0.3881\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8591 - auc: 0.9443 - loss: 0.2454 - val_accuracy: 0.7000 - val_auc: 0.7844 - val_loss: 0.4698\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8754 - auc: 0.9444 - loss: 0.2743 - val_accuracy: 0.8000 - val_auc: 0.8600 - val_loss: 0.3881\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8591 - auc: 0.9485 - loss: 0.2418 - val_accuracy: 0.8000 - val_auc: 0.8644 - val_loss: 0.3758\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854ms/step - accuracy: 0.8754 - auc: 0.9462 - loss: 0.2576 - val_accuracy: 0.8000 - val_auc: 0.8644 - val_loss: 0.3833\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.8754 - auc: 0.9469 - loss: 0.2372 - val_accuracy: 0.8000 - val_auc: 0.8533 - val_loss: 0.3822\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 824ms/step - accuracy: 0.8673 - auc: 0.9495 - loss: 0.2366 - val_accuracy: 0.8000 - val_auc: 0.8578 - val_loss: 0.3878\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8202 - auc: 0.9508 - loss: 0.2344 - val_accuracy: 0.8333 - val_auc: 0.8622 - val_loss: 0.3871\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.8407 - auc: 0.9486 - loss: 0.2330 - val_accuracy: 0.8333 - val_auc: 0.8622 - val_loss: 0.3880\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 826ms/step - accuracy: 0.8754 - auc: 0.9508 - loss: 0.2421 - val_accuracy: 0.7333 - val_auc: 0.8644 - val_loss: 0.4159\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.8583 - auc: 0.9510 - loss: 0.2719 - val_accuracy: 0.7667 - val_auc: 0.8378 - val_loss: 0.4318\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.8591 - auc: 0.9484 - loss: 0.2485 - val_accuracy: 0.8333 - val_auc: 0.8600 - val_loss: 0.3894\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830ms/step - accuracy: 0.8696 - auc: 0.9472 - loss: 0.2604 - val_accuracy: 0.8000 - val_auc: 0.8622 - val_loss: 0.3798\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 824ms/step - accuracy: 0.8754 - auc: 0.9459 - loss: 0.2589 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.4088\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.8754 - auc: 0.9478 - loss: 0.2485 - val_accuracy: 0.8000 - val_auc: 0.8467 - val_loss: 0.3952\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 816ms/step - accuracy: 0.8754 - auc: 0.9478 - loss: 0.2514 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.4063\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.8673 - auc: 0.9478 - loss: 0.2500 - val_accuracy: 0.7667 - val_auc: 0.8311 - val_loss: 0.4203\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.8591 - auc: 0.9496 - loss: 0.2463 - val_accuracy: 0.8000 - val_auc: 0.8689 - val_loss: 0.3856\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 824ms/step - accuracy: 0.8591 - auc: 0.9481 - loss: 0.2422 - val_accuracy: 0.8000 - val_auc: 0.8600 - val_loss: 0.3838\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.8591 - auc: 0.9478 - loss: 0.2351 - val_accuracy: 0.8000 - val_auc: 0.8578 - val_loss: 0.3893\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.8637 - auc: 0.9516 - loss: 0.2281 - val_accuracy: 0.8000 - val_auc: 0.8622 - val_loss: 0.3855\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 892ms/step - accuracy: 0.8476 - auc: 0.9514 - loss: 0.2285 - val_accuracy: 0.7667 - val_auc: 0.8667 - val_loss: 0.3924\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937ms/step - accuracy: 0.8589 - auc: 0.9500 - loss: 0.2332 - val_accuracy: 0.7000 - val_auc: 0.8156 - val_loss: 0.4591\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 939ms/step - accuracy: 0.8971 - auc: 0.9472 - loss: 0.2589 - val_accuracy: 0.8000 - val_auc: 0.8622 - val_loss: 0.4027\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.8146 - auc: 0.9523 - loss: 0.2376 - val_accuracy: 0.8000 - val_auc: 0.8711 - val_loss: 0.3835\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 943ms/step - accuracy: 0.8673 - auc: 0.9488 - loss: 0.2397 - val_accuracy: 0.8000 - val_auc: 0.8622 - val_loss: 0.3973\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 791ms/step - accuracy: 0.8520 - auc: 0.9501 - loss: 0.2268 - val_accuracy: 0.8000 - val_auc: 0.8689 - val_loss: 0.3832\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 775ms/step - accuracy: 0.8407 - auc: 0.9523 - loss: 0.2262 - val_accuracy: 0.8000 - val_auc: 0.8667 - val_loss: 0.3974\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 781ms/step - accuracy: 0.8371 - auc: 0.9511 - loss: 0.2180 - val_accuracy: 0.7667 - val_auc: 0.8600 - val_loss: 0.3875\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 768ms/step - accuracy: 0.8476 - auc: 0.9539 - loss: 0.2199 - val_accuracy: 0.7667 - val_auc: 0.8600 - val_loss: 0.3996\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.8589 - auc: 0.9515 - loss: 0.2173 - val_accuracy: 0.7333 - val_auc: 0.8600 - val_loss: 0.4078\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759ms/step - accuracy: 0.8806 - auc: 0.9492 - loss: 0.2160 - val_accuracy: 0.7333 - val_auc: 0.8622 - val_loss: 0.3935\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.8923 - auc: 0.9565 - loss: 0.2189 - val_accuracy: 0.7667 - val_auc: 0.8533 - val_loss: 0.4091\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 758ms/step - accuracy: 0.8532 - auc: 0.9541 - loss: 0.2195 - val_accuracy: 0.8000 - val_auc: 0.8622 - val_loss: 0.4088\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 758ms/step - accuracy: 0.8202 - auc: 0.9470 - loss: 0.2140 - val_accuracy: 0.7333 - val_auc: 0.8600 - val_loss: 0.3987\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 752ms/step - accuracy: 0.8476 - auc: 0.9544 - loss: 0.2122 - val_accuracy: 0.7667 - val_auc: 0.8511 - val_loss: 0.4102\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 760ms/step - accuracy: 0.8532 - auc: 0.9530 - loss: 0.2105 - val_accuracy: 0.7667 - val_auc: 0.8467 - val_loss: 0.4148\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 776ms/step - accuracy: 0.8532 - auc: 0.9537 - loss: 0.2065 - val_accuracy: 0.7667 - val_auc: 0.8467 - val_loss: 0.4171\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 758ms/step - accuracy: 0.8708 - auc: 0.9543 - loss: 0.2051 - val_accuracy: 0.7667 - val_auc: 0.8444 - val_loss: 0.4061\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 767ms/step - accuracy: 0.8693 - auc: 0.9567 - loss: 0.2031 - val_accuracy: 0.7667 - val_auc: 0.8444 - val_loss: 0.4066\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774ms/step - accuracy: 0.8511 - auc: 0.9552 - loss: 0.2091 - val_accuracy: 0.7333 - val_auc: 0.8489 - val_loss: 0.4249\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 767ms/step - accuracy: 0.8717 - auc: 0.9539 - loss: 0.2163 - val_accuracy: 0.7333 - val_auc: 0.8533 - val_loss: 0.4276\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 767ms/step - accuracy: 0.8660 - auc: 0.9516 - loss: 0.2206 - val_accuracy: 0.7333 - val_auc: 0.8467 - val_loss: 0.3950\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 772ms/step - accuracy: 0.8696 - auc: 0.9553 - loss: 0.2192 - val_accuracy: 0.7667 - val_auc: 0.8600 - val_loss: 0.4391\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 769ms/step - accuracy: 0.8387 - auc: 0.9534 - loss: 0.2075 - val_accuracy: 0.7333 - val_auc: 0.8600 - val_loss: 0.3932\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 778ms/step - accuracy: 0.8624 - auc: 0.9538 - loss: 0.2087 - val_accuracy: 0.7667 - val_auc: 0.8622 - val_loss: 0.4275\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 781ms/step - accuracy: 0.8717 - auc: 0.9459 - loss: 0.2094 - val_accuracy: 0.7000 - val_auc: 0.8600 - val_loss: 0.4022\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 767ms/step - accuracy: 0.8511 - auc: 0.9518 - loss: 0.2045 - val_accuracy: 0.7667 - val_auc: 0.8578 - val_loss: 0.4142\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 777ms/step - accuracy: 0.8717 - auc: 0.9533 - loss: 0.2038 - val_accuracy: 0.7667 - val_auc: 0.8578 - val_loss: 0.4102\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774ms/step - accuracy: 0.8547 - auc: 0.9558 - loss: 0.1988 - val_accuracy: 0.7667 - val_auc: 0.8489 - val_loss: 0.4101\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 775ms/step - accuracy: 0.8604 - auc: 0.9555 - loss: 0.1992 - val_accuracy: 0.7667 - val_auc: 0.8489 - val_loss: 0.4223\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 760ms/step - accuracy: 0.8604 - auc: 0.9555 - loss: 0.1969 - val_accuracy: 0.7333 - val_auc: 0.8378 - val_loss: 0.4255\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 768ms/step - accuracy: 0.8604 - auc: 0.9569 - loss: 0.1951 - val_accuracy: 0.7000 - val_auc: 0.8444 - val_loss: 0.4216\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765ms/step - accuracy: 0.8604 - auc: 0.9572 - loss: 0.1963 - val_accuracy: 0.7000 - val_auc: 0.8378 - val_loss: 0.4276\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 764ms/step - accuracy: 0.8604 - auc: 0.9576 - loss: 0.1994 - val_accuracy: 0.6333 - val_auc: 0.8156 - val_loss: 0.4674\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 773ms/step - accuracy: 0.8717 - auc: 0.9571 - loss: 0.1991 - val_accuracy: 0.7000 - val_auc: 0.8156 - val_loss: 0.5596\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765ms/step - accuracy: 0.8717 - auc: 0.9577 - loss: 0.2037 - val_accuracy: 0.7000 - val_auc: 0.8533 - val_loss: 0.4044\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 761ms/step - accuracy: 0.8859 - auc: 0.9510 - loss: 0.2144 - val_accuracy: 0.7333 - val_auc: 0.8556 - val_loss: 0.4363\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759ms/step - accuracy: 0.8829 - auc: 0.9442 - loss: 0.2181 - val_accuracy: 0.7333 - val_auc: 0.8622 - val_loss: 0.4050\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759ms/step - accuracy: 0.8696 - auc: 0.9505 - loss: 0.2117 - val_accuracy: 0.7667 - val_auc: 0.8489 - val_loss: 0.4406\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 757ms/step - accuracy: 0.8520 - auc: 0.9475 - loss: 0.2329 - val_accuracy: 0.7333 - val_auc: 0.8667 - val_loss: 0.4049\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 753ms/step - accuracy: 0.8583 - auc: 0.9492 - loss: 0.2160 - val_accuracy: 0.7667 - val_auc: 0.8556 - val_loss: 0.4313\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 754ms/step - accuracy: 0.8387 - auc: 0.9501 - loss: 0.2112 - val_accuracy: 0.7333 - val_auc: 0.8556 - val_loss: 0.4050\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.8604 - auc: 0.9524 - loss: 0.2004 - val_accuracy: 0.7333 - val_auc: 0.8511 - val_loss: 0.4302\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 767ms/step - accuracy: 0.8829 - auc: 0.9529 - loss: 0.1973 - val_accuracy: 0.7333 - val_auc: 0.8444 - val_loss: 0.4227\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 821ms/step - accuracy: 0.8660 - auc: 0.9534 - loss: 0.1948 - val_accuracy: 0.7000 - val_auc: 0.8489 - val_loss: 0.4120\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 763ms/step - accuracy: 0.8612 - auc: 0.9551 - loss: 0.2007 - val_accuracy: 0.7333 - val_auc: 0.8511 - val_loss: 0.4336\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.8717 - auc: 0.9532 - loss: 0.1935 - val_accuracy: 0.7000 - val_auc: 0.8444 - val_loss: 0.4262\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.8717 - auc: 0.9558 - loss: 0.1919 - val_accuracy: 0.7000 - val_auc: 0.8489 - val_loss: 0.4193\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.8660 - auc: 0.9541 - loss: 0.1930 - val_accuracy: 0.7000 - val_auc: 0.8467 - val_loss: 0.4216\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8612 - auc: 0.9553 - loss: 0.2017 - val_accuracy: 0.6667 - val_auc: 0.8178 - val_loss: 0.5727\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.8717 - auc: 0.9575 - loss: 0.1951 - val_accuracy: 0.7000 - val_auc: 0.8400 - val_loss: 0.4224\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 764ms/step - accuracy: 0.8547 - auc: 0.9565 - loss: 0.1941 - val_accuracy: 0.7000 - val_auc: 0.8578 - val_loss: 0.4291\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 781ms/step - accuracy: 0.8612 - auc: 0.9538 - loss: 0.2098 - val_accuracy: 0.7667 - val_auc: 0.8511 - val_loss: 0.4517\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 757ms/step - accuracy: 0.8339 - auc: 0.9554 - loss: 0.1944 - val_accuracy: 0.7333 - val_auc: 0.8578 - val_loss: 0.4131\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 764ms/step - accuracy: 0.8798 - auc: 0.9546 - loss: 0.1970 - val_accuracy: 0.7333 - val_auc: 0.8556 - val_loss: 0.4362\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 763ms/step - accuracy: 0.8829 - auc: 0.9571 - loss: 0.1978 - val_accuracy: 0.6667 - val_auc: 0.8267 - val_loss: 0.4743\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 758ms/step - accuracy: 0.8717 - auc: 0.9564 - loss: 0.1921 - val_accuracy: 0.7333 - val_auc: 0.8556 - val_loss: 0.4241\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 757ms/step - accuracy: 0.8500 - auc: 0.9569 - loss: 0.1893 - val_accuracy: 0.7000 - val_auc: 0.8578 - val_loss: 0.4319\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 772ms/step - accuracy: 0.8829 - auc: 0.9608 - loss: 0.1966 - val_accuracy: 0.6667 - val_auc: 0.8244 - val_loss: 0.4925\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 754ms/step - accuracy: 0.8604 - auc: 0.9583 - loss: 0.1865 - val_accuracy: 0.7000 - val_auc: 0.8422 - val_loss: 0.4473\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 757ms/step - accuracy: 0.8717 - auc: 0.9579 - loss: 0.1849 - val_accuracy: 0.7000 - val_auc: 0.8489 - val_loss: 0.4397\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 763ms/step - accuracy: 0.8773 - auc: 0.9587 - loss: 0.1875 - val_accuracy: 0.7000 - val_auc: 0.8400 - val_loss: 0.4417\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 752ms/step - accuracy: 0.8612 - auc: 0.9561 - loss: 0.2074 - val_accuracy: 0.7000 - val_auc: 0.8267 - val_loss: 0.6837\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 754ms/step - accuracy: 0.8354 - auc: 0.9539 - loss: 0.2177 - val_accuracy: 0.6667 - val_auc: 0.8022 - val_loss: 0.5572\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 757ms/step - accuracy: 0.8677 - auc: 0.9557 - loss: 0.2300 - val_accuracy: 0.7667 - val_auc: 0.8600 - val_loss: 0.4704\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.8612 - auc: 0.9568 - loss: 0.2017 - val_accuracy: 0.7333 - val_auc: 0.8578 - val_loss: 0.4159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [1:45:03, 1260.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 48min 35s, sys: 1h 36min 12s, total: 5h 24min 48s\n",
      "Wall time: 1h 45min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_acc = []\n",
    "all_loss = []\n",
    "all_auc = []\n",
    "\n",
    "all_val_acc = []\n",
    "all_val_loss = []\n",
    "all_val_auc = []\n",
    "\n",
    "for j, seed in tqdm(enumerate(np.arange(NUM_EXPERIMENTS) + INIT_SEED)):\n",
    "    np.random.seed(int(seed))\n",
    "    random.seed(int(seed))\n",
    "    tf.random.set_seed(int(seed))\n",
    "\n",
    "    train_id = np.random.choice(np.unique(np.ravel(data[USER])), 7, replace=False)\n",
    "    train_index = np.isin(data[USER], train_id)\n",
    "\n",
    "    train = data.iloc[train_index]\n",
    "    test = data.iloc[~train_index]\n",
    "\n",
    "    X_train, y_train = reshape_dataset(train)\n",
    "    X_test, y_test = reshape_dataset(test)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = create_model(X_train)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=10,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    auc = history.history['auc']\n",
    "\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_auc = history.history['val_auc']\n",
    "\n",
    "    all_acc.append(acc)\n",
    "    all_loss.append(loss)\n",
    "    all_auc.append(auc)\n",
    "\n",
    "    all_val_acc.append(val_acc)\n",
    "    all_val_loss.append(val_loss)\n",
    "    all_val_auc.append(val_auc)\n",
    "\n",
    "epoch_acc = np.mean(all_acc, axis=0)\n",
    "epoch_loss = np.mean(all_loss, axis=0)\n",
    "epoch_auc = np.mean(all_auc, axis=0)\n",
    "\n",
    "epoch_val_acc = np.mean(all_val_acc, axis=0)\n",
    "epoch_val_loss = np.mean(all_val_loss, axis=0)\n",
    "epoch_val_auc = np.mean(all_val_auc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: TRAIN Accuracy = 0.494 Loss = 0.698 AUC = 0.413\n",
      "Epoch 1: VAL Accuracy = 0.5 Loss = 0.694 AUC = 0.56\n",
      "Epoch 2: TRAIN Accuracy = 0.5 Loss = 0.693 AUC = 0.561\n",
      "Epoch 2: VAL Accuracy = 0.56 Loss = 0.692 AUC = 0.707\n",
      "Epoch 3: TRAIN Accuracy = 0.534 Loss = 0.692 AUC = 0.628\n",
      "Epoch 3: VAL Accuracy = 0.5 Loss = 0.689 AUC = 0.675\n",
      "Epoch 4: TRAIN Accuracy = 0.5 Loss = 0.688 AUC = 0.672\n",
      "Epoch 4: VAL Accuracy = 0.5 Loss = 0.683 AUC = 0.744\n",
      "Epoch 5: TRAIN Accuracy = 0.603 Loss = 0.68 AUC = 0.716\n",
      "Epoch 5: VAL Accuracy = 0.707 Loss = 0.673 AUC = 0.745\n",
      "Epoch 6: TRAIN Accuracy = 0.714 Loss = 0.668 AUC = 0.723\n",
      "Epoch 6: VAL Accuracy = 0.733 Loss = 0.656 AUC = 0.767\n",
      "Epoch 7: TRAIN Accuracy = 0.743 Loss = 0.65 AUC = 0.725\n",
      "Epoch 7: VAL Accuracy = 0.72 Loss = 0.637 AUC = 0.798\n",
      "Epoch 8: TRAIN Accuracy = 0.783 Loss = 0.626 AUC = 0.753\n",
      "Epoch 8: VAL Accuracy = 0.787 Loss = 0.61 AUC = 0.795\n",
      "Epoch 9: TRAIN Accuracy = 0.783 Loss = 0.597 AUC = 0.765\n",
      "Epoch 9: VAL Accuracy = 0.787 Loss = 0.58 AUC = 0.773\n",
      "Epoch 10: TRAIN Accuracy = 0.791 Loss = 0.566 AUC = 0.766\n",
      "Epoch 10: VAL Accuracy = 0.793 Loss = 0.549 AUC = 0.784\n",
      "Epoch 11: TRAIN Accuracy = 0.791 Loss = 0.536 AUC = 0.764\n",
      "Epoch 11: VAL Accuracy = 0.793 Loss = 0.519 AUC = 0.766\n",
      "Epoch 12: TRAIN Accuracy = 0.794 Loss = 0.507 AUC = 0.77\n",
      "Epoch 12: VAL Accuracy = 0.793 Loss = 0.488 AUC = 0.773\n",
      "Epoch 13: TRAIN Accuracy = 0.797 Loss = 0.481 AUC = 0.766\n",
      "Epoch 13: VAL Accuracy = 0.807 Loss = 0.464 AUC = 0.772\n",
      "Epoch 14: TRAIN Accuracy = 0.8 Loss = 0.463 AUC = 0.756\n",
      "Epoch 14: VAL Accuracy = 0.807 Loss = 0.446 AUC = 0.785\n",
      "Epoch 15: TRAIN Accuracy = 0.8 Loss = 0.449 AUC = 0.758\n",
      "Epoch 15: VAL Accuracy = 0.807 Loss = 0.433 AUC = 0.781\n",
      "Epoch 16: TRAIN Accuracy = 0.8 Loss = 0.439 AUC = 0.744\n",
      "Epoch 16: VAL Accuracy = 0.807 Loss = 0.425 AUC = 0.799\n",
      "Epoch 17: TRAIN Accuracy = 0.8 Loss = 0.433 AUC = 0.756\n",
      "Epoch 17: VAL Accuracy = 0.807 Loss = 0.418 AUC = 0.804\n",
      "Epoch 18: TRAIN Accuracy = 0.803 Loss = 0.428 AUC = 0.757\n",
      "Epoch 18: VAL Accuracy = 0.813 Loss = 0.414 AUC = 0.816\n",
      "Epoch 19: TRAIN Accuracy = 0.806 Loss = 0.425 AUC = 0.759\n",
      "Epoch 19: VAL Accuracy = 0.82 Loss = 0.41 AUC = 0.813\n",
      "Epoch 20: TRAIN Accuracy = 0.806 Loss = 0.423 AUC = 0.758\n",
      "Epoch 20: VAL Accuracy = 0.82 Loss = 0.407 AUC = 0.828\n",
      "Epoch 21: TRAIN Accuracy = 0.806 Loss = 0.421 AUC = 0.768\n",
      "Epoch 21: VAL Accuracy = 0.82 Loss = 0.405 AUC = 0.828\n",
      "Epoch 22: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.778\n",
      "Epoch 22: VAL Accuracy = 0.82 Loss = 0.403 AUC = 0.846\n",
      "Epoch 23: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.797\n",
      "Epoch 23: VAL Accuracy = 0.82 Loss = 0.401 AUC = 0.866\n",
      "Epoch 24: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.801\n",
      "Epoch 24: VAL Accuracy = 0.82 Loss = 0.399 AUC = 0.866\n",
      "Epoch 25: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.802\n",
      "Epoch 25: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.88\n",
      "Epoch 26: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.812\n",
      "Epoch 26: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.873\n",
      "Epoch 27: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.818\n",
      "Epoch 27: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.886\n",
      "Epoch 28: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.82\n",
      "Epoch 28: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.881\n",
      "Epoch 29: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.822\n",
      "Epoch 29: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.878\n",
      "Epoch 30: TRAIN Accuracy = 0.806 Loss = 0.409 AUC = 0.823\n",
      "Epoch 30: VAL Accuracy = 0.82 Loss = 0.388 AUC = 0.884\n",
      "Epoch 31: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.826\n",
      "Epoch 31: VAL Accuracy = 0.82 Loss = 0.386 AUC = 0.889\n",
      "Epoch 32: TRAIN Accuracy = 0.806 Loss = 0.407 AUC = 0.833\n",
      "Epoch 32: VAL Accuracy = 0.82 Loss = 0.383 AUC = 0.887\n",
      "Epoch 33: TRAIN Accuracy = 0.806 Loss = 0.405 AUC = 0.84\n",
      "Epoch 33: VAL Accuracy = 0.82 Loss = 0.381 AUC = 0.887\n",
      "Epoch 34: TRAIN Accuracy = 0.806 Loss = 0.404 AUC = 0.847\n",
      "Epoch 34: VAL Accuracy = 0.82 Loss = 0.38 AUC = 0.894\n",
      "Epoch 35: TRAIN Accuracy = 0.806 Loss = 0.403 AUC = 0.85\n",
      "Epoch 35: VAL Accuracy = 0.82 Loss = 0.378 AUC = 0.892\n",
      "Epoch 36: TRAIN Accuracy = 0.806 Loss = 0.402 AUC = 0.844\n",
      "Epoch 36: VAL Accuracy = 0.82 Loss = 0.376 AUC = 0.902\n",
      "Epoch 37: TRAIN Accuracy = 0.806 Loss = 0.401 AUC = 0.85\n",
      "Epoch 37: VAL Accuracy = 0.82 Loss = 0.374 AUC = 0.895\n",
      "Epoch 38: TRAIN Accuracy = 0.806 Loss = 0.4 AUC = 0.848\n",
      "Epoch 38: VAL Accuracy = 0.82 Loss = 0.373 AUC = 0.9\n",
      "Epoch 39: TRAIN Accuracy = 0.806 Loss = 0.399 AUC = 0.851\n",
      "Epoch 39: VAL Accuracy = 0.82 Loss = 0.371 AUC = 0.903\n",
      "Epoch 40: TRAIN Accuracy = 0.806 Loss = 0.398 AUC = 0.852\n",
      "Epoch 40: VAL Accuracy = 0.82 Loss = 0.369 AUC = 0.902\n",
      "Epoch 41: TRAIN Accuracy = 0.806 Loss = 0.397 AUC = 0.85\n",
      "Epoch 41: VAL Accuracy = 0.82 Loss = 0.367 AUC = 0.917\n",
      "Epoch 42: TRAIN Accuracy = 0.806 Loss = 0.396 AUC = 0.854\n",
      "Epoch 42: VAL Accuracy = 0.82 Loss = 0.366 AUC = 0.924\n",
      "Epoch 43: TRAIN Accuracy = 0.806 Loss = 0.395 AUC = 0.857\n",
      "Epoch 43: VAL Accuracy = 0.82 Loss = 0.363 AUC = 0.923\n",
      "Epoch 44: TRAIN Accuracy = 0.806 Loss = 0.393 AUC = 0.861\n",
      "Epoch 44: VAL Accuracy = 0.82 Loss = 0.361 AUC = 0.92\n",
      "Epoch 45: TRAIN Accuracy = 0.806 Loss = 0.392 AUC = 0.862\n",
      "Epoch 45: VAL Accuracy = 0.82 Loss = 0.359 AUC = 0.92\n",
      "Epoch 46: TRAIN Accuracy = 0.806 Loss = 0.391 AUC = 0.864\n",
      "Epoch 46: VAL Accuracy = 0.82 Loss = 0.359 AUC = 0.923\n",
      "Epoch 47: TRAIN Accuracy = 0.806 Loss = 0.39 AUC = 0.862\n",
      "Epoch 47: VAL Accuracy = 0.82 Loss = 0.357 AUC = 0.92\n",
      "Epoch 48: TRAIN Accuracy = 0.806 Loss = 0.388 AUC = 0.871\n",
      "Epoch 48: VAL Accuracy = 0.813 Loss = 0.357 AUC = 0.918\n",
      "Epoch 49: TRAIN Accuracy = 0.806 Loss = 0.387 AUC = 0.869\n",
      "Epoch 49: VAL Accuracy = 0.813 Loss = 0.356 AUC = 0.914\n",
      "Epoch 50: TRAIN Accuracy = 0.806 Loss = 0.386 AUC = 0.869\n",
      "Epoch 50: VAL Accuracy = 0.82 Loss = 0.352 AUC = 0.918\n",
      "Epoch 51: TRAIN Accuracy = 0.806 Loss = 0.384 AUC = 0.87\n",
      "Epoch 51: VAL Accuracy = 0.813 Loss = 0.349 AUC = 0.914\n",
      "Epoch 52: TRAIN Accuracy = 0.797 Loss = 0.383 AUC = 0.874\n",
      "Epoch 52: VAL Accuracy = 0.82 Loss = 0.348 AUC = 0.915\n",
      "Epoch 53: TRAIN Accuracy = 0.806 Loss = 0.382 AUC = 0.87\n",
      "Epoch 53: VAL Accuracy = 0.82 Loss = 0.344 AUC = 0.919\n",
      "Epoch 54: TRAIN Accuracy = 0.806 Loss = 0.378 AUC = 0.876\n",
      "Epoch 54: VAL Accuracy = 0.813 Loss = 0.347 AUC = 0.912\n",
      "Epoch 55: TRAIN Accuracy = 0.797 Loss = 0.379 AUC = 0.873\n",
      "Epoch 55: VAL Accuracy = 0.813 Loss = 0.348 AUC = 0.911\n",
      "Epoch 56: TRAIN Accuracy = 0.806 Loss = 0.38 AUC = 0.873\n",
      "Epoch 56: VAL Accuracy = 0.82 Loss = 0.343 AUC = 0.922\n",
      "Epoch 57: TRAIN Accuracy = 0.806 Loss = 0.373 AUC = 0.883\n",
      "Epoch 57: VAL Accuracy = 0.813 Loss = 0.345 AUC = 0.91\n",
      "Epoch 58: TRAIN Accuracy = 0.791 Loss = 0.375 AUC = 0.878\n",
      "Epoch 58: VAL Accuracy = 0.8 Loss = 0.362 AUC = 0.905\n",
      "Epoch 59: TRAIN Accuracy = 0.797 Loss = 0.375 AUC = 0.877\n",
      "Epoch 59: VAL Accuracy = 0.813 Loss = 0.352 AUC = 0.908\n",
      "Epoch 60: TRAIN Accuracy = 0.806 Loss = 0.372 AUC = 0.88\n",
      "Epoch 60: VAL Accuracy = 0.807 Loss = 0.366 AUC = 0.904\n",
      "Epoch 61: TRAIN Accuracy = 0.8 Loss = 0.368 AUC = 0.879\n",
      "Epoch 61: VAL Accuracy = 0.8 Loss = 0.412 AUC = 0.902\n",
      "Epoch 62: TRAIN Accuracy = 0.771 Loss = 0.417 AUC = 0.855\n",
      "Epoch 62: VAL Accuracy = 0.82 Loss = 0.344 AUC = 0.911\n",
      "Epoch 63: TRAIN Accuracy = 0.806 Loss = 0.371 AUC = 0.879\n",
      "Epoch 63: VAL Accuracy = 0.8 Loss = 0.457 AUC = 0.892\n",
      "Epoch 64: TRAIN Accuracy = 0.791 Loss = 0.41 AUC = 0.873\n",
      "Epoch 64: VAL Accuracy = 0.8 Loss = 0.442 AUC = 0.889\n",
      "Epoch 65: TRAIN Accuracy = 0.797 Loss = 0.389 AUC = 0.876\n",
      "Epoch 65: VAL Accuracy = 0.813 Loss = 0.364 AUC = 0.911\n",
      "Epoch 66: TRAIN Accuracy = 0.806 Loss = 0.371 AUC = 0.878\n",
      "Epoch 66: VAL Accuracy = 0.807 Loss = 0.371 AUC = 0.904\n",
      "Epoch 67: TRAIN Accuracy = 0.797 Loss = 0.371 AUC = 0.879\n",
      "Epoch 67: VAL Accuracy = 0.813 Loss = 0.364 AUC = 0.908\n",
      "Epoch 68: TRAIN Accuracy = 0.806 Loss = 0.364 AUC = 0.882\n",
      "Epoch 68: VAL Accuracy = 0.807 Loss = 0.371 AUC = 0.904\n",
      "Epoch 69: TRAIN Accuracy = 0.797 Loss = 0.365 AUC = 0.881\n",
      "Epoch 69: VAL Accuracy = 0.807 Loss = 0.368 AUC = 0.902\n",
      "Epoch 70: TRAIN Accuracy = 0.806 Loss = 0.362 AUC = 0.884\n",
      "Epoch 70: VAL Accuracy = 0.807 Loss = 0.378 AUC = 0.901\n",
      "Epoch 71: TRAIN Accuracy = 0.806 Loss = 0.361 AUC = 0.885\n",
      "Epoch 71: VAL Accuracy = 0.793 Loss = 0.38 AUC = 0.9\n",
      "Epoch 72: TRAIN Accuracy = 0.797 Loss = 0.361 AUC = 0.884\n",
      "Epoch 72: VAL Accuracy = 0.793 Loss = 0.386 AUC = 0.904\n",
      "Epoch 73: TRAIN Accuracy = 0.806 Loss = 0.358 AUC = 0.885\n",
      "Epoch 73: VAL Accuracy = 0.793 Loss = 0.39 AUC = 0.9\n",
      "Epoch 74: TRAIN Accuracy = 0.8 Loss = 0.359 AUC = 0.885\n",
      "Epoch 74: VAL Accuracy = 0.793 Loss = 0.387 AUC = 0.908\n",
      "Epoch 75: TRAIN Accuracy = 0.806 Loss = 0.357 AUC = 0.886\n",
      "Epoch 75: VAL Accuracy = 0.793 Loss = 0.384 AUC = 0.906\n",
      "Epoch 76: TRAIN Accuracy = 0.806 Loss = 0.355 AUC = 0.886\n",
      "Epoch 76: VAL Accuracy = 0.793 Loss = 0.386 AUC = 0.903\n",
      "Epoch 77: TRAIN Accuracy = 0.794 Loss = 0.356 AUC = 0.884\n",
      "Epoch 77: VAL Accuracy = 0.787 Loss = 0.403 AUC = 0.902\n",
      "Epoch 78: TRAIN Accuracy = 0.806 Loss = 0.354 AUC = 0.886\n",
      "Epoch 78: VAL Accuracy = 0.793 Loss = 0.391 AUC = 0.907\n",
      "Epoch 79: TRAIN Accuracy = 0.806 Loss = 0.351 AUC = 0.888\n",
      "Epoch 79: VAL Accuracy = 0.793 Loss = 0.437 AUC = 0.9\n",
      "Epoch 80: TRAIN Accuracy = 0.8 Loss = 0.36 AUC = 0.88\n",
      "Epoch 80: VAL Accuracy = 0.793 Loss = 0.39 AUC = 0.903\n",
      "Epoch 81: TRAIN Accuracy = 0.809 Loss = 0.35 AUC = 0.894\n",
      "Epoch 81: VAL Accuracy = 0.78 Loss = 0.408 AUC = 0.896\n",
      "Epoch 82: TRAIN Accuracy = 0.8 Loss = 0.354 AUC = 0.886\n",
      "Epoch 82: VAL Accuracy = 0.807 Loss = 0.414 AUC = 0.9\n",
      "Epoch 83: TRAIN Accuracy = 0.806 Loss = 0.352 AUC = 0.892\n",
      "Epoch 83: VAL Accuracy = 0.78 Loss = 0.405 AUC = 0.897\n",
      "Epoch 84: TRAIN Accuracy = 0.809 Loss = 0.348 AUC = 0.895\n",
      "Epoch 84: VAL Accuracy = 0.793 Loss = 0.429 AUC = 0.896\n",
      "Epoch 85: TRAIN Accuracy = 0.8 Loss = 0.348 AUC = 0.893\n",
      "Epoch 85: VAL Accuracy = 0.8 Loss = 0.428 AUC = 0.897\n",
      "Epoch 86: TRAIN Accuracy = 0.806 Loss = 0.35 AUC = 0.892\n",
      "Epoch 86: VAL Accuracy = 0.78 Loss = 0.447 AUC = 0.892\n",
      "Epoch 87: TRAIN Accuracy = 0.803 Loss = 0.344 AUC = 0.898\n",
      "Epoch 87: VAL Accuracy = 0.8 Loss = 0.45 AUC = 0.893\n",
      "Epoch 88: TRAIN Accuracy = 0.797 Loss = 0.345 AUC = 0.892\n",
      "Epoch 88: VAL Accuracy = 0.8 Loss = 0.464 AUC = 0.892\n",
      "Epoch 89: TRAIN Accuracy = 0.803 Loss = 0.345 AUC = 0.894\n",
      "Epoch 89: VAL Accuracy = 0.793 Loss = 0.471 AUC = 0.887\n",
      "Epoch 90: TRAIN Accuracy = 0.809 Loss = 0.344 AUC = 0.896\n",
      "Epoch 90: VAL Accuracy = 0.793 Loss = 0.464 AUC = 0.885\n",
      "Epoch 91: TRAIN Accuracy = 0.797 Loss = 0.34 AUC = 0.897\n",
      "Epoch 91: VAL Accuracy = 0.8 Loss = 0.461 AUC = 0.888\n",
      "Epoch 92: TRAIN Accuracy = 0.803 Loss = 0.341 AUC = 0.894\n",
      "Epoch 92: VAL Accuracy = 0.8 Loss = 0.469 AUC = 0.887\n",
      "Epoch 93: TRAIN Accuracy = 0.803 Loss = 0.338 AUC = 0.898\n",
      "Epoch 93: VAL Accuracy = 0.793 Loss = 0.468 AUC = 0.886\n",
      "Epoch 94: TRAIN Accuracy = 0.8 Loss = 0.339 AUC = 0.896\n",
      "Epoch 94: VAL Accuracy = 0.787 Loss = 0.458 AUC = 0.887\n",
      "Epoch 95: TRAIN Accuracy = 0.797 Loss = 0.334 AUC = 0.899\n",
      "Epoch 95: VAL Accuracy = 0.8 Loss = 0.46 AUC = 0.89\n",
      "Epoch 96: TRAIN Accuracy = 0.8 Loss = 0.336 AUC = 0.899\n",
      "Epoch 96: VAL Accuracy = 0.8 Loss = 0.432 AUC = 0.888\n",
      "Epoch 97: TRAIN Accuracy = 0.797 Loss = 0.334 AUC = 0.901\n",
      "Epoch 97: VAL Accuracy = 0.793 Loss = 0.445 AUC = 0.884\n",
      "Epoch 98: TRAIN Accuracy = 0.8 Loss = 0.332 AUC = 0.901\n",
      "Epoch 98: VAL Accuracy = 0.807 Loss = 0.422 AUC = 0.889\n",
      "Epoch 99: TRAIN Accuracy = 0.803 Loss = 0.329 AUC = 0.903\n",
      "Epoch 99: VAL Accuracy = 0.813 Loss = 0.429 AUC = 0.884\n",
      "Epoch 100: TRAIN Accuracy = 0.809 Loss = 0.331 AUC = 0.902\n",
      "Epoch 100: VAL Accuracy = 0.807 Loss = 0.424 AUC = 0.888\n",
      "Epoch 101: TRAIN Accuracy = 0.803 Loss = 0.323 AUC = 0.906\n",
      "Epoch 101: VAL Accuracy = 0.807 Loss = 0.441 AUC = 0.884\n",
      "Epoch 102: TRAIN Accuracy = 0.803 Loss = 0.333 AUC = 0.902\n",
      "Epoch 102: VAL Accuracy = 0.807 Loss = 0.422 AUC = 0.892\n",
      "Epoch 103: TRAIN Accuracy = 0.803 Loss = 0.323 AUC = 0.906\n",
      "Epoch 103: VAL Accuracy = 0.8 Loss = 0.461 AUC = 0.882\n",
      "Epoch 104: TRAIN Accuracy = 0.803 Loss = 0.33 AUC = 0.904\n",
      "Epoch 104: VAL Accuracy = 0.807 Loss = 0.42 AUC = 0.892\n",
      "Epoch 105: TRAIN Accuracy = 0.806 Loss = 0.32 AUC = 0.907\n",
      "Epoch 105: VAL Accuracy = 0.807 Loss = 0.446 AUC = 0.885\n",
      "Epoch 106: TRAIN Accuracy = 0.806 Loss = 0.323 AUC = 0.905\n",
      "Epoch 106: VAL Accuracy = 0.813 Loss = 0.44 AUC = 0.884\n",
      "Epoch 107: TRAIN Accuracy = 0.806 Loss = 0.318 AUC = 0.907\n",
      "Epoch 107: VAL Accuracy = 0.807 Loss = 0.447 AUC = 0.885\n",
      "Epoch 108: TRAIN Accuracy = 0.806 Loss = 0.321 AUC = 0.907\n",
      "Epoch 108: VAL Accuracy = 0.807 Loss = 0.451 AUC = 0.886\n",
      "Epoch 109: TRAIN Accuracy = 0.806 Loss = 0.316 AUC = 0.907\n",
      "Epoch 109: VAL Accuracy = 0.8 Loss = 0.438 AUC = 0.885\n",
      "Epoch 110: TRAIN Accuracy = 0.803 Loss = 0.317 AUC = 0.908\n",
      "Epoch 110: VAL Accuracy = 0.8 Loss = 0.437 AUC = 0.885\n",
      "Epoch 111: TRAIN Accuracy = 0.806 Loss = 0.314 AUC = 0.909\n",
      "Epoch 111: VAL Accuracy = 0.8 Loss = 0.456 AUC = 0.884\n",
      "Epoch 112: TRAIN Accuracy = 0.806 Loss = 0.315 AUC = 0.911\n",
      "Epoch 112: VAL Accuracy = 0.8 Loss = 0.457 AUC = 0.884\n",
      "Epoch 113: TRAIN Accuracy = 0.809 Loss = 0.316 AUC = 0.911\n",
      "Epoch 113: VAL Accuracy = 0.807 Loss = 0.459 AUC = 0.888\n",
      "Epoch 114: TRAIN Accuracy = 0.791 Loss = 0.321 AUC = 0.907\n",
      "Epoch 114: VAL Accuracy = 0.813 Loss = 0.455 AUC = 0.89\n",
      "Epoch 115: TRAIN Accuracy = 0.803 Loss = 0.313 AUC = 0.909\n",
      "Epoch 115: VAL Accuracy = 0.787 Loss = 0.486 AUC = 0.872\n",
      "Epoch 116: TRAIN Accuracy = 0.809 Loss = 0.322 AUC = 0.908\n",
      "Epoch 116: VAL Accuracy = 0.8 Loss = 0.485 AUC = 0.876\n",
      "Epoch 117: TRAIN Accuracy = 0.809 Loss = 0.307 AUC = 0.912\n",
      "Epoch 117: VAL Accuracy = 0.82 Loss = 0.43 AUC = 0.888\n",
      "Epoch 118: TRAIN Accuracy = 0.809 Loss = 0.314 AUC = 0.911\n",
      "Epoch 118: VAL Accuracy = 0.793 Loss = 0.444 AUC = 0.882\n",
      "Epoch 119: TRAIN Accuracy = 0.811 Loss = 0.31 AUC = 0.91\n",
      "Epoch 119: VAL Accuracy = 0.807 Loss = 0.44 AUC = 0.884\n",
      "Epoch 120: TRAIN Accuracy = 0.8 Loss = 0.312 AUC = 0.91\n",
      "Epoch 120: VAL Accuracy = 0.793 Loss = 0.549 AUC = 0.863\n",
      "Epoch 121: TRAIN Accuracy = 0.777 Loss = 0.341 AUC = 0.896\n",
      "Epoch 121: VAL Accuracy = 0.787 Loss = 0.513 AUC = 0.867\n",
      "Epoch 122: TRAIN Accuracy = 0.769 Loss = 0.358 AUC = 0.891\n",
      "Epoch 122: VAL Accuracy = 0.8 Loss = 0.514 AUC = 0.856\n",
      "Epoch 123: TRAIN Accuracy = 0.809 Loss = 0.334 AUC = 0.891\n",
      "Epoch 123: VAL Accuracy = 0.78 Loss = 0.481 AUC = 0.86\n",
      "Epoch 124: TRAIN Accuracy = 0.803 Loss = 0.329 AUC = 0.889\n",
      "Epoch 124: VAL Accuracy = 0.8 Loss = 0.518 AUC = 0.841\n",
      "Epoch 125: TRAIN Accuracy = 0.8 Loss = 0.325 AUC = 0.89\n",
      "Epoch 125: VAL Accuracy = 0.8 Loss = 0.487 AUC = 0.857\n",
      "Epoch 126: TRAIN Accuracy = 0.8 Loss = 0.332 AUC = 0.889\n",
      "Epoch 126: VAL Accuracy = 0.8 Loss = 0.526 AUC = 0.853\n",
      "Epoch 127: TRAIN Accuracy = 0.806 Loss = 0.325 AUC = 0.889\n",
      "Epoch 127: VAL Accuracy = 0.8 Loss = 0.468 AUC = 0.857\n",
      "Epoch 128: TRAIN Accuracy = 0.809 Loss = 0.325 AUC = 0.893\n",
      "Epoch 128: VAL Accuracy = 0.813 Loss = 0.463 AUC = 0.868\n",
      "Epoch 129: TRAIN Accuracy = 0.809 Loss = 0.321 AUC = 0.888\n",
      "Epoch 129: VAL Accuracy = 0.8 Loss = 0.456 AUC = 0.876\n",
      "Epoch 130: TRAIN Accuracy = 0.811 Loss = 0.323 AUC = 0.903\n",
      "Epoch 130: VAL Accuracy = 0.793 Loss = 0.483 AUC = 0.856\n",
      "Epoch 131: TRAIN Accuracy = 0.809 Loss = 0.313 AUC = 0.915\n",
      "Epoch 131: VAL Accuracy = 0.8 Loss = 0.522 AUC = 0.876\n",
      "Epoch 132: TRAIN Accuracy = 0.811 Loss = 0.309 AUC = 0.913\n",
      "Epoch 132: VAL Accuracy = 0.8 Loss = 0.537 AUC = 0.865\n",
      "Epoch 133: TRAIN Accuracy = 0.809 Loss = 0.309 AUC = 0.913\n",
      "Epoch 133: VAL Accuracy = 0.793 Loss = 0.563 AUC = 0.856\n",
      "Epoch 134: TRAIN Accuracy = 0.811 Loss = 0.323 AUC = 0.91\n",
      "Epoch 134: VAL Accuracy = 0.813 Loss = 0.445 AUC = 0.884\n",
      "Epoch 135: TRAIN Accuracy = 0.766 Loss = 0.347 AUC = 0.897\n",
      "Epoch 135: VAL Accuracy = 0.773 Loss = 0.488 AUC = 0.866\n",
      "Epoch 136: TRAIN Accuracy = 0.789 Loss = 0.326 AUC = 0.903\n",
      "Epoch 136: VAL Accuracy = 0.78 Loss = 0.488 AUC = 0.876\n",
      "Epoch 137: TRAIN Accuracy = 0.791 Loss = 0.326 AUC = 0.901\n",
      "Epoch 137: VAL Accuracy = 0.767 Loss = 0.51 AUC = 0.866\n",
      "Epoch 138: TRAIN Accuracy = 0.76 Loss = 0.329 AUC = 0.897\n",
      "Epoch 138: VAL Accuracy = 0.78 Loss = 0.502 AUC = 0.881\n",
      "Epoch 139: TRAIN Accuracy = 0.791 Loss = 0.313 AUC = 0.914\n",
      "Epoch 139: VAL Accuracy = 0.773 Loss = 0.542 AUC = 0.877\n",
      "Epoch 140: TRAIN Accuracy = 0.783 Loss = 0.314 AUC = 0.907\n",
      "Epoch 140: VAL Accuracy = 0.767 Loss = 0.54 AUC = 0.87\n",
      "Epoch 141: TRAIN Accuracy = 0.771 Loss = 0.319 AUC = 0.905\n",
      "Epoch 141: VAL Accuracy = 0.78 Loss = 0.56 AUC = 0.87\n",
      "Epoch 142: TRAIN Accuracy = 0.777 Loss = 0.306 AUC = 0.916\n",
      "Epoch 142: VAL Accuracy = 0.78 Loss = 0.474 AUC = 0.882\n",
      "Epoch 143: TRAIN Accuracy = 0.783 Loss = 0.309 AUC = 0.912\n",
      "Epoch 143: VAL Accuracy = 0.8 Loss = 0.486 AUC = 0.882\n",
      "Epoch 144: TRAIN Accuracy = 0.78 Loss = 0.307 AUC = 0.91\n",
      "Epoch 144: VAL Accuracy = 0.76 Loss = 0.482 AUC = 0.882\n",
      "Epoch 145: TRAIN Accuracy = 0.797 Loss = 0.302 AUC = 0.915\n",
      "Epoch 145: VAL Accuracy = 0.78 Loss = 0.517 AUC = 0.876\n",
      "Epoch 146: TRAIN Accuracy = 0.806 Loss = 0.297 AUC = 0.917\n",
      "Epoch 146: VAL Accuracy = 0.8 Loss = 0.508 AUC = 0.876\n",
      "Epoch 147: TRAIN Accuracy = 0.783 Loss = 0.298 AUC = 0.917\n",
      "Epoch 147: VAL Accuracy = 0.78 Loss = 0.573 AUC = 0.871\n",
      "Epoch 148: TRAIN Accuracy = 0.797 Loss = 0.291 AUC = 0.918\n",
      "Epoch 148: VAL Accuracy = 0.793 Loss = 0.499 AUC = 0.874\n",
      "Epoch 149: TRAIN Accuracy = 0.794 Loss = 0.294 AUC = 0.917\n",
      "Epoch 149: VAL Accuracy = 0.793 Loss = 0.558 AUC = 0.868\n",
      "Epoch 150: TRAIN Accuracy = 0.797 Loss = 0.29 AUC = 0.914\n",
      "Epoch 150: VAL Accuracy = 0.807 Loss = 0.53 AUC = 0.868\n",
      "Epoch 151: TRAIN Accuracy = 0.8 Loss = 0.286 AUC = 0.916\n",
      "Epoch 151: VAL Accuracy = 0.807 Loss = 0.545 AUC = 0.867\n",
      "Epoch 152: TRAIN Accuracy = 0.809 Loss = 0.284 AUC = 0.918\n",
      "Epoch 152: VAL Accuracy = 0.8 Loss = 0.529 AUC = 0.871\n",
      "Epoch 153: TRAIN Accuracy = 0.806 Loss = 0.289 AUC = 0.918\n",
      "Epoch 153: VAL Accuracy = 0.8 Loss = 0.592 AUC = 0.863\n",
      "Epoch 154: TRAIN Accuracy = 0.8 Loss = 0.284 AUC = 0.917\n",
      "Epoch 154: VAL Accuracy = 0.793 Loss = 0.517 AUC = 0.876\n",
      "Epoch 155: TRAIN Accuracy = 0.826 Loss = 0.286 AUC = 0.919\n",
      "Epoch 155: VAL Accuracy = 0.793 Loss = 0.577 AUC = 0.863\n",
      "Epoch 156: TRAIN Accuracy = 0.811 Loss = 0.283 AUC = 0.92\n",
      "Epoch 156: VAL Accuracy = 0.787 Loss = 0.511 AUC = 0.876\n",
      "Epoch 157: TRAIN Accuracy = 0.811 Loss = 0.288 AUC = 0.92\n",
      "Epoch 157: VAL Accuracy = 0.787 Loss = 0.563 AUC = 0.871\n",
      "Epoch 158: TRAIN Accuracy = 0.829 Loss = 0.284 AUC = 0.921\n",
      "Epoch 158: VAL Accuracy = 0.793 Loss = 0.558 AUC = 0.871\n",
      "Epoch 159: TRAIN Accuracy = 0.823 Loss = 0.281 AUC = 0.92\n",
      "Epoch 159: VAL Accuracy = 0.807 Loss = 0.537 AUC = 0.878\n",
      "Epoch 160: TRAIN Accuracy = 0.831 Loss = 0.279 AUC = 0.923\n",
      "Epoch 160: VAL Accuracy = 0.793 Loss = 0.531 AUC = 0.878\n",
      "Epoch 161: TRAIN Accuracy = 0.817 Loss = 0.278 AUC = 0.924\n",
      "Epoch 161: VAL Accuracy = 0.8 Loss = 0.569 AUC = 0.873\n",
      "Epoch 162: TRAIN Accuracy = 0.826 Loss = 0.277 AUC = 0.924\n",
      "Epoch 162: VAL Accuracy = 0.793 Loss = 0.535 AUC = 0.875\n",
      "Epoch 163: TRAIN Accuracy = 0.817 Loss = 0.277 AUC = 0.926\n",
      "Epoch 163: VAL Accuracy = 0.787 Loss = 0.575 AUC = 0.86\n",
      "Epoch 164: TRAIN Accuracy = 0.831 Loss = 0.275 AUC = 0.927\n",
      "Epoch 164: VAL Accuracy = 0.78 Loss = 0.611 AUC = 0.86\n",
      "Epoch 165: TRAIN Accuracy = 0.831 Loss = 0.296 AUC = 0.919\n",
      "Epoch 165: VAL Accuracy = 0.787 Loss = 0.602 AUC = 0.859\n",
      "Epoch 166: TRAIN Accuracy = 0.82 Loss = 0.284 AUC = 0.924\n",
      "Epoch 166: VAL Accuracy = 0.767 Loss = 0.632 AUC = 0.857\n",
      "Epoch 167: TRAIN Accuracy = 0.803 Loss = 0.309 AUC = 0.91\n",
      "Epoch 167: VAL Accuracy = 0.787 Loss = 0.513 AUC = 0.876\n",
      "Epoch 168: TRAIN Accuracy = 0.806 Loss = 0.294 AUC = 0.922\n",
      "Epoch 168: VAL Accuracy = 0.773 Loss = 0.549 AUC = 0.864\n",
      "Epoch 169: TRAIN Accuracy = 0.823 Loss = 0.286 AUC = 0.923\n",
      "Epoch 169: VAL Accuracy = 0.787 Loss = 0.557 AUC = 0.867\n",
      "Epoch 170: TRAIN Accuracy = 0.809 Loss = 0.288 AUC = 0.921\n",
      "Epoch 170: VAL Accuracy = 0.78 Loss = 0.548 AUC = 0.871\n",
      "Epoch 171: TRAIN Accuracy = 0.829 Loss = 0.289 AUC = 0.922\n",
      "Epoch 171: VAL Accuracy = 0.8 Loss = 0.556 AUC = 0.872\n",
      "Epoch 172: TRAIN Accuracy = 0.829 Loss = 0.288 AUC = 0.924\n",
      "Epoch 172: VAL Accuracy = 0.793 Loss = 0.535 AUC = 0.878\n",
      "Epoch 173: TRAIN Accuracy = 0.82 Loss = 0.286 AUC = 0.924\n",
      "Epoch 173: VAL Accuracy = 0.793 Loss = 0.546 AUC = 0.875\n",
      "Epoch 174: TRAIN Accuracy = 0.811 Loss = 0.285 AUC = 0.923\n",
      "Epoch 174: VAL Accuracy = 0.807 Loss = 0.535 AUC = 0.878\n",
      "Epoch 175: TRAIN Accuracy = 0.829 Loss = 0.283 AUC = 0.924\n",
      "Epoch 175: VAL Accuracy = 0.82 Loss = 0.551 AUC = 0.875\n",
      "Epoch 176: TRAIN Accuracy = 0.826 Loss = 0.28 AUC = 0.926\n",
      "Epoch 176: VAL Accuracy = 0.8 Loss = 0.544 AUC = 0.873\n",
      "Epoch 177: TRAIN Accuracy = 0.823 Loss = 0.279 AUC = 0.924\n",
      "Epoch 177: VAL Accuracy = 0.813 Loss = 0.554 AUC = 0.874\n",
      "Epoch 178: TRAIN Accuracy = 0.834 Loss = 0.276 AUC = 0.926\n",
      "Epoch 178: VAL Accuracy = 0.8 Loss = 0.556 AUC = 0.868\n",
      "Epoch 179: TRAIN Accuracy = 0.831 Loss = 0.275 AUC = 0.926\n",
      "Epoch 179: VAL Accuracy = 0.807 Loss = 0.564 AUC = 0.872\n",
      "Epoch 180: TRAIN Accuracy = 0.829 Loss = 0.276 AUC = 0.925\n",
      "Epoch 180: VAL Accuracy = 0.8 Loss = 0.581 AUC = 0.866\n",
      "Epoch 181: TRAIN Accuracy = 0.837 Loss = 0.274 AUC = 0.926\n",
      "Epoch 181: VAL Accuracy = 0.8 Loss = 0.594 AUC = 0.862\n",
      "Epoch 182: TRAIN Accuracy = 0.837 Loss = 0.272 AUC = 0.925\n",
      "Epoch 182: VAL Accuracy = 0.793 Loss = 0.608 AUC = 0.864\n",
      "Epoch 183: TRAIN Accuracy = 0.834 Loss = 0.273 AUC = 0.928\n",
      "Epoch 183: VAL Accuracy = 0.8 Loss = 0.62 AUC = 0.86\n",
      "Epoch 184: TRAIN Accuracy = 0.829 Loss = 0.272 AUC = 0.926\n",
      "Epoch 184: VAL Accuracy = 0.773 Loss = 0.669 AUC = 0.857\n",
      "Epoch 185: TRAIN Accuracy = 0.837 Loss = 0.271 AUC = 0.928\n",
      "Epoch 185: VAL Accuracy = 0.787 Loss = 0.649 AUC = 0.855\n",
      "Epoch 186: TRAIN Accuracy = 0.829 Loss = 0.271 AUC = 0.928\n",
      "Epoch 186: VAL Accuracy = 0.78 Loss = 0.679 AUC = 0.859\n",
      "Epoch 187: TRAIN Accuracy = 0.831 Loss = 0.275 AUC = 0.926\n",
      "Epoch 187: VAL Accuracy = 0.8 Loss = 0.669 AUC = 0.86\n",
      "Epoch 188: TRAIN Accuracy = 0.829 Loss = 0.27 AUC = 0.934\n",
      "Epoch 188: VAL Accuracy = 0.78 Loss = 0.692 AUC = 0.856\n",
      "Epoch 189: TRAIN Accuracy = 0.829 Loss = 0.274 AUC = 0.93\n",
      "Epoch 189: VAL Accuracy = 0.8 Loss = 0.645 AUC = 0.863\n",
      "Epoch 190: TRAIN Accuracy = 0.846 Loss = 0.268 AUC = 0.938\n",
      "Epoch 190: VAL Accuracy = 0.78 Loss = 0.687 AUC = 0.854\n",
      "Epoch 191: TRAIN Accuracy = 0.831 Loss = 0.269 AUC = 0.933\n",
      "Epoch 191: VAL Accuracy = 0.793 Loss = 0.638 AUC = 0.862\n",
      "Epoch 192: TRAIN Accuracy = 0.843 Loss = 0.265 AUC = 0.933\n",
      "Epoch 192: VAL Accuracy = 0.787 Loss = 0.67 AUC = 0.859\n",
      "Epoch 193: TRAIN Accuracy = 0.846 Loss = 0.268 AUC = 0.93\n",
      "Epoch 193: VAL Accuracy = 0.78 Loss = 0.663 AUC = 0.853\n",
      "Epoch 194: TRAIN Accuracy = 0.849 Loss = 0.263 AUC = 0.934\n",
      "Epoch 194: VAL Accuracy = 0.787 Loss = 0.677 AUC = 0.857\n",
      "Epoch 195: TRAIN Accuracy = 0.843 Loss = 0.263 AUC = 0.931\n",
      "Epoch 195: VAL Accuracy = 0.793 Loss = 0.66 AUC = 0.859\n",
      "Epoch 196: TRAIN Accuracy = 0.851 Loss = 0.262 AUC = 0.932\n",
      "Epoch 196: VAL Accuracy = 0.787 Loss = 0.661 AUC = 0.86\n",
      "Epoch 197: TRAIN Accuracy = 0.846 Loss = 0.267 AUC = 0.933\n",
      "Epoch 197: VAL Accuracy = 0.793 Loss = 0.698 AUC = 0.857\n",
      "Epoch 198: TRAIN Accuracy = 0.851 Loss = 0.265 AUC = 0.937\n",
      "Epoch 198: VAL Accuracy = 0.78 Loss = 0.686 AUC = 0.858\n",
      "Epoch 199: TRAIN Accuracy = 0.84 Loss = 0.274 AUC = 0.934\n",
      "Epoch 199: VAL Accuracy = 0.807 Loss = 0.637 AUC = 0.871\n",
      "Epoch 200: TRAIN Accuracy = 0.86 Loss = 0.263 AUC = 0.938\n",
      "Epoch 200: VAL Accuracy = 0.793 Loss = 0.687 AUC = 0.864\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {(i + 1)}: TRAIN Accuracy = {np.round(epoch_acc[i], 3)} Loss = {np.round(epoch_loss[i], 3)} AUC = {np.round(epoch_auc[i], 3)}\")\n",
    "    print(f\"Epoch {(i + 1)}: VAL Accuracy = {np.round(epoch_val_acc[i], 3)} Loss = {np.round(epoch_val_loss[i], 3)} AUC = {np.round(epoch_val_auc[i], 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-signals-_5HxkjSc-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
