{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 00:04:01.458961: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-22 00:04:01.465953: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-03-22 00:04:01.484603: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1742591041.518711 1358780 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1742591041.529013 1358780 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-22 00:04:01.566560: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GRU, Input, BatchNormalization, Dropout, TimeDistributed\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.keras import LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 200\n",
    "NUM_EXPERIMENTS = 5\n",
    "\n",
    "def create_model(train):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train.shape[1], train.shape[2])))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(10, return_sequences=True))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(10, return_sequences=True))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LTC(10, return_sequences=False))\n",
    "\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(6, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.003), loss='binary_crossentropy', metrics=[\"accuracy\", AUC(name=\"auc\")])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = [\"ID\"]\n",
    "USER = [\"SubjectID\"]\n",
    "IDS = [\"SubjectID\", \"VideoID\"]\n",
    "TARGET = [\"predefinedlabel\"]\n",
    "FEATURES = [\"Raw\", \"Delta\", \"Theta\", \"Alpha1\", \"Alpha2\", \"Beta1\", \"Beta2\", \"Gamma1\", \"Gamma2\"]\n",
    "LAGS = [1, 2]\n",
    "INIT_SEED = 5412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>Raw</th>\n",
       "      <th>Delta</th>\n",
       "      <th>Theta</th>\n",
       "      <th>Alpha1</th>\n",
       "      <th>Alpha2</th>\n",
       "      <th>Beta1</th>\n",
       "      <th>Beta2</th>\n",
       "      <th>Gamma1</th>\n",
       "      <th>...</th>\n",
       "      <th>Raw_2</th>\n",
       "      <th>Delta_2</th>\n",
       "      <th>Theta_2</th>\n",
       "      <th>Alpha1_2</th>\n",
       "      <th>Alpha2_2</th>\n",
       "      <th>Beta1_2</th>\n",
       "      <th>Beta2_2</th>\n",
       "      <th>Gamma1_2</th>\n",
       "      <th>Gamma2_2</th>\n",
       "      <th>predefinedlabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>73787.0</td>\n",
       "      <td>28083.0</td>\n",
       "      <td>1439.0</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>2746.0</td>\n",
       "      <td>3687.0</td>\n",
       "      <td>5293.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>758353.0</td>\n",
       "      <td>383745.0</td>\n",
       "      <td>201999.0</td>\n",
       "      <td>62107.0</td>\n",
       "      <td>36293.0</td>\n",
       "      <td>130536.0</td>\n",
       "      <td>57243.0</td>\n",
       "      <td>...</td>\n",
       "      <td>278.0</td>\n",
       "      <td>301963.0</td>\n",
       "      <td>90612.0</td>\n",
       "      <td>33735.0</td>\n",
       "      <td>23991.0</td>\n",
       "      <td>27946.0</td>\n",
       "      <td>45097.0</td>\n",
       "      <td>33228.0</td>\n",
       "      <td>8293.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SubjectID    Raw     Delta     Theta    Alpha1   Alpha2    Beta1  \\\n",
       "0   0        0.0  278.0  301963.0   90612.0   33735.0  23991.0  27946.0   \n",
       "1   0        0.0  -50.0   73787.0   28083.0    1439.0   2240.0   2746.0   \n",
       "2   0        0.0  101.0  758353.0  383745.0  201999.0  62107.0  36293.0   \n",
       "\n",
       "      Beta2   Gamma1  ...  Raw_2   Delta_2  Theta_2  Alpha1_2  Alpha2_2  \\\n",
       "0   45097.0  33228.0  ...    0.0       0.0      0.0       0.0       0.0   \n",
       "1    3687.0   5293.0  ...    0.0       0.0      0.0       0.0       0.0   \n",
       "2  130536.0  57243.0  ...  278.0  301963.0  90612.0   33735.0   23991.0   \n",
       "\n",
       "   Beta1_2  Beta2_2  Gamma1_2  Gamma2_2  predefinedlabel  \n",
       "0      0.0      0.0       0.0       0.0              0.0  \n",
       "1      0.0      0.0       0.0       0.0              0.0  \n",
       "2  27946.0  45097.0   33228.0    8293.0              0.0  \n",
       "\n",
       "[3 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = Path(\"/home/aseliverstov/projects/brain_signals/data\")\n",
    "data = pd.read_csv(data_dir / \"EEG_data.csv\")\n",
    "\n",
    "new_features = []\n",
    "for lag in LAGS:\n",
    "    for feature_name in FEATURES:\n",
    "        new_feature_name = f\"{feature_name}_{lag}\"\n",
    "        new_features.append(new_feature_name)\n",
    "        data[new_feature_name] = data.groupby(IDS)[feature_name].shift(lag).fillna(0)\n",
    "FEATURES.extend(new_features)\n",
    "\n",
    "data[\"ID\"] = (len(np.unique(data[\"VideoID\"])) * data[\"SubjectID\"] + data[\"VideoID\"]).astype(\"int\")\n",
    "data = data[ID + USER + FEATURES + TARGET]\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(data):\n",
    "    features = []\n",
    "    target = []\n",
    "    for cur_id in np.unique(data[ID].to_numpy()):\n",
    "        cur_id_data = data[data[ID].to_numpy() == cur_id]\n",
    "        target.append(np.mean(cur_id_data[TARGET].to_numpy()).astype(\"int\"))\n",
    "        features.append(cur_id_data[FEATURES].to_numpy())\n",
    "\n",
    "    features = pad_sequences(features)\n",
    "    return np.array(features), np.array(target)\n",
    "\n",
    "def pad_sequences(arrays, pad_value=0):\n",
    "    max_length = max(arr.shape[0] for arr in arrays)\n",
    "    padded_arrays = [\n",
    "        np.pad(\n",
    "            arr,\n",
    "            ((0, max_length - arr.shape[0]), (0, 0)),\n",
    "            mode='constant',\n",
    "            constant_values=pad_value)\n",
    "            for arr in arrays\n",
    "        ]\n",
    "    return np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-22 00:04:06.082241: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">27</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">870</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LTC</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">870</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m27\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc (\u001b[38;5;33mLTC\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │         \u001b[38;5;34m1,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_1 (\u001b[38;5;33mLTC\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │           \u001b[38;5;34m870\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ ltc_2 (\u001b[38;5;33mLTC\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m870\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m66\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m7\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,397</span> (13.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,397\u001b[0m (13.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,397</span> (13.27 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,397\u001b[0m (13.27 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, _ = reshape_dataset(data)\n",
    "model = create_model(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.5471 - auc: 0.6567 - loss: 0.6901 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6948\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.4217 - auc: 0.5439 - loss: 0.7040 - val_accuracy: 0.4333 - val_auc: 0.5000 - val_loss: 0.6934\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 767ms/step - accuracy: 0.5662 - auc: 0.5352 - loss: 0.6934 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.4370 - auc: 0.4516 - loss: 0.7076 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.5193 - auc: 0.4788 - loss: 0.7040 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 962ms/step - accuracy: 0.4507 - auc: 0.3827 - loss: 0.7130 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 727ms/step - accuracy: 0.5698 - auc: 0.6285 - loss: 0.6803 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759ms/step - accuracy: 0.5035 - auc: 0.5058 - loss: 0.6921 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.5193 - auc: 0.4799 - loss: 0.6967 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765ms/step - accuracy: 0.3565 - auc: 0.3357 - loss: 0.7047 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 734ms/step - accuracy: 0.6398 - auc: 0.5851 - loss: 0.6893 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6927\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 701ms/step - accuracy: 0.5576 - auc: 0.6408 - loss: 0.6818 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6922\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.3799 - auc: 0.3972 - loss: 0.7024 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6923\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 899ms/step - accuracy: 0.5566 - auc: 0.5265 - loss: 0.6872 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6925\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.5025 - auc: 0.5071 - loss: 0.6876 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6933\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 892ms/step - accuracy: 0.6421 - auc: 0.6445 - loss: 0.6864 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 889ms/step - accuracy: 0.5110 - auc: 0.5076 - loss: 0.6961 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6932\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.5437 - auc: 0.5270 - loss: 0.6896 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6914\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 867ms/step - accuracy: 0.4964 - auc: 0.5796 - loss: 0.6901 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6891\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.5771 - auc: 0.5259 - loss: 0.6912 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6876\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.5954 - auc: 0.5679 - loss: 0.6929 - val_accuracy: 0.5000 - val_auc: 0.7333 - val_loss: 0.6872\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.6429 - auc: 0.6294 - loss: 0.6826 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6861\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 871ms/step - accuracy: 0.5813 - auc: 0.7013 - loss: 0.6661 - val_accuracy: 0.6333 - val_auc: 0.6667 - val_loss: 0.6780\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 881ms/step - accuracy: 0.4343 - auc: 0.4481 - loss: 0.7057 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6688\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 909ms/step - accuracy: 0.4631 - auc: 0.4591 - loss: 0.7096 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6615\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 813ms/step - accuracy: 0.6643 - auc: 0.7148 - loss: 0.6509 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6496\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.5664 - auc: 0.5607 - loss: 0.6764 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.6274\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.5423 - auc: 0.5369 - loss: 0.6804 - val_accuracy: 0.8000 - val_auc: 0.8222 - val_loss: 0.5921\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.6788 - auc: 0.7239 - loss: 0.6447 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.5288\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.6625 - auc: 0.7310 - loss: 0.6158 - val_accuracy: 0.5000 - val_auc: 0.8333 - val_loss: 0.8270\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 889ms/step - accuracy: 0.4515 - auc: 0.5057 - loss: 0.8250 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6150\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 779ms/step - accuracy: 0.6192 - auc: 0.6297 - loss: 0.6776 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6559\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 800ms/step - accuracy: 0.6094 - auc: 0.6439 - loss: 0.6639 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6392\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 887ms/step - accuracy: 0.6181 - auc: 0.6385 - loss: 0.6609 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6283\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 789ms/step - accuracy: 0.6044 - auc: 0.6328 - loss: 0.6401 - val_accuracy: 0.6333 - val_auc: 0.8333 - val_loss: 0.6161\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 756ms/step - accuracy: 0.4688 - auc: 0.4558 - loss: 0.6785 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.5962\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 791ms/step - accuracy: 0.6232 - auc: 0.6604 - loss: 0.6338 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.5597\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 767ms/step - accuracy: 0.6583 - auc: 0.7104 - loss: 0.6229 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.5174\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 808ms/step - accuracy: 0.6015 - auc: 0.7615 - loss: 0.5950 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4698\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.7535 - auc: 0.7594 - loss: 0.5500 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4404\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 874ms/step - accuracy: 0.6886 - auc: 0.6648 - loss: 0.5590 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4194\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 881ms/step - accuracy: 0.7366 - auc: 0.7972 - loss: 0.5066 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.4016\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 789ms/step - accuracy: 0.7558 - auc: 0.7631 - loss: 0.5051 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3920\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774ms/step - accuracy: 0.7879 - auc: 0.7628 - loss: 0.4944 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3883\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 753ms/step - accuracy: 0.7615 - auc: 0.7717 - loss: 0.4783 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3850\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 780ms/step - accuracy: 0.7460 - auc: 0.8047 - loss: 0.4899 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3830\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.7502 - auc: 0.7209 - loss: 0.5130 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3821\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 906ms/step - accuracy: 0.7316 - auc: 0.8010 - loss: 0.4844 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3814\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 793ms/step - accuracy: 0.7615 - auc: 0.7395 - loss: 0.4850 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3805\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 802ms/step - accuracy: 0.7398 - auc: 0.7644 - loss: 0.4987 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3794\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.7398 - auc: 0.7307 - loss: 0.5137 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3797\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 795ms/step - accuracy: 0.7615 - auc: 0.8990 - loss: 0.4438 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3828\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.7533 - auc: 0.7881 - loss: 0.4852 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3867\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 975ms/step - accuracy: 0.7615 - auc: 0.7241 - loss: 0.4890 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3856\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 917ms/step - accuracy: 0.7615 - auc: 0.7198 - loss: 0.4927 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3802\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 811ms/step - accuracy: 0.7615 - auc: 0.7741 - loss: 0.4778 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 812ms/step - accuracy: 0.7615 - auc: 0.7414 - loss: 0.4929 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3772\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.7398 - auc: 0.7378 - loss: 0.5089 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3777\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 797ms/step - accuracy: 0.7615 - auc: 0.8533 - loss: 0.4452 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3787\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809ms/step - accuracy: 0.7615 - auc: 0.6784 - loss: 0.5129 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3817\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900ms/step - accuracy: 0.7615 - auc: 0.7157 - loss: 0.4971 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3805\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.7615 - auc: 0.8208 - loss: 0.4622 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 792ms/step - accuracy: 0.7615 - auc: 0.7474 - loss: 0.4796 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3765\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 789ms/step - accuracy: 0.7615 - auc: 0.7978 - loss: 0.4753 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3763\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 893ms/step - accuracy: 0.7671 - auc: 0.7442 - loss: 0.4857 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 917ms/step - accuracy: 0.7615 - auc: 0.7220 - loss: 0.4887 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3807\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.7615 - auc: 0.7248 - loss: 0.4831 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3817\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 797ms/step - accuracy: 0.7615 - auc: 0.6918 - loss: 0.4975 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3800\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 782ms/step - accuracy: 0.7615 - auc: 0.6839 - loss: 0.5015 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 767ms/step - accuracy: 0.7615 - auc: 0.6258 - loss: 0.5245 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.7615 - auc: 0.7996 - loss: 0.4725 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3795\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.7615 - auc: 0.7323 - loss: 0.4859 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3795\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 797ms/step - accuracy: 0.7615 - auc: 0.6737 - loss: 0.4977 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3789\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 794ms/step - accuracy: 0.7024 - auc: 0.7026 - loss: 0.5429 - val_accuracy: 0.7333 - val_auc: 0.7333 - val_loss: 0.5004\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 933ms/step - accuracy: 0.6367 - auc: 0.5947 - loss: 0.6417 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6034\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.6207 - auc: 0.6343 - loss: 0.6294 - val_accuracy: 0.6333 - val_auc: 0.5333 - val_loss: 0.5941\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 776ms/step - accuracy: 0.6459 - auc: 0.5815 - loss: 0.6107 - val_accuracy: 0.7333 - val_auc: 0.7333 - val_loss: 0.5548\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.6560 - auc: 0.6885 - loss: 0.5897 - val_accuracy: 0.7333 - val_auc: 0.7333 - val_loss: 0.5209\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 891ms/step - accuracy: 0.6894 - auc: 0.6409 - loss: 0.5745 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4627\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 788ms/step - accuracy: 0.6988 - auc: 0.7649 - loss: 0.5562 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.4675\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 786ms/step - accuracy: 0.7398 - auc: 0.8133 - loss: 0.5208 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4161\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.7445 - auc: 0.7142 - loss: 0.5359 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3934\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.7818 - auc: 0.7921 - loss: 0.4703 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3911\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867ms/step - accuracy: 0.7398 - auc: 0.6864 - loss: 0.5149 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3902\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.7615 - auc: 0.7666 - loss: 0.4796 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3823\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783ms/step - accuracy: 0.7558 - auc: 0.6116 - loss: 0.5183 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3809\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 758ms/step - accuracy: 0.7615 - auc: 0.7343 - loss: 0.4867 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3827\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.7615 - auc: 0.8629 - loss: 0.4629 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3821\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 791ms/step - accuracy: 0.7615 - auc: 0.7476 - loss: 0.5006 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3790\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 802ms/step - accuracy: 0.7615 - auc: 0.7429 - loss: 0.4825 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3783\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.7280 - auc: 0.6588 - loss: 0.5292 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.7398 - auc: 0.7594 - loss: 0.4918 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3783\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.7615 - auc: 0.6833 - loss: 0.4939 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3784\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 892ms/step - accuracy: 0.7533 - auc: 0.7763 - loss: 0.4840 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 807ms/step - accuracy: 0.7558 - auc: 0.7852 - loss: 0.4845 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3811\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 881ms/step - accuracy: 0.7579 - auc: 0.7420 - loss: 0.4904 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4106\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 874ms/step - accuracy: 0.7466 - auc: 0.7835 - loss: 0.4975 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3858\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.7615 - auc: 0.6961 - loss: 0.5082 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3796\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 927ms/step - accuracy: 0.7615 - auc: 0.7603 - loss: 0.4875 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3803\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.7398 - auc: 0.7176 - loss: 0.5024 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3805\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.7615 - auc: 0.7730 - loss: 0.4807 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3822\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7615 - auc: 0.6881 - loss: 0.5053 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3800\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 845ms/step - accuracy: 0.7615 - auc: 0.6793 - loss: 0.5034 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3797\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 897ms/step - accuracy: 0.7558 - auc: 0.7033 - loss: 0.4958 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3790\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 930ms/step - accuracy: 0.7615 - auc: 0.7449 - loss: 0.4809 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3799\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 884ms/step - accuracy: 0.7615 - auc: 0.8661 - loss: 0.4733 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3795\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 886ms/step - accuracy: 0.7615 - auc: 0.7545 - loss: 0.4798 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3790\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 788ms/step - accuracy: 0.7615 - auc: 0.8124 - loss: 0.4615 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3785\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 898ms/step - accuracy: 0.7615 - auc: 0.7470 - loss: 0.4729 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3782\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 914ms/step - accuracy: 0.7615 - auc: 0.7859 - loss: 0.4760 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3781\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 921ms/step - accuracy: 0.7615 - auc: 0.7209 - loss: 0.4849 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3781\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 907ms/step - accuracy: 0.7615 - auc: 0.7574 - loss: 0.4807 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3777\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 788ms/step - accuracy: 0.7615 - auc: 0.7518 - loss: 0.4775 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3773\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 785ms/step - accuracy: 0.7615 - auc: 0.8372 - loss: 0.4623 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 871ms/step - accuracy: 0.7615 - auc: 0.8666 - loss: 0.4609 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.7615 - auc: 0.7345 - loss: 0.4847 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3770\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.7615 - auc: 0.6873 - loss: 0.4950 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.7615 - auc: 0.6796 - loss: 0.4871 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3790\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 921ms/step - accuracy: 0.7615 - auc: 0.7958 - loss: 0.4741 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3797\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.7615 - auc: 0.7259 - loss: 0.4834 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3805\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.7615 - auc: 0.7202 - loss: 0.4769 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3796\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.7615 - auc: 0.6908 - loss: 0.4893 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3791\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 869ms/step - accuracy: 0.7615 - auc: 0.7656 - loss: 0.4678 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.7615 - auc: 0.7618 - loss: 0.4803 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3774\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 761ms/step - accuracy: 0.7615 - auc: 0.7077 - loss: 0.4879 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3769\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.7615 - auc: 0.6897 - loss: 0.4916 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.7615 - auc: 0.6808 - loss: 0.4981 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 779ms/step - accuracy: 0.7615 - auc: 0.7156 - loss: 0.4860 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 785ms/step - accuracy: 0.7615 - auc: 0.7238 - loss: 0.4890 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3799\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 819ms/step - accuracy: 0.7615 - auc: 0.8111 - loss: 0.4742 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3806\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 868ms/step - accuracy: 0.7615 - auc: 0.7439 - loss: 0.4805 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3802\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 800ms/step - accuracy: 0.7615 - auc: 0.7859 - loss: 0.4719 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3797\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 809ms/step - accuracy: 0.7615 - auc: 0.7484 - loss: 0.4772 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 774ms/step - accuracy: 0.7615 - auc: 0.7678 - loss: 0.4780 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 775ms/step - accuracy: 0.7615 - auc: 0.8756 - loss: 0.4525 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 905ms/step - accuracy: 0.7615 - auc: 0.8222 - loss: 0.4603 - val_accuracy: 0.8333 - val_auc: 0.8222 - val_loss: 0.3772\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 769ms/step - accuracy: 0.7615 - auc: 0.5997 - loss: 0.5137 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 831ms/step - accuracy: 0.7615 - auc: 0.7492 - loss: 0.4792 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3779\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.7615 - auc: 0.7359 - loss: 0.4869 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3782\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 764ms/step - accuracy: 0.7615 - auc: 0.6343 - loss: 0.5009 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3785\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.7615 - auc: 0.7391 - loss: 0.4803 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 783ms/step - accuracy: 0.7615 - auc: 0.7376 - loss: 0.4821 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3776\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 827ms/step - accuracy: 0.7615 - auc: 0.7342 - loss: 0.4826 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875ms/step - accuracy: 0.7615 - auc: 0.7266 - loss: 0.4870 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3778\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 933ms/step - accuracy: 0.7615 - auc: 0.8294 - loss: 0.4679 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3782\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890ms/step - accuracy: 0.7615 - auc: 0.6867 - loss: 0.4916 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3784\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.7615 - auc: 0.7431 - loss: 0.4808 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 803ms/step - accuracy: 0.7615 - auc: 0.7452 - loss: 0.4890 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3780\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 907ms/step - accuracy: 0.7615 - auc: 0.7916 - loss: 0.4698 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3780\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.7615 - auc: 0.8095 - loss: 0.4758 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3787\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.7615 - auc: 0.7306 - loss: 0.4838 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3794\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 782ms/step - accuracy: 0.7615 - auc: 0.7114 - loss: 0.4844 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787ms/step - accuracy: 0.7615 - auc: 0.7168 - loss: 0.4861 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3786\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.7615 - auc: 0.7194 - loss: 0.4851 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3779\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.7615 - auc: 0.7485 - loss: 0.4773 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3771\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 845ms/step - accuracy: 0.7615 - auc: 0.7622 - loss: 0.4844 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3772\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867ms/step - accuracy: 0.7615 - auc: 0.7245 - loss: 0.4848 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3777\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 800ms/step - accuracy: 0.7615 - auc: 0.8740 - loss: 0.4636 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3777\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 984ms/step - accuracy: 0.7615 - auc: 0.7861 - loss: 0.4717 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3770\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 874ms/step - accuracy: 0.7615 - auc: 0.8152 - loss: 0.4725 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3767\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.7615 - auc: 0.7830 - loss: 0.4752 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 769ms/step - accuracy: 0.7502 - auc: 0.7803 - loss: 0.4845 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3779\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 779ms/step - accuracy: 0.7615 - auc: 0.6119 - loss: 0.5024 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3787\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 901ms/step - accuracy: 0.7615 - auc: 0.6739 - loss: 0.5035 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3794\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 891ms/step - accuracy: 0.7615 - auc: 0.7574 - loss: 0.4748 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3797\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 806ms/step - accuracy: 0.7615 - auc: 0.7108 - loss: 0.4823 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3801\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 781ms/step - accuracy: 0.7615 - auc: 0.7143 - loss: 0.4875 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3799\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 794ms/step - accuracy: 0.7615 - auc: 0.7588 - loss: 0.4742 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3796\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890ms/step - accuracy: 0.7615 - auc: 0.8018 - loss: 0.4710 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3791\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.7615 - auc: 0.8176 - loss: 0.4607 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3789\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 796ms/step - accuracy: 0.7615 - auc: 0.7689 - loss: 0.4768 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3786\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 798ms/step - accuracy: 0.7615 - auc: 0.6668 - loss: 0.4983 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3788\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 883ms/step - accuracy: 0.7615 - auc: 0.7892 - loss: 0.4774 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3793\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 919ms/step - accuracy: 0.7615 - auc: 0.8213 - loss: 0.4758 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3797\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 854ms/step - accuracy: 0.7615 - auc: 0.8086 - loss: 0.4677 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3791\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.7615 - auc: 0.7190 - loss: 0.4855 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3796\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.7615 - auc: 0.7566 - loss: 0.4782 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3802\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.7615 - auc: 0.7573 - loss: 0.4781 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3798\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 776ms/step - accuracy: 0.7615 - auc: 0.6884 - loss: 0.4898 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3792\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 834ms/step - accuracy: 0.7615 - auc: 0.6994 - loss: 0.4886 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3778\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 826ms/step - accuracy: 0.7615 - auc: 0.8301 - loss: 0.4676 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3767\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 903ms/step - accuracy: 0.7615 - auc: 0.6821 - loss: 0.4916 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3766\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 782ms/step - accuracy: 0.7615 - auc: 0.8771 - loss: 0.4627 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3763\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 808ms/step - accuracy: 0.7615 - auc: 0.8232 - loss: 0.4684 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 795ms/step - accuracy: 0.7615 - auc: 0.7545 - loss: 0.4707 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3760\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 818ms/step - accuracy: 0.7398 - auc: 0.7967 - loss: 0.5200 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3900\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 921ms/step - accuracy: 0.7130 - auc: 0.6122 - loss: 0.5590 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3768\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.7615 - auc: 0.6608 - loss: 0.4891 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3782\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.7615 - auc: 0.8281 - loss: 0.4552 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3801\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 872ms/step - accuracy: 0.7615 - auc: 0.7971 - loss: 0.4692 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3797\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.7615 - auc: 0.7230 - loss: 0.4896 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3782\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.7615 - auc: 0.6543 - loss: 0.5007 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3781\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 956ms/step - accuracy: 0.7615 - auc: 0.6366 - loss: 0.4919 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3781\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.7615 - auc: 0.6329 - loss: 0.5027 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3788\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.7615 - auc: 0.6857 - loss: 0.4849 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3796\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 896ms/step - accuracy: 0.7615 - auc: 0.7569 - loss: 0.4758 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3797\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.7615 - auc: 0.8480 - loss: 0.4644 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3788\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774ms/step - accuracy: 0.7615 - auc: 0.8265 - loss: 0.4705 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3780\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883ms/step - accuracy: 0.7615 - auc: 0.7642 - loss: 0.4773 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3773\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 633ms/step - accuracy: 0.7615 - auc: 0.7625 - loss: 0.4770 - val_accuracy: 0.8333 - val_auc: 0.8444 - val_loss: 0.3775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [23:43, 1423.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 1s/step - accuracy: 0.5668 - auc: 0.6022 - loss: 0.6808 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6974\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 813ms/step - accuracy: 0.5753 - auc: 0.5490 - loss: 0.6812 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6893\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 773ms/step - accuracy: 0.5572 - auc: 0.5873 - loss: 0.6755 - val_accuracy: 0.5000 - val_auc: 0.5333 - val_loss: 0.6925\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 935ms/step - accuracy: 0.4067 - auc: 0.3650 - loss: 0.7093 - val_accuracy: 0.5667 - val_auc: 0.6000 - val_loss: 0.6915\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 784ms/step - accuracy: 0.6326 - auc: 0.6064 - loss: 0.6847 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6856\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.4883 - auc: 0.5179 - loss: 0.6855 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6835\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 978ms/step - accuracy: 0.5504 - auc: 0.5741 - loss: 0.6836 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6834\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.5604 - auc: 0.5554 - loss: 0.6869 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6844\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 789ms/step - accuracy: 0.5524 - auc: 0.6325 - loss: 0.6782 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6801\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 976ms/step - accuracy: 0.5677 - auc: 0.5733 - loss: 0.6738 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6757\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 929ms/step - accuracy: 0.5417 - auc: 0.5548 - loss: 0.6804 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6719\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 790ms/step - accuracy: 0.5667 - auc: 0.6416 - loss: 0.6743 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6639\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.4463 - auc: 0.4459 - loss: 0.6879 - val_accuracy: 0.6000 - val_auc: 0.8000 - val_loss: 0.6603\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.5179 - auc: 0.3978 - loss: 0.6993 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6510\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 847ms/step - accuracy: 0.5245 - auc: 0.6419 - loss: 0.6610 - val_accuracy: 0.6000 - val_auc: 0.8000 - val_loss: 0.6430\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 819ms/step - accuracy: 0.5936 - auc: 0.5609 - loss: 0.6610 - val_accuracy: 0.6000 - val_auc: 0.8000 - val_loss: 0.6343\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.5112 - auc: 0.6062 - loss: 0.6616 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6263\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 816ms/step - accuracy: 0.6009 - auc: 0.6415 - loss: 0.6373 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5942\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 761ms/step - accuracy: 0.6588 - auc: 0.7417 - loss: 0.5993 - val_accuracy: 0.5000 - val_auc: 0.7600 - val_loss: 0.6773\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.7854 - auc: 0.8398 - loss: 0.5395 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.5037\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 934ms/step - accuracy: 0.7406 - auc: 0.7019 - loss: 0.5510 - val_accuracy: 0.7667 - val_auc: 0.7600 - val_loss: 0.5007\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.7132 - auc: 0.8950 - loss: 0.4985 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4908\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.6930 - auc: 0.8354 - loss: 0.5334 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4906\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 909ms/step - accuracy: 0.7361 - auc: 0.7874 - loss: 0.5165 - val_accuracy: 0.7000 - val_auc: 0.7200 - val_loss: 0.5593\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 803ms/step - accuracy: 0.6190 - auc: 0.7433 - loss: 0.7088 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.4613\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.6960 - auc: 0.7478 - loss: 0.5521 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5516\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 894ms/step - accuracy: 0.6352 - auc: 0.7190 - loss: 0.6095 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5558\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 891ms/step - accuracy: 0.6434 - auc: 0.7101 - loss: 0.5985 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5394\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 783ms/step - accuracy: 0.6707 - auc: 0.7444 - loss: 0.5810 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4440\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 908ms/step - accuracy: 0.7287 - auc: 0.7781 - loss: 0.5051 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4608\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 880ms/step - accuracy: 0.7204 - auc: 0.7638 - loss: 0.5264 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4404\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 989ms/step - accuracy: 0.7780 - auc: 0.7398 - loss: 0.4852 - val_accuracy: 0.7667 - val_auc: 0.7867 - val_loss: 0.4903\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 804ms/step - accuracy: 0.7287 - auc: 0.7141 - loss: 0.5381 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4427\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854ms/step - accuracy: 0.7245 - auc: 0.7403 - loss: 0.5312 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5092\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.6588 - auc: 0.8524 - loss: 0.5440 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4828\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.7135 - auc: 0.8065 - loss: 0.4922 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4409\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 926ms/step - accuracy: 0.7667 - auc: 0.8537 - loss: 0.4581 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4298\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.7391 - auc: 0.7718 - loss: 0.4740 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4261\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 816ms/step - accuracy: 0.7450 - auc: 0.7003 - loss: 0.5049 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4250\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.7667 - auc: 0.7492 - loss: 0.4864 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4244\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 807ms/step - accuracy: 0.7667 - auc: 0.7244 - loss: 0.4864 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4233\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.7667 - auc: 0.8173 - loss: 0.4460 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4225\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 907ms/step - accuracy: 0.7498 - auc: 0.7718 - loss: 0.4740 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4221\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 922ms/step - accuracy: 0.7667 - auc: 0.8846 - loss: 0.4311 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4220\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.7667 - auc: 0.7793 - loss: 0.4579 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4213\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 819ms/step - accuracy: 0.7667 - auc: 0.7569 - loss: 0.4526 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4211\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787ms/step - accuracy: 0.7513 - auc: 0.6792 - loss: 0.4834 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4209\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 804ms/step - accuracy: 0.7667 - auc: 0.7026 - loss: 0.4757 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4207\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 898ms/step - accuracy: 0.7667 - auc: 0.8065 - loss: 0.4681 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4204\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 810ms/step - accuracy: 0.7667 - auc: 0.6726 - loss: 0.4963 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4202\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 933ms/step - accuracy: 0.7513 - auc: 0.7864 - loss: 0.4579 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4202\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 817ms/step - accuracy: 0.7667 - auc: 0.7693 - loss: 0.4547 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4201\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 813ms/step - accuracy: 0.7667 - auc: 0.7302 - loss: 0.4646 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4200\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 832ms/step - accuracy: 0.7667 - auc: 0.7628 - loss: 0.4537 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4198\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 899ms/step - accuracy: 0.7667 - auc: 0.7558 - loss: 0.4499 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4197\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 773ms/step - accuracy: 0.7667 - auc: 0.7731 - loss: 0.4451 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4197\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 886ms/step - accuracy: 0.7667 - auc: 0.7229 - loss: 0.4578 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4198\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 804ms/step - accuracy: 0.7667 - auc: 0.7524 - loss: 0.4562 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4199\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.7631 - auc: 0.7922 - loss: 0.4527 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4199\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 934ms/step - accuracy: 0.7667 - auc: 0.7874 - loss: 0.4518 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4199\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 893ms/step - accuracy: 0.7667 - auc: 0.7508 - loss: 0.4689 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4197\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 801ms/step - accuracy: 0.7667 - auc: 0.7085 - loss: 0.4816 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4195\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 821ms/step - accuracy: 0.7667 - auc: 0.7329 - loss: 0.4723 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4194\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 886ms/step - accuracy: 0.7667 - auc: 0.7944 - loss: 0.4519 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4193\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.7667 - auc: 0.7478 - loss: 0.4605 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4192\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 803ms/step - accuracy: 0.7667 - auc: 0.7950 - loss: 0.4520 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4191\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 935ms/step - accuracy: 0.7667 - auc: 0.7277 - loss: 0.4733 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4194\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 814ms/step - accuracy: 0.7667 - auc: 0.7655 - loss: 0.4602 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4194\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 933ms/step - accuracy: 0.7667 - auc: 0.8141 - loss: 0.4375 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4194\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 946ms/step - accuracy: 0.7667 - auc: 0.7946 - loss: 0.4596 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4196\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.7667 - auc: 0.7435 - loss: 0.4597 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.7667 - auc: 0.7772 - loss: 0.4731 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4208\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 803ms/step - accuracy: 0.7667 - auc: 0.8762 - loss: 0.4419 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4193\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 825ms/step - accuracy: 0.7667 - auc: 0.8417 - loss: 0.4406 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4190\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 928ms/step - accuracy: 0.7667 - auc: 0.6759 - loss: 0.4776 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4191\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.7667 - auc: 0.6780 - loss: 0.4713 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.7667 - auc: 0.8254 - loss: 0.4343 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4191\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 860ms/step - accuracy: 0.7667 - auc: 0.8008 - loss: 0.4404 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 944ms/step - accuracy: 0.7667 - auc: 0.7178 - loss: 0.4651 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 832ms/step - accuracy: 0.7667 - auc: 0.7568 - loss: 0.4444 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.7667 - auc: 0.8374 - loss: 0.4409 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.7667 - auc: 0.7500 - loss: 0.4523 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 920ms/step - accuracy: 0.7667 - auc: 0.7950 - loss: 0.4496 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 967ms/step - accuracy: 0.7667 - auc: 0.8157 - loss: 0.4449 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 968ms/step - accuracy: 0.7667 - auc: 0.7371 - loss: 0.4502 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 948ms/step - accuracy: 0.7667 - auc: 0.7401 - loss: 0.4537 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 897ms/step - accuracy: 0.7667 - auc: 0.7572 - loss: 0.4520 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.7667 - auc: 0.8333 - loss: 0.4410 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4190\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 861ms/step - accuracy: 0.7667 - auc: 0.7649 - loss: 0.4605 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4190\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.7667 - auc: 0.8177 - loss: 0.4383 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.7667 - auc: 0.8020 - loss: 0.4444 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.7667 - auc: 0.7007 - loss: 0.4659 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877ms/step - accuracy: 0.7667 - auc: 0.7941 - loss: 0.4477 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4192\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 769ms/step - accuracy: 0.7667 - auc: 0.7589 - loss: 0.4528 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4195\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864ms/step - accuracy: 0.7667 - auc: 0.7316 - loss: 0.4466 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4193\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 770ms/step - accuracy: 0.7667 - auc: 0.7512 - loss: 0.4548 - val_accuracy: 0.8000 - val_auc: 0.7867 - val_loss: 0.4192\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 776ms/step - accuracy: 0.7667 - auc: 0.7314 - loss: 0.4556 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.7667 - auc: 0.7793 - loss: 0.4470 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 763ms/step - accuracy: 0.7667 - auc: 0.7955 - loss: 0.4541 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 761ms/step - accuracy: 0.7667 - auc: 0.6835 - loss: 0.4636 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765ms/step - accuracy: 0.7667 - auc: 0.8213 - loss: 0.4411 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 742ms/step - accuracy: 0.7667 - auc: 0.7484 - loss: 0.4636 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 743ms/step - accuracy: 0.7667 - auc: 0.7636 - loss: 0.4552 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 756ms/step - accuracy: 0.7667 - auc: 0.8545 - loss: 0.4377 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.7667 - auc: 0.7652 - loss: 0.4458 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 749ms/step - accuracy: 0.7667 - auc: 0.7820 - loss: 0.4518 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 763ms/step - accuracy: 0.7667 - auc: 0.7528 - loss: 0.4517 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4187\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 871ms/step - accuracy: 0.7667 - auc: 0.8015 - loss: 0.4386 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 890ms/step - accuracy: 0.7667 - auc: 0.7946 - loss: 0.4473 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4188\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 772ms/step - accuracy: 0.7667 - auc: 0.8080 - loss: 0.4420 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 773ms/step - accuracy: 0.7667 - auc: 0.7193 - loss: 0.4617 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.7667 - auc: 0.7698 - loss: 0.4625 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.7667 - auc: 0.8363 - loss: 0.4361 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 942ms/step - accuracy: 0.7667 - auc: 0.8013 - loss: 0.4453 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 960ms/step - accuracy: 0.7667 - auc: 0.8602 - loss: 0.4329 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 918ms/step - accuracy: 0.7667 - auc: 0.8029 - loss: 0.4468 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883ms/step - accuracy: 0.7667 - auc: 0.7316 - loss: 0.4617 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875ms/step - accuracy: 0.7667 - auc: 0.7759 - loss: 0.4509 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4190\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 786ms/step - accuracy: 0.7667 - auc: 0.6654 - loss: 0.4685 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 898ms/step - accuracy: 0.7667 - auc: 0.8551 - loss: 0.4383 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.7667 - auc: 0.7956 - loss: 0.4441 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 908ms/step - accuracy: 0.7667 - auc: 0.8047 - loss: 0.4434 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4189\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.7667 - auc: 0.6787 - loss: 0.4704 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.7667 - auc: 0.7960 - loss: 0.4399 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4181\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 884ms/step - accuracy: 0.7667 - auc: 0.8572 - loss: 0.4367 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4188\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 901ms/step - accuracy: 0.7667 - auc: 0.7595 - loss: 0.4511 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4194\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 900ms/step - accuracy: 0.7667 - auc: 0.8443 - loss: 0.4484 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4193\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 904ms/step - accuracy: 0.7667 - auc: 0.7728 - loss: 0.4600 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4183\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 795ms/step - accuracy: 0.7667 - auc: 0.7533 - loss: 0.4526 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4179\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.7667 - auc: 0.8556 - loss: 0.4326 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4180\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.7667 - auc: 0.8290 - loss: 0.4397 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.7667 - auc: 0.8132 - loss: 0.4489 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4186\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.7667 - auc: 0.8474 - loss: 0.4480 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4184\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 781ms/step - accuracy: 0.7667 - auc: 0.8024 - loss: 0.4533 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4180\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.7667 - auc: 0.8236 - loss: 0.4420 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4179\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937ms/step - accuracy: 0.7667 - auc: 0.7353 - loss: 0.4597 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.7667 - auc: 0.8084 - loss: 0.4371 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4176\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 802ms/step - accuracy: 0.7667 - auc: 0.6855 - loss: 0.4594 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4180\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 856ms/step - accuracy: 0.7667 - auc: 0.7899 - loss: 0.4442 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4182\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783ms/step - accuracy: 0.7667 - auc: 0.7526 - loss: 0.4484 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4179\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809ms/step - accuracy: 0.7667 - auc: 0.8770 - loss: 0.4325 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 961ms/step - accuracy: 0.7667 - auc: 0.7551 - loss: 0.4498 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4177\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 815ms/step - accuracy: 0.7667 - auc: 0.8140 - loss: 0.4398 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4175\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 906ms/step - accuracy: 0.7667 - auc: 0.7592 - loss: 0.4527 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4180\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 909ms/step - accuracy: 0.7667 - auc: 0.8157 - loss: 0.4502 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 891ms/step - accuracy: 0.7667 - auc: 0.8270 - loss: 0.4488 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4179\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.7667 - auc: 0.8283 - loss: 0.4439 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4175\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 812ms/step - accuracy: 0.7667 - auc: 0.8146 - loss: 0.4376 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4173\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 934ms/step - accuracy: 0.7667 - auc: 0.8199 - loss: 0.4532 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4175\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 909ms/step - accuracy: 0.7667 - auc: 0.7654 - loss: 0.4544 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4173\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 801ms/step - accuracy: 0.7667 - auc: 0.7974 - loss: 0.4415 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4173\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 878ms/step - accuracy: 0.7667 - auc: 0.8125 - loss: 0.4471 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4173\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 832ms/step - accuracy: 0.7667 - auc: 0.7980 - loss: 0.4462 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4175\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 784ms/step - accuracy: 0.7667 - auc: 0.7758 - loss: 0.4522 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4169\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 902ms/step - accuracy: 0.7667 - auc: 0.8669 - loss: 0.4289 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4169\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 895ms/step - accuracy: 0.7667 - auc: 0.7532 - loss: 0.4512 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4170\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 914ms/step - accuracy: 0.7667 - auc: 0.7016 - loss: 0.4641 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4166\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.7667 - auc: 0.7994 - loss: 0.4455 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4165\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.7667 - auc: 0.8150 - loss: 0.4354 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4163\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 871ms/step - accuracy: 0.7667 - auc: 0.7263 - loss: 0.4548 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4164\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 900ms/step - accuracy: 0.7667 - auc: 0.7109 - loss: 0.4605 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4163\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.7667 - auc: 0.8143 - loss: 0.4374 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4160\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.7667 - auc: 0.7966 - loss: 0.4453 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4158\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 876ms/step - accuracy: 0.7667 - auc: 0.7334 - loss: 0.4474 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4157\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 962ms/step - accuracy: 0.7667 - auc: 0.7440 - loss: 0.4528 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4157\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 775ms/step - accuracy: 0.7667 - auc: 0.7931 - loss: 0.4462 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4158\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 771ms/step - accuracy: 0.7667 - auc: 0.8513 - loss: 0.4353 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4163\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 776ms/step - accuracy: 0.7667 - auc: 0.8163 - loss: 0.4509 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4156\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 821ms/step - accuracy: 0.7667 - auc: 0.7908 - loss: 0.4420 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4152\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 885ms/step - accuracy: 0.7667 - auc: 0.7386 - loss: 0.4526 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4151\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 889ms/step - accuracy: 0.7667 - auc: 0.7699 - loss: 0.4463 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4151\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.7667 - auc: 0.8164 - loss: 0.4348 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4148\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 778ms/step - accuracy: 0.7667 - auc: 0.8223 - loss: 0.4345 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4147\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.7667 - auc: 0.7667 - loss: 0.4544 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4152\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 831ms/step - accuracy: 0.7667 - auc: 0.7402 - loss: 0.4523 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4147\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.7667 - auc: 0.7546 - loss: 0.4491 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4157\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 945ms/step - accuracy: 0.7667 - auc: 0.8096 - loss: 0.4472 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4148\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.7667 - auc: 0.8998 - loss: 0.4294 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4143\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 920ms/step - accuracy: 0.7667 - auc: 0.8339 - loss: 0.4403 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4145\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.7667 - auc: 0.7310 - loss: 0.4535 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4139\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 906ms/step - accuracy: 0.7667 - auc: 0.8402 - loss: 0.4382 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4155\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 797ms/step - accuracy: 0.7667 - auc: 0.7545 - loss: 0.4521 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4145\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 964ms/step - accuracy: 0.7667 - auc: 0.8288 - loss: 0.4466 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4156\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 929ms/step - accuracy: 0.7667 - auc: 0.7716 - loss: 0.4502 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4135\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.7667 - auc: 0.8060 - loss: 0.4444 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4140\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783ms/step - accuracy: 0.7667 - auc: 0.7831 - loss: 0.4401 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4141\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 992ms/step - accuracy: 0.7667 - auc: 0.7482 - loss: 0.4506 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4135\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 902ms/step - accuracy: 0.7667 - auc: 0.8557 - loss: 0.4324 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4131\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 781ms/step - accuracy: 0.7667 - auc: 0.8651 - loss: 0.4304 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4128\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865ms/step - accuracy: 0.7667 - auc: 0.8665 - loss: 0.4286 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4145\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 835ms/step - accuracy: 0.7667 - auc: 0.8004 - loss: 0.4420 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4133\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 959ms/step - accuracy: 0.7667 - auc: 0.7925 - loss: 0.4473 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4125\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 794ms/step - accuracy: 0.7667 - auc: 0.8326 - loss: 0.4326 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4122\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 797ms/step - accuracy: 0.7667 - auc: 0.7896 - loss: 0.4419 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4121\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 826ms/step - accuracy: 0.7667 - auc: 0.7578 - loss: 0.4478 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4122\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 803ms/step - accuracy: 0.7667 - auc: 0.8082 - loss: 0.4414 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4117\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.7667 - auc: 0.7631 - loss: 0.4466 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4117\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 844ms/step - accuracy: 0.7667 - auc: 0.7815 - loss: 0.4376 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4122\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 803ms/step - accuracy: 0.7667 - auc: 0.7973 - loss: 0.4369 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4187\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 919ms/step - accuracy: 0.7667 - auc: 0.7009 - loss: 0.4652 - val_accuracy: 0.8000 - val_auc: 0.8133 - val_loss: 0.4123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [48:15, 1452.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.5776 - auc: 0.6501 - loss: 0.6621 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.7012\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.5641 - auc: 0.5054 - loss: 0.6887 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6906\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6212 - auc: 0.6007 - loss: 0.6746 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6914\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 935ms/step - accuracy: 0.5220 - auc: 0.5709 - loss: 0.6837 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6940\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 871ms/step - accuracy: 0.4574 - auc: 0.4962 - loss: 0.7015 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6935\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 859ms/step - accuracy: 0.3465 - auc: 0.5044 - loss: 0.7107 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6925\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 982ms/step - accuracy: 0.5207 - auc: 0.5083 - loss: 0.6959 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6920\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.5329 - auc: 0.5131 - loss: 0.6916 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6910\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.4526 - auc: 0.4481 - loss: 0.6971 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6905\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 972ms/step - accuracy: 0.5243 - auc: 0.5554 - loss: 0.6846 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6897\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 915ms/step - accuracy: 0.5366 - auc: 0.5921 - loss: 0.6810 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6892\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.6050 - auc: 0.6455 - loss: 0.6832 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6883\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 899ms/step - accuracy: 0.4110 - auc: 0.4935 - loss: 0.6976 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6876\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 910ms/step - accuracy: 0.4668 - auc: 0.4713 - loss: 0.6984 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6868\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 959ms/step - accuracy: 0.4751 - auc: 0.4791 - loss: 0.6993 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6863\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 985ms/step - accuracy: 0.4520 - auc: 0.4959 - loss: 0.6895 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6864\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.5415 - auc: 0.5703 - loss: 0.6859 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6860\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 955ms/step - accuracy: 0.5524 - auc: 0.6581 - loss: 0.6879 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6843\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 926ms/step - accuracy: 0.6047 - auc: 0.5684 - loss: 0.6880 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6834\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 948ms/step - accuracy: 0.5428 - auc: 0.5882 - loss: 0.6876 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6829\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 907ms/step - accuracy: 0.6180 - auc: 0.5487 - loss: 0.6913 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6816\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.6161 - auc: 0.6262 - loss: 0.6803 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6799\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 947ms/step - accuracy: 0.5638 - auc: 0.5459 - loss: 0.6852 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6783\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 803ms/step - accuracy: 0.6101 - auc: 0.5357 - loss: 0.6840 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6777\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 952ms/step - accuracy: 0.5252 - auc: 0.5905 - loss: 0.6837 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6765\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 978ms/step - accuracy: 0.6046 - auc: 0.5995 - loss: 0.6841 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6753\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 902ms/step - accuracy: 0.5429 - auc: 0.5913 - loss: 0.6785 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6739\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 826ms/step - accuracy: 0.4616 - auc: 0.4562 - loss: 0.7014 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6723\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 971ms/step - accuracy: 0.5554 - auc: 0.5213 - loss: 0.6868 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6694\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 961ms/step - accuracy: 0.5429 - auc: 0.6214 - loss: 0.6696 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6653\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.6894 - auc: 0.6960 - loss: 0.6526 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6628\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.5597 - auc: 0.5439 - loss: 0.6842 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6608\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 835ms/step - accuracy: 0.5970 - auc: 0.6124 - loss: 0.6727 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6581\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 899ms/step - accuracy: 0.6648 - auc: 0.5587 - loss: 0.6806 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6571\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.5805 - auc: 0.4993 - loss: 0.6766 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6566\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 837ms/step - accuracy: 0.6541 - auc: 0.6164 - loss: 0.6643 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6546\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950ms/step - accuracy: 0.6968 - auc: 0.7103 - loss: 0.6570 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6523\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.6406 - auc: 0.6314 - loss: 0.6545 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6497\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 778ms/step - accuracy: 0.6437 - auc: 0.6832 - loss: 0.6499 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6474\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 889ms/step - accuracy: 0.5163 - auc: 0.6310 - loss: 0.6589 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6453\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 931ms/step - accuracy: 0.6190 - auc: 0.6613 - loss: 0.6505 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6434\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 889ms/step - accuracy: 0.6323 - auc: 0.5405 - loss: 0.6585 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6408\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 806ms/step - accuracy: 0.5717 - auc: 0.5669 - loss: 0.6656 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6371\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 939ms/step - accuracy: 0.5392 - auc: 0.5920 - loss: 0.6574 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.5907\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 936ms/step - accuracy: 0.6179 - auc: 0.7122 - loss: 0.6383 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.5748\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 775ms/step - accuracy: 0.7365 - auc: 0.6650 - loss: 0.6114 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.5638\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 822ms/step - accuracy: 0.7307 - auc: 0.7378 - loss: 0.5926 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4877\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 786ms/step - accuracy: 0.7617 - auc: 0.6782 - loss: 0.5679 - val_accuracy: 0.7333 - val_auc: 0.7333 - val_loss: 0.5610\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 937ms/step - accuracy: 0.7199 - auc: 0.8444 - loss: 0.5471 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.5604\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 799ms/step - accuracy: 0.6468 - auc: 0.7119 - loss: 0.6034 - val_accuracy: 0.7333 - val_auc: 0.8111 - val_loss: 0.5454\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 886ms/step - accuracy: 0.7594 - auc: 0.8150 - loss: 0.5483 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.5438\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.7037 - auc: 0.7487 - loss: 0.5783 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4567\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.8213 - auc: 0.8047 - loss: 0.4856 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4838\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 902ms/step - accuracy: 0.7785 - auc: 0.8319 - loss: 0.4782 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4233\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 922ms/step - accuracy: 0.7655 - auc: 0.7627 - loss: 0.5165 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.4383\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 964ms/step - accuracy: 0.7635 - auc: 0.7185 - loss: 0.5142 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4169\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 822ms/step - accuracy: 0.8336 - auc: 0.7682 - loss: 0.4692 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4119\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.8035 - auc: 0.7716 - loss: 0.4876 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4041\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 790ms/step - accuracy: 0.8171 - auc: 0.7437 - loss: 0.4628 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3985\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.8171 - auc: 0.8522 - loss: 0.4210 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3996\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 926ms/step - accuracy: 0.8171 - auc: 0.8186 - loss: 0.4406 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4054\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 843ms/step - accuracy: 0.8135 - auc: 0.7799 - loss: 0.4467 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4194\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 843ms/step - accuracy: 0.8108 - auc: 0.7699 - loss: 0.4575 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4105\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 881ms/step - accuracy: 0.7841 - auc: 0.7367 - loss: 0.4724 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3902\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864ms/step - accuracy: 0.8171 - auc: 0.6639 - loss: 0.5019 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3859\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 792ms/step - accuracy: 0.7882 - auc: 0.7328 - loss: 0.4761 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3834\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 895ms/step - accuracy: 0.8177 - auc: 0.7059 - loss: 0.4691 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3845\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 970ms/step - accuracy: 0.7829 - auc: 0.7353 - loss: 0.4717 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3846\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890ms/step - accuracy: 0.7865 - auc: 0.6694 - loss: 0.4891 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3847\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 917ms/step - accuracy: 0.7960 - auc: 0.8071 - loss: 0.4348 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3830\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.8275 - auc: 0.7761 - loss: 0.4507 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3818\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.8171 - auc: 0.7783 - loss: 0.4309 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3812\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 828ms/step - accuracy: 0.8171 - auc: 0.8630 - loss: 0.4118 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3795\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 751ms/step - accuracy: 0.8171 - auc: 0.7552 - loss: 0.4368 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3795\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 766ms/step - accuracy: 0.7829 - auc: 0.8277 - loss: 0.4403 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 814ms/step - accuracy: 0.8114 - auc: 0.7512 - loss: 0.4411 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3796\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.7954 - auc: 0.8782 - loss: 0.4048 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3794\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 833ms/step - accuracy: 0.8171 - auc: 0.7686 - loss: 0.4344 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3796\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 756ms/step - accuracy: 0.8058 - auc: 0.7168 - loss: 0.4538 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3790\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 854ms/step - accuracy: 0.8513 - auc: 0.8335 - loss: 0.4235 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3782\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 757ms/step - accuracy: 0.8008 - auc: 0.8179 - loss: 0.4254 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 776ms/step - accuracy: 0.8171 - auc: 0.7286 - loss: 0.4370 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3777\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.7954 - auc: 0.7404 - loss: 0.4476 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3781\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 758ms/step - accuracy: 0.8171 - auc: 0.7788 - loss: 0.4384 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 880ms/step - accuracy: 0.8171 - auc: 0.8825 - loss: 0.4146 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 755ms/step - accuracy: 0.8171 - auc: 0.8195 - loss: 0.4194 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 792ms/step - accuracy: 0.8171 - auc: 0.8123 - loss: 0.4251 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 724ms/step - accuracy: 0.8171 - auc: 0.8239 - loss: 0.4183 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3775\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.8171 - auc: 0.8150 - loss: 0.4218 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.8171 - auc: 0.8589 - loss: 0.4067 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3773\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.8171 - auc: 0.7173 - loss: 0.4463 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 744ms/step - accuracy: 0.8171 - auc: 0.7556 - loss: 0.4284 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3791\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 782ms/step - accuracy: 0.8171 - auc: 0.7751 - loss: 0.4245 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3807\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.8171 - auc: 0.7158 - loss: 0.4354 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3800\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 746ms/step - accuracy: 0.8171 - auc: 0.7897 - loss: 0.4252 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 801ms/step - accuracy: 0.8171 - auc: 0.7746 - loss: 0.4186 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3772\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 849ms/step - accuracy: 0.8171 - auc: 0.7086 - loss: 0.4453 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792ms/step - accuracy: 0.8171 - auc: 0.6919 - loss: 0.4368 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3771\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.8058 - auc: 0.7725 - loss: 0.4352 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3772\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 874ms/step - accuracy: 0.8171 - auc: 0.8019 - loss: 0.4235 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3775\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.7607 - loss: 0.4353 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3787\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882ms/step - accuracy: 0.8171 - auc: 0.7625 - loss: 0.4337 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3815\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 723ms/step - accuracy: 0.8171 - auc: 0.7147 - loss: 0.4376 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3849\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 709ms/step - accuracy: 0.8171 - auc: 0.7823 - loss: 0.4305 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3832\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 718ms/step - accuracy: 0.8171 - auc: 0.7388 - loss: 0.4376 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3824\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765ms/step - accuracy: 0.7954 - auc: 0.7294 - loss: 0.4520 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3809\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 747ms/step - accuracy: 0.8171 - auc: 0.7341 - loss: 0.4374 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3804\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 857ms/step - accuracy: 0.8171 - auc: 0.8381 - loss: 0.4158 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 766ms/step - accuracy: 0.8171 - auc: 0.6445 - loss: 0.4650 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3798\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.8171 - auc: 0.8365 - loss: 0.4166 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3816\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8171 - auc: 0.8026 - loss: 0.4185 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3838\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8171 - auc: 0.8423 - loss: 0.4195 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3836\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 779ms/step - accuracy: 0.8171 - auc: 0.8042 - loss: 0.4282 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3820\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.8171 - auc: 0.7422 - loss: 0.4400 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3814\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 758ms/step - accuracy: 0.8171 - auc: 0.7664 - loss: 0.4264 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3807\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.8171 - auc: 0.7668 - loss: 0.4229 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3802\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 756ms/step - accuracy: 0.8171 - auc: 0.8048 - loss: 0.4225 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3809\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 882ms/step - accuracy: 0.8171 - auc: 0.7005 - loss: 0.4440 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3812\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8171 - auc: 0.8140 - loss: 0.4227 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3815\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 873ms/step - accuracy: 0.8171 - auc: 0.7583 - loss: 0.4274 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3814\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 766ms/step - accuracy: 0.8171 - auc: 0.7282 - loss: 0.4378 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3811\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 905ms/step - accuracy: 0.8171 - auc: 0.8757 - loss: 0.4090 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3801\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.7283 - loss: 0.4365 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3794\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 836ms/step - accuracy: 0.8171 - auc: 0.7297 - loss: 0.4292 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3794\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 770ms/step - accuracy: 0.8171 - auc: 0.8172 - loss: 0.4228 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3798\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 779ms/step - accuracy: 0.8171 - auc: 0.8577 - loss: 0.4154 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3798\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900ms/step - accuracy: 0.8171 - auc: 0.9070 - loss: 0.4037 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3794\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 851ms/step - accuracy: 0.8171 - auc: 0.8002 - loss: 0.4241 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3795\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 753ms/step - accuracy: 0.8171 - auc: 0.8610 - loss: 0.4104 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3791\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 844ms/step - accuracy: 0.8171 - auc: 0.7938 - loss: 0.4226 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 753ms/step - accuracy: 0.8171 - auc: 0.8000 - loss: 0.4217 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3794\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 786ms/step - accuracy: 0.8171 - auc: 0.7821 - loss: 0.4237 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3795\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.8171 - auc: 0.7509 - loss: 0.4265 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3794\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 771ms/step - accuracy: 0.8171 - auc: 0.7270 - loss: 0.4264 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3793\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.8171 - auc: 0.7365 - loss: 0.4334 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.9258 - loss: 0.3922 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3785\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 891ms/step - accuracy: 0.8171 - auc: 0.8762 - loss: 0.4007 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3776\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759ms/step - accuracy: 0.8171 - auc: 0.7870 - loss: 0.4262 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3776\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.8171 - auc: 0.7291 - loss: 0.4335 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3778\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 873ms/step - accuracy: 0.8171 - auc: 0.7538 - loss: 0.4306 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3782\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 877ms/step - accuracy: 0.8171 - auc: 0.7830 - loss: 0.4231 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3786\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 766ms/step - accuracy: 0.8171 - auc: 0.7994 - loss: 0.4200 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3795\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893ms/step - accuracy: 0.8171 - auc: 0.6986 - loss: 0.4360 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3806\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 744ms/step - accuracy: 0.8171 - auc: 0.7390 - loss: 0.4265 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3815\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 729ms/step - accuracy: 0.8171 - auc: 0.7265 - loss: 0.4289 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3822\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 745ms/step - accuracy: 0.8171 - auc: 0.8521 - loss: 0.4129 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3824\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 892ms/step - accuracy: 0.8171 - auc: 0.8243 - loss: 0.4226 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3823\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 850ms/step - accuracy: 0.8171 - auc: 0.7768 - loss: 0.4280 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3809\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 870ms/step - accuracy: 0.8171 - auc: 0.7827 - loss: 0.4216 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3796\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792ms/step - accuracy: 0.8171 - auc: 0.8358 - loss: 0.4149 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3783\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 842ms/step - accuracy: 0.8171 - auc: 0.7576 - loss: 0.4226 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3763\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774ms/step - accuracy: 0.8171 - auc: 0.8340 - loss: 0.4142 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3755\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 789ms/step - accuracy: 0.8171 - auc: 0.7450 - loss: 0.4372 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3768\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 730ms/step - accuracy: 0.8171 - auc: 0.8894 - loss: 0.4047 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3802\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 766ms/step - accuracy: 0.8325 - auc: 0.8596 - loss: 0.4077 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3810\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8171 - auc: 0.7254 - loss: 0.4300 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3806\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783ms/step - accuracy: 0.8171 - auc: 0.7824 - loss: 0.4266 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3804\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 769ms/step - accuracy: 0.8227 - auc: 0.7392 - loss: 0.4261 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3803\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 871ms/step - accuracy: 0.7954 - auc: 0.8240 - loss: 0.4276 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3794\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 826ms/step - accuracy: 0.8171 - auc: 0.8046 - loss: 0.4259 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8171 - auc: 0.7596 - loss: 0.4344 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3784\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 761ms/step - accuracy: 0.8171 - auc: 0.7749 - loss: 0.4243 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3782\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 838ms/step - accuracy: 0.8171 - auc: 0.8216 - loss: 0.4211 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 832ms/step - accuracy: 0.8171 - auc: 0.7827 - loss: 0.4213 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 894ms/step - accuracy: 0.7829 - auc: 0.7838 - loss: 0.4360 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 814ms/step - accuracy: 0.8171 - auc: 0.8349 - loss: 0.4169 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3785\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 924ms/step - accuracy: 0.8171 - auc: 0.8326 - loss: 0.4178 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3786\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 841ms/step - accuracy: 0.8171 - auc: 0.7934 - loss: 0.4272 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3793\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 919ms/step - accuracy: 0.8171 - auc: 0.7713 - loss: 0.4260 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3810\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 936ms/step - accuracy: 0.8171 - auc: 0.6808 - loss: 0.4391 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3822\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830ms/step - accuracy: 0.8171 - auc: 0.7779 - loss: 0.4261 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3827\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.8171 - auc: 0.7025 - loss: 0.4297 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3813\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 740ms/step - accuracy: 0.8171 - auc: 0.7731 - loss: 0.4256 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3804\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 798ms/step - accuracy: 0.8171 - auc: 0.8395 - loss: 0.4175 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3795\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882ms/step - accuracy: 0.8171 - auc: 0.7504 - loss: 0.4306 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3799\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 712ms/step - accuracy: 0.8171 - auc: 0.8353 - loss: 0.4205 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3801\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 704ms/step - accuracy: 0.8171 - auc: 0.7652 - loss: 0.4230 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3804\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 803ms/step - accuracy: 0.8171 - auc: 0.8050 - loss: 0.4127 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3801\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 794ms/step - accuracy: 0.8171 - auc: 0.8154 - loss: 0.4179 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3796\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 743ms/step - accuracy: 0.8171 - auc: 0.8392 - loss: 0.4187 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3791\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.8171 - auc: 0.7742 - loss: 0.4191 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3790\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865ms/step - accuracy: 0.8171 - auc: 0.7940 - loss: 0.4257 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3794\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864ms/step - accuracy: 0.8171 - auc: 0.7671 - loss: 0.4221 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3798\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 776ms/step - accuracy: 0.8171 - auc: 0.7639 - loss: 0.4269 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3804\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 787ms/step - accuracy: 0.8171 - auc: 0.8156 - loss: 0.4197 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3805\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 863ms/step - accuracy: 0.8171 - auc: 0.7224 - loss: 0.4339 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3807\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 780ms/step - accuracy: 0.8171 - auc: 0.6696 - loss: 0.4339 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3813\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 756ms/step - accuracy: 0.8171 - auc: 0.8064 - loss: 0.4203 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3817\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 759ms/step - accuracy: 0.8171 - auc: 0.7602 - loss: 0.4302 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3814\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 775ms/step - accuracy: 0.8171 - auc: 0.8568 - loss: 0.4167 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3812\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 753ms/step - accuracy: 0.8171 - auc: 0.7285 - loss: 0.4310 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3806\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 733ms/step - accuracy: 0.8171 - auc: 0.6991 - loss: 0.4427 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3802\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765ms/step - accuracy: 0.8171 - auc: 0.7917 - loss: 0.4210 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3800\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 861ms/step - accuracy: 0.8171 - auc: 0.7621 - loss: 0.4284 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3794\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 837ms/step - accuracy: 0.8171 - auc: 0.8669 - loss: 0.4111 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3789\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 757ms/step - accuracy: 0.8171 - auc: 0.6786 - loss: 0.4345 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3787\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864ms/step - accuracy: 0.8171 - auc: 0.7937 - loss: 0.4183 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3788\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 752ms/step - accuracy: 0.8171 - auc: 0.7319 - loss: 0.4292 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3792\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 837ms/step - accuracy: 0.8171 - auc: 0.7598 - loss: 0.4279 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3798\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 846ms/step - accuracy: 0.8171 - auc: 0.7051 - loss: 0.4319 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [1:12:59, 1466.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 1s/step - accuracy: 0.4786 - auc: 0.4708 - loss: 0.7127 - val_accuracy: 0.5000 - val_auc: 0.6667 - val_loss: 0.6934\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 856ms/step - accuracy: 0.3773 - auc: 0.3086 - loss: 0.7332 - val_accuracy: 0.5000 - val_auc: 0.4667 - val_loss: 0.6934\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 768ms/step - accuracy: 0.5580 - auc: 0.5686 - loss: 0.6847 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6931\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.5047 - auc: 0.4844 - loss: 0.6968 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6921\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865ms/step - accuracy: 0.4947 - auc: 0.4748 - loss: 0.6992 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6919\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 868ms/step - accuracy: 0.5820 - auc: 0.5534 - loss: 0.6909 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6907\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.5016 - auc: 0.5321 - loss: 0.7056 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6891\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 882ms/step - accuracy: 0.4671 - auc: 0.4437 - loss: 0.7060 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6869\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 889ms/step - accuracy: 0.7243 - auc: 0.7129 - loss: 0.6671 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6875\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.5947 - auc: 0.4546 - loss: 0.7070 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6852\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 927ms/step - accuracy: 0.5792 - auc: 0.6303 - loss: 0.6813 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6816\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 821ms/step - accuracy: 0.4717 - auc: 0.5159 - loss: 0.6984 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6774\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 968ms/step - accuracy: 0.4889 - auc: 0.5007 - loss: 0.7008 - val_accuracy: 0.5000 - val_auc: 0.6333 - val_loss: 0.6760\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 879ms/step - accuracy: 0.5343 - auc: 0.6577 - loss: 0.6695 - val_accuracy: 0.6333 - val_auc: 0.6333 - val_loss: 0.6691\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 794ms/step - accuracy: 0.5935 - auc: 0.6049 - loss: 0.6803 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6632\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.6210 - auc: 0.7123 - loss: 0.6601 - val_accuracy: 0.6333 - val_auc: 0.7333 - val_loss: 0.6570\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.6436 - auc: 0.6982 - loss: 0.6609 - val_accuracy: 0.6333 - val_auc: 0.8333 - val_loss: 0.6463\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 768ms/step - accuracy: 0.6176 - auc: 0.6657 - loss: 0.6629 - val_accuracy: 0.5000 - val_auc: 0.8111 - val_loss: 0.6722\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.6741 - auc: 0.6923 - loss: 0.6512 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.6171\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.6885 - auc: 0.7336 - loss: 0.6218 - val_accuracy: 0.7667 - val_auc: 0.8333 - val_loss: 0.5736\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 834ms/step - accuracy: 0.7253 - auc: 0.7090 - loss: 0.5922 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.5152\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.7807 - auc: 0.7828 - loss: 0.5228 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4544\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.7993 - auc: 0.8445 - loss: 0.4986 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4313\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 876ms/step - accuracy: 0.7864 - auc: 0.7793 - loss: 0.5004 - val_accuracy: 0.6333 - val_auc: 0.7667 - val_loss: 0.6280\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.7956 - auc: 0.8225 - loss: 0.4761 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4244\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.7674 - auc: 0.7717 - loss: 0.4934 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4267\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.7712 - auc: 0.7459 - loss: 0.5082 - val_accuracy: 0.7667 - val_auc: 0.8111 - val_loss: 0.4274\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 916ms/step - accuracy: 0.8119 - auc: 0.8637 - loss: 0.4314 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4008\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 926ms/step - accuracy: 0.8038 - auc: 0.7563 - loss: 0.4610 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3974\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 796ms/step - accuracy: 0.8038 - auc: 0.8100 - loss: 0.4310 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4058\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 858ms/step - accuracy: 0.7981 - auc: 0.8001 - loss: 0.4269 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3873\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 804ms/step - accuracy: 0.8038 - auc: 0.8589 - loss: 0.4141 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3824\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 924ms/step - accuracy: 0.8038 - auc: 0.7546 - loss: 0.4621 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3846\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.8267 - auc: 0.8140 - loss: 0.4229 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3899\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.8038 - auc: 0.7749 - loss: 0.4398 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3846\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.8038 - auc: 0.6945 - loss: 0.4525 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3816\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.8038 - auc: 0.7766 - loss: 0.4312 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3808\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 897ms/step - accuracy: 0.8038 - auc: 0.8090 - loss: 0.4244 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3793\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 875ms/step - accuracy: 0.7956 - auc: 0.7781 - loss: 0.4401 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3944\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 916ms/step - accuracy: 0.7740 - auc: 0.7760 - loss: 0.4775 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4906\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 797ms/step - accuracy: 0.7217 - auc: 0.7701 - loss: 0.4924 - val_accuracy: 0.7333 - val_auc: 0.8333 - val_loss: 0.4736\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883ms/step - accuracy: 0.7739 - auc: 0.8716 - loss: 0.4508 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4029\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 809ms/step - accuracy: 0.7807 - auc: 0.7207 - loss: 0.4769 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.4033\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.8038 - auc: 0.8394 - loss: 0.4252 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3849\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.7821 - auc: 0.8682 - loss: 0.4235 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3809\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.8038 - auc: 0.8592 - loss: 0.4022 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3787\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.8119 - auc: 0.7813 - loss: 0.4239 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3823\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 932ms/step - accuracy: 0.7696 - auc: 0.8315 - loss: 0.4278 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3857\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 906ms/step - accuracy: 0.8038 - auc: 0.8388 - loss: 0.4087 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3865\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 819ms/step - accuracy: 0.7821 - auc: 0.8058 - loss: 0.4308 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3809\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.7899 - auc: 0.7814 - loss: 0.4395 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3781\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 780ms/step - accuracy: 0.8038 - auc: 0.8268 - loss: 0.4208 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3778\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 897ms/step - accuracy: 0.7981 - auc: 0.8182 - loss: 0.4158 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3788\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 814ms/step - accuracy: 0.7956 - auc: 0.7676 - loss: 0.4377 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3785\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 919ms/step - accuracy: 0.8038 - auc: 0.8935 - loss: 0.4031 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3772\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 922ms/step - accuracy: 0.8038 - auc: 0.7835 - loss: 0.4246 - val_accuracy: 0.8333 - val_auc: 0.8333 - val_loss: 0.3767\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.8038 - auc: 0.7895 - loss: 0.4223 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3771\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 816ms/step - accuracy: 0.8038 - auc: 0.8036 - loss: 0.4187 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3794\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 832ms/step - accuracy: 0.8038 - auc: 0.7859 - loss: 0.4323 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3758\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.8038 - auc: 0.8126 - loss: 0.4149 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3756\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 967ms/step - accuracy: 0.8038 - auc: 0.8055 - loss: 0.4130 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3767\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.8038 - auc: 0.8248 - loss: 0.4176 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3767\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 825ms/step - accuracy: 0.8119 - auc: 0.7852 - loss: 0.4278 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3764\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 905ms/step - accuracy: 0.8038 - auc: 0.8057 - loss: 0.4215 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3758\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 877ms/step - accuracy: 0.8038 - auc: 0.8252 - loss: 0.4179 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3760\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 861ms/step - accuracy: 0.8038 - auc: 0.8124 - loss: 0.4113 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3753\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 772ms/step - accuracy: 0.8038 - auc: 0.8131 - loss: 0.4161 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3745\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 864ms/step - accuracy: 0.8038 - auc: 0.7658 - loss: 0.4342 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3761\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 772ms/step - accuracy: 0.8038 - auc: 0.8384 - loss: 0.4090 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3772\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 875ms/step - accuracy: 0.8038 - auc: 0.8203 - loss: 0.4114 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3765\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 895ms/step - accuracy: 0.8073 - auc: 0.7689 - loss: 0.4238 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3767\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 788ms/step - accuracy: 0.7764 - auc: 0.7574 - loss: 0.4426 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3764\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913ms/step - accuracy: 0.8038 - auc: 0.8146 - loss: 0.4182 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3779\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 777ms/step - accuracy: 0.8192 - auc: 0.8844 - loss: 0.3938 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3769\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 783ms/step - accuracy: 0.8038 - auc: 0.7635 - loss: 0.4296 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3758\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 869ms/step - accuracy: 0.8038 - auc: 0.8721 - loss: 0.3990 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3746\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 830ms/step - accuracy: 0.8119 - auc: 0.7849 - loss: 0.4184 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3737\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 917ms/step - accuracy: 0.8038 - auc: 0.8116 - loss: 0.4223 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3745\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 862ms/step - accuracy: 0.8038 - auc: 0.8230 - loss: 0.4130 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3746\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 805ms/step - accuracy: 0.8038 - auc: 0.7969 - loss: 0.4228 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3746\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 800ms/step - accuracy: 0.8038 - auc: 0.8180 - loss: 0.4107 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3742\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 954ms/step - accuracy: 0.8038 - auc: 0.8182 - loss: 0.4133 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3739\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 881ms/step - accuracy: 0.8038 - auc: 0.8140 - loss: 0.4138 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3754\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.8038 - auc: 0.8018 - loss: 0.4143 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3770\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 923ms/step - accuracy: 0.8038 - auc: 0.7929 - loss: 0.4154 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3770\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 808ms/step - accuracy: 0.8038 - auc: 0.7937 - loss: 0.4159 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3732\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.8038 - auc: 0.8025 - loss: 0.4118 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3763\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 825ms/step - accuracy: 0.8038 - auc: 0.8934 - loss: 0.3995 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3751\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 798ms/step - accuracy: 0.8038 - auc: 0.8133 - loss: 0.4218 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3684\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 913ms/step - accuracy: 0.8038 - auc: 0.7908 - loss: 0.4192 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3693\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875ms/step - accuracy: 0.7981 - auc: 0.7511 - loss: 0.4357 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3737\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 812ms/step - accuracy: 0.7945 - auc: 0.8032 - loss: 0.4317 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3769\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 815ms/step - accuracy: 0.8038 - auc: 0.8286 - loss: 0.4085 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3688\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 934ms/step - accuracy: 0.7899 - auc: 0.7775 - loss: 0.4376 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3671\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 800ms/step - accuracy: 0.7603 - auc: 0.8367 - loss: 0.4297 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3869\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 781ms/step - accuracy: 0.8038 - auc: 0.7981 - loss: 0.4174 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3734\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 797ms/step - accuracy: 0.8038 - auc: 0.7938 - loss: 0.4167 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3712\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 818ms/step - accuracy: 0.7883 - auc: 0.7674 - loss: 0.4279 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3713\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 801ms/step - accuracy: 0.8038 - auc: 0.7926 - loss: 0.4169 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3724\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 792ms/step - accuracy: 0.8379 - auc: 0.8385 - loss: 0.3949 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3707\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894ms/step - accuracy: 0.8038 - auc: 0.8639 - loss: 0.3979 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3681\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 928ms/step - accuracy: 0.8038 - auc: 0.7592 - loss: 0.4223 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3663\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 806ms/step - accuracy: 0.8038 - auc: 0.7867 - loss: 0.4143 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3653\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 815ms/step - accuracy: 0.7696 - auc: 0.7751 - loss: 0.4325 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3640\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 831ms/step - accuracy: 0.8038 - auc: 0.7420 - loss: 0.4297 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3648\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 798ms/step - accuracy: 0.8038 - auc: 0.8822 - loss: 0.3986 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3642\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 885ms/step - accuracy: 0.8038 - auc: 0.8058 - loss: 0.4181 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3647\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 905ms/step - accuracy: 0.8038 - auc: 0.8278 - loss: 0.4092 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3638\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 824ms/step - accuracy: 0.8038 - auc: 0.7847 - loss: 0.4123 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3630\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 824ms/step - accuracy: 0.8038 - auc: 0.7969 - loss: 0.4123 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3627\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 821ms/step - accuracy: 0.8038 - auc: 0.7769 - loss: 0.4224 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3624\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 784ms/step - accuracy: 0.8038 - auc: 0.8512 - loss: 0.4101 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3609\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 780ms/step - accuracy: 0.8038 - auc: 0.8150 - loss: 0.4071 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3606\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.8038 - auc: 0.7880 - loss: 0.4185 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3600\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 771ms/step - accuracy: 0.8038 - auc: 0.7869 - loss: 0.4125 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3619\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.8038 - auc: 0.7763 - loss: 0.4164 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3641\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.8038 - auc: 0.8191 - loss: 0.4016 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3626\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 887ms/step - accuracy: 0.8038 - auc: 0.7485 - loss: 0.4449 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3621\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 808ms/step - accuracy: 0.7981 - auc: 0.8079 - loss: 0.4135 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3622\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 921ms/step - accuracy: 0.8038 - auc: 0.7829 - loss: 0.4193 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3621\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893ms/step - accuracy: 0.8038 - auc: 0.7870 - loss: 0.4141 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3626\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.8038 - auc: 0.8571 - loss: 0.3984 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3631\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 948ms/step - accuracy: 0.8038 - auc: 0.8320 - loss: 0.4022 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3617\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 991ms/step - accuracy: 0.8038 - auc: 0.8927 - loss: 0.3953 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3607\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 880ms/step - accuracy: 0.8038 - auc: 0.8249 - loss: 0.4095 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3618\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 863ms/step - accuracy: 0.8038 - auc: 0.7840 - loss: 0.4211 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3646\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 940ms/step - accuracy: 0.8038 - auc: 0.8342 - loss: 0.4055 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3661\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 832ms/step - accuracy: 0.8038 - auc: 0.7083 - loss: 0.4438 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3649\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.7956 - auc: 0.8727 - loss: 0.4027 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3621\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 949ms/step - accuracy: 0.8038 - auc: 0.8418 - loss: 0.4030 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3630\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.7956 - auc: 0.7924 - loss: 0.4155 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3626\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 899ms/step - accuracy: 0.8038 - auc: 0.7995 - loss: 0.4153 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3610\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 871ms/step - accuracy: 0.8038 - auc: 0.7731 - loss: 0.4264 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3607\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 929ms/step - accuracy: 0.7956 - auc: 0.7670 - loss: 0.4297 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3637\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 812ms/step - accuracy: 0.8038 - auc: 0.8210 - loss: 0.4142 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3707\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 899ms/step - accuracy: 0.8038 - auc: 0.8206 - loss: 0.4259 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3657\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 830ms/step - accuracy: 0.8038 - auc: 0.8925 - loss: 0.3967 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3627\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 778ms/step - accuracy: 0.8038 - auc: 0.8704 - loss: 0.3959 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3608\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 775ms/step - accuracy: 0.8038 - auc: 0.8293 - loss: 0.4105 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3594\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875ms/step - accuracy: 0.8038 - auc: 0.8027 - loss: 0.4161 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3594\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 835ms/step - accuracy: 0.8038 - auc: 0.8039 - loss: 0.4097 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3599\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 896ms/step - accuracy: 0.8038 - auc: 0.7820 - loss: 0.4174 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3603\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8038 - auc: 0.8025 - loss: 0.4115 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3592\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 942ms/step - accuracy: 0.8038 - auc: 0.7841 - loss: 0.4136 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3589\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 828ms/step - accuracy: 0.8038 - auc: 0.8448 - loss: 0.4018 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3586\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 989ms/step - accuracy: 0.8038 - auc: 0.7884 - loss: 0.4133 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3581\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.8038 - auc: 0.8188 - loss: 0.4115 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3583\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 811ms/step - accuracy: 0.8038 - auc: 0.8033 - loss: 0.4126 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3583\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 917ms/step - accuracy: 0.8038 - auc: 0.7752 - loss: 0.4186 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3584\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 785ms/step - accuracy: 0.8038 - auc: 0.8610 - loss: 0.3981 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3625\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 854ms/step - accuracy: 0.8038 - auc: 0.7970 - loss: 0.4110 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3646\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900ms/step - accuracy: 0.8038 - auc: 0.8309 - loss: 0.4124 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3609\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 915ms/step - accuracy: 0.8038 - auc: 0.7992 - loss: 0.4160 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3597\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.8038 - auc: 0.8135 - loss: 0.4103 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3596\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 888ms/step - accuracy: 0.8038 - auc: 0.7929 - loss: 0.4141 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3590\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 851ms/step - accuracy: 0.8038 - auc: 0.8515 - loss: 0.3999 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3577\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 829ms/step - accuracy: 0.8038 - auc: 0.8475 - loss: 0.4030 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3570\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 929ms/step - accuracy: 0.8038 - auc: 0.7918 - loss: 0.4181 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3593\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.8038 - auc: 0.7044 - loss: 0.4352 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3617\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 911ms/step - accuracy: 0.8038 - auc: 0.7984 - loss: 0.4127 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3611\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 833ms/step - accuracy: 0.8038 - auc: 0.7618 - loss: 0.4170 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3616\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 811ms/step - accuracy: 0.8038 - auc: 0.8103 - loss: 0.4132 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3608\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 865ms/step - accuracy: 0.8038 - auc: 0.7579 - loss: 0.4152 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3589\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8038 - auc: 0.8298 - loss: 0.4070 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3587\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 781ms/step - accuracy: 0.8038 - auc: 0.7838 - loss: 0.4091 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3585\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 831ms/step - accuracy: 0.8038 - auc: 0.8329 - loss: 0.4005 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3585\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 782ms/step - accuracy: 0.8038 - auc: 0.8293 - loss: 0.4043 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3583\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.8038 - auc: 0.8356 - loss: 0.4062 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3581\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 783ms/step - accuracy: 0.8038 - auc: 0.9112 - loss: 0.3817 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3585\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 817ms/step - accuracy: 0.8038 - auc: 0.8073 - loss: 0.4084 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3596\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 975ms/step - accuracy: 0.8038 - auc: 0.7887 - loss: 0.4083 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3591\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 853ms/step - accuracy: 0.8192 - auc: 0.7933 - loss: 0.4060 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3577\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882ms/step - accuracy: 0.8038 - auc: 0.7989 - loss: 0.4192 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3582\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 891ms/step - accuracy: 0.8038 - auc: 0.8709 - loss: 0.4007 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3624\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 889ms/step - accuracy: 0.8038 - auc: 0.8073 - loss: 0.4152 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3606\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 932ms/step - accuracy: 0.8038 - auc: 0.8333 - loss: 0.4082 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3580\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 938ms/step - accuracy: 0.8038 - auc: 0.7500 - loss: 0.4280 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3568\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 885ms/step - accuracy: 0.8038 - auc: 0.8518 - loss: 0.3982 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3564\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.8038 - auc: 0.7923 - loss: 0.4172 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3568\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 841ms/step - accuracy: 0.8038 - auc: 0.8706 - loss: 0.3974 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3575\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 812ms/step - accuracy: 0.8038 - auc: 0.8743 - loss: 0.3939 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3585\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.8038 - auc: 0.8569 - loss: 0.4029 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3580\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 917ms/step - accuracy: 0.8038 - auc: 0.7579 - loss: 0.4177 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3570\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 878ms/step - accuracy: 0.8038 - auc: 0.7602 - loss: 0.4181 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3569\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 771ms/step - accuracy: 0.8038 - auc: 0.8200 - loss: 0.4095 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3565\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 772ms/step - accuracy: 0.8038 - auc: 0.7393 - loss: 0.4215 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3567\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 891ms/step - accuracy: 0.8038 - auc: 0.8004 - loss: 0.4132 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3569\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 988ms/step - accuracy: 0.8038 - auc: 0.7942 - loss: 0.4153 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3573\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 897ms/step - accuracy: 0.8038 - auc: 0.8312 - loss: 0.4039 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3572\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 959ms/step - accuracy: 0.7883 - auc: 0.8683 - loss: 0.3952 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3568\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 924ms/step - accuracy: 0.8038 - auc: 0.8022 - loss: 0.4209 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3570\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 810ms/step - accuracy: 0.8038 - auc: 0.8310 - loss: 0.4062 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3569\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 858ms/step - accuracy: 0.8038 - auc: 0.8302 - loss: 0.4057 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3563\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 794ms/step - accuracy: 0.8038 - auc: 0.8262 - loss: 0.4053 - val_accuracy: 0.8333 - val_auc: 0.8111 - val_loss: 0.3559\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 938ms/step - accuracy: 0.8038 - auc: 0.8670 - loss: 0.4050 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3556\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 938ms/step - accuracy: 0.8038 - auc: 0.7559 - loss: 0.4174 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3558\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 924ms/step - accuracy: 0.8038 - auc: 0.7551 - loss: 0.4178 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3566\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 911ms/step - accuracy: 0.8038 - auc: 0.8228 - loss: 0.4062 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3581\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 897ms/step - accuracy: 0.8038 - auc: 0.8337 - loss: 0.4081 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3597\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 919ms/step - accuracy: 0.8038 - auc: 0.8518 - loss: 0.3998 - val_accuracy: 0.8333 - val_auc: 0.8556 - val_loss: 0.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [1:38:20, 1488.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 1s/step - accuracy: 0.5694 - auc: 0.4602 - loss: 0.6978 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 2/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 828ms/step - accuracy: 0.5559 - auc: 0.5545 - loss: 0.6794 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 3/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 882ms/step - accuracy: 0.6277 - auc: 0.5070 - loss: 0.6928 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 4/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 972ms/step - accuracy: 0.4232 - auc: 0.5624 - loss: 0.6926 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 5/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 816ms/step - accuracy: 0.5095 - auc: 0.5206 - loss: 0.6953 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 6/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 824ms/step - accuracy: 0.5300 - auc: 0.4833 - loss: 0.6942 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 7/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 824ms/step - accuracy: 0.5860 - auc: 0.5896 - loss: 0.6885 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 8/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 950ms/step - accuracy: 0.5701 - auc: 0.5504 - loss: 0.6916 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 9/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882ms/step - accuracy: 0.6481 - auc: 0.6567 - loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6931\n",
      "Epoch 10/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 792ms/step - accuracy: 0.5333 - auc: 0.4896 - loss: 0.6955 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 11/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.5529 - auc: 0.5665 - loss: 0.6919 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6931\n",
      "Epoch 12/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 846ms/step - accuracy: 0.5390 - auc: 0.5049 - loss: 0.6930 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 13/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 774ms/step - accuracy: 0.5927 - auc: 0.6138 - loss: 0.6921 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 14/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 871ms/step - accuracy: 0.4494 - auc: 0.4219 - loss: 0.6922 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6930\n",
      "Epoch 15/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 790ms/step - accuracy: 0.5532 - auc: 0.3996 - loss: 0.6932 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.6930\n",
      "Epoch 16/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 993ms/step - accuracy: 0.3713 - auc: 0.4726 - loss: 0.6879 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 17/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 918ms/step - accuracy: 0.4735 - auc: 0.5080 - loss: 0.6899 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 18/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 859ms/step - accuracy: 0.5179 - auc: 0.4983 - loss: 0.6994 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 19/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.4941 - auc: 0.4603 - loss: 0.6950 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 20/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 943ms/step - accuracy: 0.5155 - auc: 0.4859 - loss: 0.7001 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 21/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 849ms/step - accuracy: 0.5622 - auc: 0.4881 - loss: 0.6912 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6930\n",
      "Epoch 22/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 889ms/step - accuracy: 0.4342 - auc: 0.4134 - loss: 0.7026 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6929\n",
      "Epoch 23/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 901ms/step - accuracy: 0.5636 - auc: 0.5258 - loss: 0.6929 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6929\n",
      "Epoch 24/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 820ms/step - accuracy: 0.5321 - auc: 0.5226 - loss: 0.6985 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 25/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 884ms/step - accuracy: 0.4331 - auc: 0.5182 - loss: 0.6934 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 26/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 887ms/step - accuracy: 0.4628 - auc: 0.3543 - loss: 0.6959 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 27/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 815ms/step - accuracy: 0.6318 - auc: 0.5733 - loss: 0.6921 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 28/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 850ms/step - accuracy: 0.4212 - auc: 0.4153 - loss: 0.6969 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 29/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 909ms/step - accuracy: 0.4954 - auc: 0.4549 - loss: 0.6984 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 30/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 855ms/step - accuracy: 0.6827 - auc: 0.6202 - loss: 0.6899 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6928\n",
      "Epoch 31/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 884ms/step - accuracy: 0.5028 - auc: 0.4449 - loss: 0.6943 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6927\n",
      "Epoch 32/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 940ms/step - accuracy: 0.5584 - auc: 0.3887 - loss: 0.6962 - val_accuracy: 0.5000 - val_auc: 0.5000 - val_loss: 0.6927\n",
      "Epoch 33/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 930ms/step - accuracy: 0.5238 - auc: 0.5550 - loss: 0.6922 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6927\n",
      "Epoch 34/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 882ms/step - accuracy: 0.6214 - auc: 0.5451 - loss: 0.6910 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6927\n",
      "Epoch 35/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 923ms/step - accuracy: 0.4839 - auc: 0.4771 - loss: 0.6930 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6927\n",
      "Epoch 36/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 904ms/step - accuracy: 0.5016 - auc: 0.4938 - loss: 0.6940 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6927\n",
      "Epoch 37/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 822ms/step - accuracy: 0.5243 - auc: 0.6091 - loss: 0.6920 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6926\n",
      "Epoch 38/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 914ms/step - accuracy: 0.5824 - auc: 0.5231 - loss: 0.6923 - val_accuracy: 0.6000 - val_auc: 0.5000 - val_loss: 0.6925\n",
      "Epoch 39/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.6806 - auc: 0.5757 - loss: 0.6905 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6923\n",
      "Epoch 40/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.4992 - auc: 0.4769 - loss: 0.6933 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6923\n",
      "Epoch 41/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 801ms/step - accuracy: 0.5836 - auc: 0.5045 - loss: 0.6925 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6922\n",
      "Epoch 42/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 795ms/step - accuracy: 0.6467 - auc: 0.6003 - loss: 0.6903 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6922\n",
      "Epoch 43/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 935ms/step - accuracy: 0.5929 - auc: 0.5320 - loss: 0.6929 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6921\n",
      "Epoch 44/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.4480 - auc: 0.5247 - loss: 0.6931 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6920\n",
      "Epoch 45/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 921ms/step - accuracy: 0.5601 - auc: 0.6505 - loss: 0.6905 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6918\n",
      "Epoch 46/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 831ms/step - accuracy: 0.5621 - auc: 0.6448 - loss: 0.6900 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6914\n",
      "Epoch 47/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 962ms/step - accuracy: 0.5046 - auc: 0.5196 - loss: 0.6927 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6912\n",
      "Epoch 48/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 839ms/step - accuracy: 0.5146 - auc: 0.5874 - loss: 0.6905 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6908\n",
      "Epoch 49/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 956ms/step - accuracy: 0.6393 - auc: 0.5744 - loss: 0.6908 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6906\n",
      "Epoch 50/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 906ms/step - accuracy: 0.4902 - auc: 0.5076 - loss: 0.6934 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6905\n",
      "Epoch 51/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step - accuracy: 0.5212 - auc: 0.4854 - loss: 0.6929 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6901\n",
      "Epoch 52/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 808ms/step - accuracy: 0.6100 - auc: 0.6492 - loss: 0.6876 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6897\n",
      "Epoch 53/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 846ms/step - accuracy: 0.5793 - auc: 0.5323 - loss: 0.6914 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6894\n",
      "Epoch 54/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 1s/step - accuracy: 0.6136 - auc: 0.5945 - loss: 0.6877 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6890\n",
      "Epoch 55/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 847ms/step - accuracy: 0.6511 - auc: 0.6994 - loss: 0.6828 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6885\n",
      "Epoch 56/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 901ms/step - accuracy: 0.5978 - auc: 0.6073 - loss: 0.6883 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6880\n",
      "Epoch 57/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 957ms/step - accuracy: 0.6304 - auc: 0.6671 - loss: 0.6831 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6868\n",
      "Epoch 58/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 821ms/step - accuracy: 0.5934 - auc: 0.5794 - loss: 0.6856 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6838\n",
      "Epoch 59/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 853ms/step - accuracy: 0.6560 - auc: 0.7233 - loss: 0.6695 - val_accuracy: 0.6000 - val_auc: 0.6000 - val_loss: 0.6783\n",
      "Epoch 60/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 888ms/step - accuracy: 0.6157 - auc: 0.6698 - loss: 0.6706 - val_accuracy: 0.6000 - val_auc: 0.7000 - val_loss: 0.6682\n",
      "Epoch 61/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 869ms/step - accuracy: 0.6380 - auc: 0.6760 - loss: 0.6625 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.6382\n",
      "Epoch 62/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 926ms/step - accuracy: 0.6765 - auc: 0.7859 - loss: 0.6315 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.7595\n",
      "Epoch 63/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.4654 - auc: 0.3526 - loss: 0.8115 - val_accuracy: 0.5000 - val_auc: 0.6000 - val_loss: 0.7250\n",
      "Epoch 64/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 810ms/step - accuracy: 0.4186 - auc: 0.4501 - loss: 0.7426 - val_accuracy: 0.5000 - val_auc: 0.7000 - val_loss: 0.6916\n",
      "Epoch 65/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 794ms/step - accuracy: 0.5289 - auc: 0.4709 - loss: 0.6972 - val_accuracy: 0.5000 - val_auc: 0.7000 - val_loss: 0.6883\n",
      "Epoch 66/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 897ms/step - accuracy: 0.5854 - auc: 0.6224 - loss: 0.6773 - val_accuracy: 0.7000 - val_auc: 0.7000 - val_loss: 0.6760\n",
      "Epoch 67/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882ms/step - accuracy: 0.6600 - auc: 0.6405 - loss: 0.6717 - val_accuracy: 0.5000 - val_auc: 0.8000 - val_loss: 0.6750\n",
      "Epoch 68/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 813ms/step - accuracy: 0.6048 - auc: 0.6530 - loss: 0.6723 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6602\n",
      "Epoch 69/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.7213 - auc: 0.7067 - loss: 0.6637 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6403\n",
      "Epoch 70/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 938ms/step - accuracy: 0.7481 - auc: 0.7790 - loss: 0.6358 - val_accuracy: 0.7333 - val_auc: 0.7467 - val_loss: 0.6175\n",
      "Epoch 71/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883ms/step - accuracy: 0.7085 - auc: 0.7425 - loss: 0.6269 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.6144\n",
      "Epoch 72/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 855ms/step - accuracy: 0.8019 - auc: 0.7691 - loss: 0.5809 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.5684\n",
      "Epoch 73/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 848ms/step - accuracy: 0.8600 - auc: 0.9119 - loss: 0.5134 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.5229\n",
      "Epoch 74/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 919ms/step - accuracy: 0.8600 - auc: 0.8440 - loss: 0.4818 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.5522\n",
      "Epoch 75/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 773ms/step - accuracy: 0.8258 - auc: 0.7665 - loss: 0.4992 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.5521\n",
      "Epoch 76/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 879ms/step - accuracy: 0.8258 - auc: 0.8198 - loss: 0.4800 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5471\n",
      "Epoch 77/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 758ms/step - accuracy: 0.7946 - auc: 0.7880 - loss: 0.4874 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5349\n",
      "Epoch 78/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 881ms/step - accuracy: 0.8867 - auc: 0.8556 - loss: 0.4135 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4452\n",
      "Epoch 79/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 892ms/step - accuracy: 0.8600 - auc: 0.8006 - loss: 0.4037 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4356\n",
      "Epoch 80/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 849ms/step - accuracy: 0.8331 - auc: 0.8462 - loss: 0.3907 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4311\n",
      "Epoch 81/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 931ms/step - accuracy: 0.8754 - auc: 0.9219 - loss: 0.3323 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4282\n",
      "Epoch 82/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 840ms/step - accuracy: 0.8754 - auc: 0.8678 - loss: 0.3527 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4271\n",
      "Epoch 83/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 885ms/step - accuracy: 0.8600 - auc: 0.8493 - loss: 0.3533 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4287\n",
      "Epoch 84/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 956ms/step - accuracy: 0.8754 - auc: 0.8716 - loss: 0.3363 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4289\n",
      "Epoch 85/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 945ms/step - accuracy: 0.8095 - auc: 0.8234 - loss: 0.4159 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5556\n",
      "Epoch 86/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 872ms/step - accuracy: 0.7901 - auc: 0.7809 - loss: 0.4517 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5432\n",
      "Epoch 87/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 838ms/step - accuracy: 0.7808 - auc: 0.8182 - loss: 0.4526 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5334\n",
      "Epoch 88/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 936ms/step - accuracy: 0.7783 - auc: 0.8495 - loss: 0.4460 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5281\n",
      "Epoch 89/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.7808 - auc: 0.7571 - loss: 0.4695 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5232\n",
      "Epoch 90/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 842ms/step - accuracy: 0.8019 - auc: 0.7643 - loss: 0.4689 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4916\n",
      "Epoch 91/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 862ms/step - accuracy: 0.8903 - auc: 0.8762 - loss: 0.3979 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4271\n",
      "Epoch 92/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 799ms/step - accuracy: 0.8754 - auc: 0.8443 - loss: 0.3876 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4254\n",
      "Epoch 93/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 903ms/step - accuracy: 0.8629 - auc: 0.8949 - loss: 0.4035 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4220\n",
      "Epoch 94/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 934ms/step - accuracy: 0.8258 - auc: 0.9056 - loss: 0.3613 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4204\n",
      "Epoch 95/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 815ms/step - accuracy: 0.8754 - auc: 0.8779 - loss: 0.3505 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4206\n",
      "Epoch 96/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 890ms/step - accuracy: 0.8413 - auc: 0.8123 - loss: 0.3716 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4208\n",
      "Epoch 97/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 983ms/step - accuracy: 0.8754 - auc: 0.9127 - loss: 0.3164 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4208\n",
      "Epoch 98/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841ms/step - accuracy: 0.8754 - auc: 0.8289 - loss: 0.3615 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4206\n",
      "Epoch 99/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 842ms/step - accuracy: 0.8413 - auc: 0.8737 - loss: 0.4003 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4202\n",
      "Epoch 100/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 948ms/step - accuracy: 0.8754 - auc: 0.8890 - loss: 0.3339 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4202\n",
      "Epoch 101/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 878ms/step - accuracy: 0.8754 - auc: 0.8667 - loss: 0.3491 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4206\n",
      "Epoch 102/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 863ms/step - accuracy: 0.8754 - auc: 0.8370 - loss: 0.3482 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4209\n",
      "Epoch 103/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8537 - auc: 0.8132 - loss: 0.3760 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4205\n",
      "Epoch 104/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 945ms/step - accuracy: 0.8754 - auc: 0.9187 - loss: 0.3230 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4203\n",
      "Epoch 105/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 926ms/step - accuracy: 0.8790 - auc: 0.8810 - loss: 0.3330 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4203\n",
      "Epoch 106/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 942ms/step - accuracy: 0.8754 - auc: 0.8437 - loss: 0.3445 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4203\n",
      "Epoch 107/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 834ms/step - accuracy: 0.8754 - auc: 0.8933 - loss: 0.3303 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4201\n",
      "Epoch 108/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 932ms/step - accuracy: 0.8754 - auc: 0.8945 - loss: 0.3295 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 109/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.8754 - auc: 0.8336 - loss: 0.3501 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 110/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 881ms/step - accuracy: 0.8754 - auc: 0.8747 - loss: 0.3333 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4200\n",
      "Epoch 111/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 804ms/step - accuracy: 0.8754 - auc: 0.9164 - loss: 0.3235 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4203\n",
      "Epoch 112/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 898ms/step - accuracy: 0.8754 - auc: 0.8545 - loss: 0.3434 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4206\n",
      "Epoch 113/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 850ms/step - accuracy: 0.8754 - auc: 0.8171 - loss: 0.3547 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4204\n",
      "Epoch 114/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 925ms/step - accuracy: 0.8754 - auc: 0.8662 - loss: 0.3348 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4201\n",
      "Epoch 115/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 791ms/step - accuracy: 0.8754 - auc: 0.9298 - loss: 0.3196 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4201\n",
      "Epoch 116/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.8754 - auc: 0.9051 - loss: 0.3269 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4203\n",
      "Epoch 117/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 839ms/step - accuracy: 0.8754 - auc: 0.8172 - loss: 0.3578 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4203\n",
      "Epoch 118/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.8754 - auc: 0.8790 - loss: 0.3334 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4206\n",
      "Epoch 119/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 820ms/step - accuracy: 0.8754 - auc: 0.8263 - loss: 0.3464 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4203\n",
      "Epoch 120/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 845ms/step - accuracy: 0.8754 - auc: 0.8612 - loss: 0.3375 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4199\n",
      "Epoch 121/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 897ms/step - accuracy: 0.8719 - auc: 0.8774 - loss: 0.3272 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4198\n",
      "Epoch 122/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.8754 - auc: 0.8196 - loss: 0.3456 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4195\n",
      "Epoch 123/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 875ms/step - accuracy: 0.8754 - auc: 0.8947 - loss: 0.3309 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4194\n",
      "Epoch 124/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 781ms/step - accuracy: 0.8754 - auc: 0.8946 - loss: 0.3329 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4194\n",
      "Epoch 125/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 798ms/step - accuracy: 0.8600 - auc: 0.8591 - loss: 0.3413 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 126/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809ms/step - accuracy: 0.8754 - auc: 0.8966 - loss: 0.3311 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 127/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 911ms/step - accuracy: 0.8754 - auc: 0.8496 - loss: 0.3400 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 128/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 973ms/step - accuracy: 0.8754 - auc: 0.8283 - loss: 0.3458 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 129/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 864ms/step - accuracy: 0.8754 - auc: 0.8834 - loss: 0.3356 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 130/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 819ms/step - accuracy: 0.8754 - auc: 0.8420 - loss: 0.3465 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4191\n",
      "Epoch 131/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 792ms/step - accuracy: 0.8754 - auc: 0.8734 - loss: 0.3326 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 132/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 916ms/step - accuracy: 0.8673 - auc: 0.8460 - loss: 0.3480 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 133/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 826ms/step - accuracy: 0.8754 - auc: 0.8592 - loss: 0.3459 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 134/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 936ms/step - accuracy: 0.8754 - auc: 0.8740 - loss: 0.3409 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 135/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 808ms/step - accuracy: 0.8754 - auc: 0.8457 - loss: 0.3500 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4191\n",
      "Epoch 136/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 880ms/step - accuracy: 0.8537 - auc: 0.8848 - loss: 0.3474 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4192\n",
      "Epoch 137/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 797ms/step - accuracy: 0.8754 - auc: 0.9160 - loss: 0.3295 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 138/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.8754 - auc: 0.8603 - loss: 0.3318 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 139/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 934ms/step - accuracy: 0.8754 - auc: 0.9090 - loss: 0.3267 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4199\n",
      "Epoch 140/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 847ms/step - accuracy: 0.8754 - auc: 0.8917 - loss: 0.3290 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4202\n",
      "Epoch 141/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 910ms/step - accuracy: 0.8754 - auc: 0.8553 - loss: 0.3346 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4201\n",
      "Epoch 142/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 807ms/step - accuracy: 0.8754 - auc: 0.9020 - loss: 0.3288 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4201\n",
      "Epoch 143/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 907ms/step - accuracy: 0.8754 - auc: 0.9100 - loss: 0.3257 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4203\n",
      "Epoch 144/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 909ms/step - accuracy: 0.8754 - auc: 0.8550 - loss: 0.3363 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4204\n",
      "Epoch 145/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 945ms/step - accuracy: 0.8754 - auc: 0.8532 - loss: 0.3473 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4202\n",
      "Epoch 146/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 843ms/step - accuracy: 0.8754 - auc: 0.8270 - loss: 0.3471 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4203\n",
      "Epoch 147/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 951ms/step - accuracy: 0.8754 - auc: 0.8726 - loss: 0.3422 - val_accuracy: 0.7333 - val_auc: 0.7733 - val_loss: 0.4840\n",
      "Epoch 148/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 1s/step - accuracy: 0.8258 - auc: 0.8198 - loss: 0.5632 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5405\n",
      "Epoch 149/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 909ms/step - accuracy: 0.7865 - auc: 0.7593 - loss: 0.4532 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5475\n",
      "Epoch 150/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 851ms/step - accuracy: 0.7368 - auc: 0.6850 - loss: 0.5176 - val_accuracy: 0.7000 - val_auc: 0.7000 - val_loss: 0.5426\n",
      "Epoch 151/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 914ms/step - accuracy: 0.7865 - auc: 0.8036 - loss: 0.4790 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5346\n",
      "Epoch 152/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 921ms/step - accuracy: 0.7523 - auc: 0.7830 - loss: 0.4832 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5306\n",
      "Epoch 153/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 909ms/step - accuracy: 0.7865 - auc: 0.7691 - loss: 0.4603 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5279\n",
      "Epoch 154/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 809ms/step - accuracy: 0.7865 - auc: 0.8110 - loss: 0.4541 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5253\n",
      "Epoch 155/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 872ms/step - accuracy: 0.7865 - auc: 0.7143 - loss: 0.4642 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5220\n",
      "Epoch 156/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 817ms/step - accuracy: 0.7946 - auc: 0.7582 - loss: 0.4638 - val_accuracy: 0.7000 - val_auc: 0.8000 - val_loss: 0.5166\n",
      "Epoch 157/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 802ms/step - accuracy: 0.8028 - auc: 0.8514 - loss: 0.4403 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4866\n",
      "Epoch 158/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 929ms/step - accuracy: 0.8456 - auc: 0.9117 - loss: 0.4091 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4277\n",
      "Epoch 159/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.8600 - auc: 0.9036 - loss: 0.3791 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4256\n",
      "Epoch 160/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 760ms/step - accuracy: 0.8413 - auc: 0.8546 - loss: 0.3811 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4233\n",
      "Epoch 161/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 908ms/step - accuracy: 0.8754 - auc: 0.8569 - loss: 0.3497 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4220\n",
      "Epoch 162/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 827ms/step - accuracy: 0.8754 - auc: 0.8150 - loss: 0.3662 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4214\n",
      "Epoch 163/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 829ms/step - accuracy: 0.8754 - auc: 0.8870 - loss: 0.3411 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4210\n",
      "Epoch 164/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 925ms/step - accuracy: 0.8754 - auc: 0.8374 - loss: 0.3480 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4210\n",
      "Epoch 165/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 800ms/step - accuracy: 0.8754 - auc: 0.8555 - loss: 0.3458 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4210\n",
      "Epoch 166/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 897ms/step - accuracy: 0.8754 - auc: 0.8630 - loss: 0.3397 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4210\n",
      "Epoch 167/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 834ms/step - accuracy: 0.8754 - auc: 0.9202 - loss: 0.3249 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4212\n",
      "Epoch 168/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 955ms/step - accuracy: 0.8754 - auc: 0.8509 - loss: 0.3359 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4212\n",
      "Epoch 169/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 796ms/step - accuracy: 0.8754 - auc: 0.8831 - loss: 0.3321 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4211\n",
      "Epoch 170/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 900ms/step - accuracy: 0.8754 - auc: 0.8405 - loss: 0.3468 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4209\n",
      "Epoch 171/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 837ms/step - accuracy: 0.8754 - auc: 0.9065 - loss: 0.3336 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4202\n",
      "Epoch 172/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 970ms/step - accuracy: 0.8754 - auc: 0.8414 - loss: 0.3477 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4199\n",
      "Epoch 173/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844ms/step - accuracy: 0.8754 - auc: 0.8788 - loss: 0.3317 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4195\n",
      "Epoch 174/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 823ms/step - accuracy: 0.8754 - auc: 0.8975 - loss: 0.3309 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 175/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 898ms/step - accuracy: 0.8754 - auc: 0.9039 - loss: 0.3314 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 176/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 902ms/step - accuracy: 0.8754 - auc: 0.8426 - loss: 0.3394 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 177/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 910ms/step - accuracy: 0.8754 - auc: 0.8540 - loss: 0.3376 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4195\n",
      "Epoch 178/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.8754 - auc: 0.9152 - loss: 0.3245 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 179/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 925ms/step - accuracy: 0.8754 - auc: 0.8440 - loss: 0.3490 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4201\n",
      "Epoch 180/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 807ms/step - accuracy: 0.8754 - auc: 0.8806 - loss: 0.3354 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4208\n",
      "Epoch 181/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 887ms/step - accuracy: 0.8537 - auc: 0.8479 - loss: 0.3589 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4210\n",
      "Epoch 182/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 906ms/step - accuracy: 0.8413 - auc: 0.8723 - loss: 0.4272 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4198\n",
      "Epoch 183/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 821ms/step - accuracy: 0.8754 - auc: 0.9016 - loss: 0.3354 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4198\n",
      "Epoch 184/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 970ms/step - accuracy: 0.8754 - auc: 0.8934 - loss: 0.3290 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4199\n",
      "Epoch 185/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 883ms/step - accuracy: 0.8754 - auc: 0.8541 - loss: 0.3433 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4207\n",
      "Epoch 186/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1s/step - accuracy: 0.8413 - auc: 0.8939 - loss: 0.3617 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4201\n",
      "Epoch 187/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 974ms/step - accuracy: 0.8754 - auc: 0.8985 - loss: 0.3296 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4198\n",
      "Epoch 188/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 928ms/step - accuracy: 0.8673 - auc: 0.9061 - loss: 0.3339 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4196\n",
      "Epoch 189/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 988ms/step - accuracy: 0.8754 - auc: 0.8694 - loss: 0.3431 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 190/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 957ms/step - accuracy: 0.8754 - auc: 0.8892 - loss: 0.3305 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4194\n",
      "Epoch 191/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 951ms/step - accuracy: 0.8754 - auc: 0.8474 - loss: 0.3361 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4197\n",
      "Epoch 192/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 805ms/step - accuracy: 0.8754 - auc: 0.8805 - loss: 0.3434 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4208\n",
      "Epoch 193/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 896ms/step - accuracy: 0.8754 - auc: 0.8734 - loss: 0.3312 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4216\n",
      "Epoch 194/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 831ms/step - accuracy: 0.8754 - auc: 0.8643 - loss: 0.3350 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4210\n",
      "Epoch 195/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 923ms/step - accuracy: 0.8754 - auc: 0.9166 - loss: 0.3168 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4208\n",
      "Epoch 196/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 880ms/step - accuracy: 0.8754 - auc: 0.8603 - loss: 0.3366 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4203\n",
      "Epoch 197/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 812ms/step - accuracy: 0.8754 - auc: 0.8053 - loss: 0.3521 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4195\n",
      "Epoch 198/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 818ms/step - accuracy: 0.8754 - auc: 0.8831 - loss: 0.3250 - val_accuracy: 0.8000 - val_auc: 0.8000 - val_loss: 0.4195\n",
      "Epoch 199/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 899ms/step - accuracy: 0.8754 - auc: 0.8572 - loss: 0.3389 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n",
      "Epoch 200/200\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 827ms/step - accuracy: 0.8754 - auc: 0.8681 - loss: 0.3352 - val_accuracy: 0.8000 - val_auc: 0.7733 - val_loss: 0.4193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [2:03:32, 1482.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 30min 13s, sys: 59min 34s, total: 4h 29min 47s\n",
      "Wall time: 2h 3min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_acc = []\n",
    "all_loss = []\n",
    "all_auc = []\n",
    "\n",
    "all_val_acc = []\n",
    "all_val_loss = []\n",
    "all_val_auc = []\n",
    "\n",
    "for j, seed in tqdm(enumerate(np.arange(NUM_EXPERIMENTS) + INIT_SEED)):\n",
    "    np.random.seed(int(seed))\n",
    "    random.seed(int(seed))\n",
    "    tf.random.set_seed(int(seed))\n",
    "\n",
    "    train_id = np.random.choice(np.unique(np.ravel(data[USER])), 7, replace=False)\n",
    "    train_index = np.isin(data[USER], train_id)\n",
    "\n",
    "    train = data.iloc[train_index]\n",
    "    test = data.iloc[~train_index]\n",
    "\n",
    "    X_train, y_train = reshape_dataset(train)\n",
    "    X_test, y_test = reshape_dataset(test)\n",
    "\n",
    "    y_train = y_train.reshape(-1, 1)\n",
    "    y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "    model = create_model(X_train)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=NUM_EPOCHS,\n",
    "        batch_size=10,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    auc = history.history['auc']\n",
    "\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    val_auc = history.history['val_auc']\n",
    "\n",
    "    all_acc.append(acc)\n",
    "    all_loss.append(loss)\n",
    "    all_auc.append(auc)\n",
    "\n",
    "    all_val_acc.append(val_acc)\n",
    "    all_val_loss.append(val_loss)\n",
    "    all_val_auc.append(val_auc)\n",
    "\n",
    "epoch_acc = np.mean(all_acc, axis=0)\n",
    "epoch_loss = np.mean(all_loss, axis=0)\n",
    "epoch_auc = np.mean(all_auc, axis=0)\n",
    "\n",
    "epoch_val_acc = np.mean(all_val_acc, axis=0)\n",
    "epoch_val_loss = np.mean(all_val_loss, axis=0)\n",
    "epoch_val_auc = np.mean(all_val_auc, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: TRAIN Accuracy = 0.506 Loss = 0.701 AUC = 0.536\n",
      "Epoch 1: VAL Accuracy = 0.5 Loss = 0.696 AUC = 0.607\n",
      "Epoch 2: TRAIN Accuracy = 0.46 Loss = 0.704 AUC = 0.476\n",
      "Epoch 2: VAL Accuracy = 0.487 Loss = 0.692 AUC = 0.547\n",
      "Epoch 3: TRAIN Accuracy = 0.54 Loss = 0.691 AUC = 0.546\n",
      "Epoch 3: VAL Accuracy = 0.5 Loss = 0.693 AUC = 0.553\n",
      "Epoch 4: TRAIN Accuracy = 0.477 Loss = 0.696 AUC = 0.477\n",
      "Epoch 4: VAL Accuracy = 0.513 Loss = 0.693 AUC = 0.573\n",
      "Epoch 5: TRAIN Accuracy = 0.531 Loss = 0.696 AUC = 0.512\n",
      "Epoch 5: VAL Accuracy = 0.52 Loss = 0.691 AUC = 0.573\n",
      "Epoch 6: TRAIN Accuracy = 0.48 Loss = 0.698 AUC = 0.472\n",
      "Epoch 6: VAL Accuracy = 0.52 Loss = 0.691 AUC = 0.593\n",
      "Epoch 7: TRAIN Accuracy = 0.526 Loss = 0.693 AUC = 0.534\n",
      "Epoch 7: VAL Accuracy = 0.52 Loss = 0.69 AUC = 0.573\n",
      "Epoch 8: TRAIN Accuracy = 0.531 Loss = 0.692 AUC = 0.524\n",
      "Epoch 8: VAL Accuracy = 0.52 Loss = 0.69 AUC = 0.573\n",
      "Epoch 9: TRAIN Accuracy = 0.554 Loss = 0.688 AUC = 0.547\n",
      "Epoch 9: VAL Accuracy = 0.52 Loss = 0.689 AUC = 0.593\n",
      "Epoch 10: TRAIN Accuracy = 0.529 Loss = 0.69 AUC = 0.502\n",
      "Epoch 10: VAL Accuracy = 0.547 Loss = 0.687 AUC = 0.573\n",
      "Epoch 11: TRAIN Accuracy = 0.54 Loss = 0.685 AUC = 0.571\n",
      "Epoch 11: VAL Accuracy = 0.52 Loss = 0.686 AUC = 0.573\n",
      "Epoch 12: TRAIN Accuracy = 0.554 Loss = 0.687 AUC = 0.577\n",
      "Epoch 12: VAL Accuracy = 0.52 Loss = 0.683 AUC = 0.593\n",
      "Epoch 13: TRAIN Accuracy = 0.483 Loss = 0.695 AUC = 0.499\n",
      "Epoch 13: VAL Accuracy = 0.547 Loss = 0.682 AUC = 0.64\n",
      "Epoch 14: TRAIN Accuracy = 0.5 Loss = 0.689 AUC = 0.494\n",
      "Epoch 14: VAL Accuracy = 0.573 Loss = 0.678 AUC = 0.64\n",
      "Epoch 15: TRAIN Accuracy = 0.523 Loss = 0.684 AUC = 0.534\n",
      "Epoch 15: VAL Accuracy = 0.573 Loss = 0.676 AUC = 0.653\n",
      "Epoch 16: TRAIN Accuracy = 0.543 Loss = 0.677 AUC = 0.574\n",
      "Epoch 16: VAL Accuracy = 0.547 Loss = 0.673 AUC = 0.633\n",
      "Epoch 17: TRAIN Accuracy = 0.537 Loss = 0.679 AUC = 0.577\n",
      "Epoch 17: VAL Accuracy = 0.587 Loss = 0.669 AUC = 0.653\n",
      "Epoch 18: TRAIN Accuracy = 0.569 Loss = 0.672 AUC = 0.581\n",
      "Epoch 18: VAL Accuracy = 0.54 Loss = 0.667 AUC = 0.676\n",
      "Epoch 19: TRAIN Accuracy = 0.583 Loss = 0.658 AUC = 0.612\n",
      "Epoch 19: VAL Accuracy = 0.6 Loss = 0.672 AUC = 0.672\n",
      "Epoch 20: TRAIN Accuracy = 0.637 Loss = 0.645 AUC = 0.652\n",
      "Epoch 20: VAL Accuracy = 0.667 Loss = 0.628 AUC = 0.677\n",
      "Epoch 21: TRAIN Accuracy = 0.634 Loss = 0.638 AUC = 0.615\n",
      "Epoch 21: VAL Accuracy = 0.633 Loss = 0.616 AUC = 0.688\n",
      "Epoch 22: TRAIN Accuracy = 0.643 Loss = 0.62 AUC = 0.653\n",
      "Epoch 22: VAL Accuracy = 0.653 Loss = 0.601 AUC = 0.676\n",
      "Epoch 23: TRAIN Accuracy = 0.649 Loss = 0.617 AUC = 0.683\n",
      "Epoch 23: VAL Accuracy = 0.68 Loss = 0.594 AUC = 0.682\n",
      "Epoch 24: TRAIN Accuracy = 0.617 Loss = 0.619 AUC = 0.62\n",
      "Epoch 24: VAL Accuracy = 0.62 Loss = 0.645 AUC = 0.671\n",
      "Epoch 25: TRAIN Accuracy = 0.557 Loss = 0.668 AUC = 0.604\n",
      "Epoch 25: VAL Accuracy = 0.673 Loss = 0.583 AUC = 0.693\n",
      "Epoch 26: TRAIN Accuracy = 0.646 Loss = 0.611 AUC = 0.647\n",
      "Epoch 26: VAL Accuracy = 0.66 Loss = 0.599 AUC = 0.696\n",
      "Epoch 27: TRAIN Accuracy = 0.643 Loss = 0.621 AUC = 0.65\n",
      "Epoch 27: VAL Accuracy = 0.687 Loss = 0.595 AUC = 0.713\n",
      "Epoch 28: TRAIN Accuracy = 0.609 Loss = 0.611 AUC = 0.617\n",
      "Epoch 28: VAL Accuracy = 0.693 Loss = 0.579 AUC = 0.713\n",
      "Epoch 29: TRAIN Accuracy = 0.657 Loss = 0.597 AUC = 0.659\n",
      "Epoch 29: VAL Accuracy = 0.72 Loss = 0.546 AUC = 0.713\n",
      "Epoch 30: TRAIN Accuracy = 0.686 Loss = 0.574 AUC = 0.719\n",
      "Epoch 30: VAL Accuracy = 0.653 Loss = 0.61 AUC = 0.733\n",
      "Epoch 31: TRAIN Accuracy = 0.646 Loss = 0.613 AUC = 0.655\n",
      "Epoch 31: VAL Accuracy = 0.68 Loss = 0.56 AUC = 0.693\n",
      "Epoch 32: TRAIN Accuracy = 0.663 Loss = 0.588 AUC = 0.651\n",
      "Epoch 32: VAL Accuracy = 0.673 Loss = 0.576 AUC = 0.693\n",
      "Epoch 33: TRAIN Accuracy = 0.646 Loss = 0.601 AUC = 0.663\n",
      "Epoch 33: VAL Accuracy = 0.7 Loss = 0.563 AUC = 0.693\n",
      "Epoch 34: TRAIN Accuracy = 0.66 Loss = 0.592 AUC = 0.66\n",
      "Epoch 34: VAL Accuracy = 0.68 Loss = 0.575 AUC = 0.696\n",
      "Epoch 35: TRAIN Accuracy = 0.634 Loss = 0.588 AUC = 0.658\n",
      "Epoch 35: VAL Accuracy = 0.7 Loss = 0.567 AUC = 0.716\n",
      "Epoch 36: TRAIN Accuracy = 0.631 Loss = 0.591 AUC = 0.61\n",
      "Epoch 36: VAL Accuracy = 0.72 Loss = 0.553 AUC = 0.716\n",
      "Epoch 37: TRAIN Accuracy = 0.694 Loss = 0.567 AUC = 0.73\n",
      "Epoch 37: VAL Accuracy = 0.74 Loss = 0.543 AUC = 0.72\n",
      "Epoch 38: TRAIN Accuracy = 0.677 Loss = 0.569 AUC = 0.696\n",
      "Epoch 38: VAL Accuracy = 0.74 Loss = 0.533 AUC = 0.711\n",
      "Epoch 39: TRAIN Accuracy = 0.694 Loss = 0.572 AUC = 0.675\n",
      "Epoch 39: VAL Accuracy = 0.74 Loss = 0.526 AUC = 0.735\n",
      "Epoch 40: TRAIN Accuracy = 0.666 Loss = 0.567 AUC = 0.682\n",
      "Epoch 40: VAL Accuracy = 0.72 Loss = 0.539 AUC = 0.735\n",
      "Epoch 41: TRAIN Accuracy = 0.686 Loss = 0.562 AUC = 0.69\n",
      "Epoch 41: VAL Accuracy = 0.72 Loss = 0.53 AUC = 0.735\n",
      "Epoch 42: TRAIN Accuracy = 0.703 Loss = 0.54 AUC = 0.717\n",
      "Epoch 42: VAL Accuracy = 0.74 Loss = 0.512 AUC = 0.731\n",
      "Epoch 43: TRAIN Accuracy = 0.689 Loss = 0.562 AUC = 0.679\n",
      "Epoch 43: VAL Accuracy = 0.74 Loss = 0.509 AUC = 0.751\n",
      "Epoch 44: TRAIN Accuracy = 0.674 Loss = 0.529 AUC = 0.712\n",
      "Epoch 44: VAL Accuracy = 0.78 Loss = 0.496 AUC = 0.766\n",
      "Epoch 45: TRAIN Accuracy = 0.717 Loss = 0.522 AUC = 0.771\n",
      "Epoch 45: VAL Accuracy = 0.76 Loss = 0.491 AUC = 0.773\n",
      "Epoch 46: TRAIN Accuracy = 0.743 Loss = 0.507 AUC = 0.771\n",
      "Epoch 46: VAL Accuracy = 0.767 Loss = 0.488 AUC = 0.766\n",
      "Epoch 47: TRAIN Accuracy = 0.723 Loss = 0.526 AUC = 0.712\n",
      "Epoch 47: VAL Accuracy = 0.78 Loss = 0.473 AUC = 0.771\n",
      "Epoch 48: TRAIN Accuracy = 0.714 Loss = 0.512 AUC = 0.747\n",
      "Epoch 48: VAL Accuracy = 0.76 Loss = 0.488 AUC = 0.751\n",
      "Epoch 49: TRAIN Accuracy = 0.731 Loss = 0.514 AUC = 0.748\n",
      "Epoch 49: VAL Accuracy = 0.76 Loss = 0.488 AUC = 0.771\n",
      "Epoch 50: TRAIN Accuracy = 0.709 Loss = 0.523 AUC = 0.708\n",
      "Epoch 50: VAL Accuracy = 0.76 Loss = 0.483 AUC = 0.766\n",
      "Epoch 51: TRAIN Accuracy = 0.746 Loss = 0.514 AUC = 0.734\n",
      "Epoch 51: VAL Accuracy = 0.78 Loss = 0.482 AUC = 0.766\n",
      "Epoch 52: TRAIN Accuracy = 0.74 Loss = 0.502 AUC = 0.77\n",
      "Epoch 52: VAL Accuracy = 0.78 Loss = 0.465 AUC = 0.766\n",
      "Epoch 53: TRAIN Accuracy = 0.751 Loss = 0.496 AUC = 0.738\n",
      "Epoch 53: VAL Accuracy = 0.767 Loss = 0.472 AUC = 0.768\n",
      "Epoch 54: TRAIN Accuracy = 0.74 Loss = 0.499 AUC = 0.746\n",
      "Epoch 54: VAL Accuracy = 0.78 Loss = 0.459 AUC = 0.777\n",
      "Epoch 55: TRAIN Accuracy = 0.754 Loss = 0.493 AUC = 0.781\n",
      "Epoch 55: VAL Accuracy = 0.78 Loss = 0.461 AUC = 0.777\n",
      "Epoch 56: TRAIN Accuracy = 0.743 Loss = 0.492 AUC = 0.759\n",
      "Epoch 56: VAL Accuracy = 0.78 Loss = 0.456 AUC = 0.773\n",
      "Epoch 57: TRAIN Accuracy = 0.771 Loss = 0.482 AUC = 0.778\n",
      "Epoch 57: VAL Accuracy = 0.78 Loss = 0.455 AUC = 0.766\n",
      "Epoch 58: TRAIN Accuracy = 0.763 Loss = 0.483 AUC = 0.772\n",
      "Epoch 58: VAL Accuracy = 0.78 Loss = 0.453 AUC = 0.766\n",
      "Epoch 59: TRAIN Accuracy = 0.774 Loss = 0.477 AUC = 0.79\n",
      "Epoch 59: VAL Accuracy = 0.78 Loss = 0.45 AUC = 0.766\n",
      "Epoch 60: TRAIN Accuracy = 0.754 Loss = 0.479 AUC = 0.759\n",
      "Epoch 60: VAL Accuracy = 0.78 Loss = 0.449 AUC = 0.797\n",
      "Epoch 61: TRAIN Accuracy = 0.769 Loss = 0.475 AUC = 0.785\n",
      "Epoch 61: VAL Accuracy = 0.82 Loss = 0.444 AUC = 0.812\n",
      "Epoch 62: TRAIN Accuracy = 0.78 Loss = 0.469 AUC = 0.791\n",
      "Epoch 62: VAL Accuracy = 0.747 Loss = 0.471 AUC = 0.777\n",
      "Epoch 63: TRAIN Accuracy = 0.746 Loss = 0.497 AUC = 0.707\n",
      "Epoch 63: VAL Accuracy = 0.76 Loss = 0.462 AUC = 0.775\n",
      "Epoch 64: TRAIN Accuracy = 0.72 Loss = 0.495 AUC = 0.713\n",
      "Epoch 64: VAL Accuracy = 0.76 Loss = 0.451 AUC = 0.795\n",
      "Epoch 65: TRAIN Accuracy = 0.743 Loss = 0.49 AUC = 0.721\n",
      "Epoch 65: VAL Accuracy = 0.76 Loss = 0.449 AUC = 0.797\n",
      "Epoch 66: TRAIN Accuracy = 0.749 Loss = 0.477 AUC = 0.775\n",
      "Epoch 66: VAL Accuracy = 0.8 Loss = 0.447 AUC = 0.795\n",
      "Epoch 67: TRAIN Accuracy = 0.76 Loss = 0.483 AUC = 0.751\n",
      "Epoch 67: VAL Accuracy = 0.76 Loss = 0.447 AUC = 0.817\n",
      "Epoch 68: TRAIN Accuracy = 0.757 Loss = 0.481 AUC = 0.749\n",
      "Epoch 68: VAL Accuracy = 0.8 Loss = 0.444 AUC = 0.817\n",
      "Epoch 69: TRAIN Accuracy = 0.789 Loss = 0.475 AUC = 0.774\n",
      "Epoch 69: VAL Accuracy = 0.8 Loss = 0.44 AUC = 0.817\n",
      "Epoch 70: TRAIN Accuracy = 0.78 Loss = 0.474 AUC = 0.771\n",
      "Epoch 70: VAL Accuracy = 0.807 Loss = 0.435 AUC = 0.807\n",
      "Epoch 71: TRAIN Accuracy = 0.786 Loss = 0.474 AUC = 0.759\n",
      "Epoch 71: VAL Accuracy = 0.8 Loss = 0.434 AUC = 0.818\n",
      "Epoch 72: TRAIN Accuracy = 0.783 Loss = 0.464 AUC = 0.78\n",
      "Epoch 72: VAL Accuracy = 0.82 Loss = 0.425 AUC = 0.818\n",
      "Epoch 73: TRAIN Accuracy = 0.803 Loss = 0.448 AUC = 0.813\n",
      "Epoch 73: VAL Accuracy = 0.82 Loss = 0.416 AUC = 0.817\n",
      "Epoch 74: TRAIN Accuracy = 0.791 Loss = 0.457 AUC = 0.784\n",
      "Epoch 74: VAL Accuracy = 0.787 Loss = 0.446 AUC = 0.796\n",
      "Epoch 75: TRAIN Accuracy = 0.76 Loss = 0.496 AUC = 0.72\n",
      "Epoch 75: VAL Accuracy = 0.767 Loss = 0.466 AUC = 0.776\n",
      "Epoch 76: TRAIN Accuracy = 0.76 Loss = 0.481 AUC = 0.755\n",
      "Epoch 76: VAL Accuracy = 0.76 Loss = 0.463 AUC = 0.764\n",
      "Epoch 77: TRAIN Accuracy = 0.757 Loss = 0.478 AUC = 0.761\n",
      "Epoch 77: VAL Accuracy = 0.78 Loss = 0.452 AUC = 0.802\n",
      "Epoch 78: TRAIN Accuracy = 0.786 Loss = 0.455 AUC = 0.792\n",
      "Epoch 78: VAL Accuracy = 0.8 Loss = 0.428 AUC = 0.799\n",
      "Epoch 79: TRAIN Accuracy = 0.786 Loss = 0.451 AUC = 0.765\n",
      "Epoch 79: VAL Accuracy = 0.82 Loss = 0.414 AUC = 0.815\n",
      "Epoch 80: TRAIN Accuracy = 0.789 Loss = 0.445 AUC = 0.784\n",
      "Epoch 80: VAL Accuracy = 0.807 Loss = 0.414 AUC = 0.822\n",
      "Epoch 81: TRAIN Accuracy = 0.797 Loss = 0.425 AUC = 0.815\n",
      "Epoch 81: VAL Accuracy = 0.82 Loss = 0.403 AUC = 0.819\n",
      "Epoch 82: TRAIN Accuracy = 0.8 Loss = 0.441 AUC = 0.784\n",
      "Epoch 82: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.819\n",
      "Epoch 83: TRAIN Accuracy = 0.797 Loss = 0.423 AUC = 0.81\n",
      "Epoch 83: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.817\n",
      "Epoch 84: TRAIN Accuracy = 0.803 Loss = 0.427 AUC = 0.798\n",
      "Epoch 84: VAL Accuracy = 0.82 Loss = 0.398 AUC = 0.827\n",
      "Epoch 85: TRAIN Accuracy = 0.794 Loss = 0.428 AUC = 0.812\n",
      "Epoch 85: VAL Accuracy = 0.8 Loss = 0.422 AUC = 0.827\n",
      "Epoch 86: TRAIN Accuracy = 0.786 Loss = 0.448 AUC = 0.768\n",
      "Epoch 86: VAL Accuracy = 0.8 Loss = 0.419 AUC = 0.825\n",
      "Epoch 87: TRAIN Accuracy = 0.783 Loss = 0.441 AUC = 0.795\n",
      "Epoch 87: VAL Accuracy = 0.8 Loss = 0.418 AUC = 0.824\n",
      "Epoch 88: TRAIN Accuracy = 0.783 Loss = 0.434 AUC = 0.833\n",
      "Epoch 88: VAL Accuracy = 0.8 Loss = 0.416 AUC = 0.82\n",
      "Epoch 89: TRAIN Accuracy = 0.783 Loss = 0.445 AUC = 0.787\n",
      "Epoch 89: VAL Accuracy = 0.8 Loss = 0.413 AUC = 0.822\n",
      "Epoch 90: TRAIN Accuracy = 0.789 Loss = 0.437 AUC = 0.788\n",
      "Epoch 90: VAL Accuracy = 0.82 Loss = 0.407 AUC = 0.822\n",
      "Epoch 91: TRAIN Accuracy = 0.8 Loss = 0.435 AUC = 0.789\n",
      "Epoch 91: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.819\n",
      "Epoch 92: TRAIN Accuracy = 0.797 Loss = 0.435 AUC = 0.773\n",
      "Epoch 92: VAL Accuracy = 0.82 Loss = 0.396 AUC = 0.821\n",
      "Epoch 93: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.835\n",
      "Epoch 93: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.814\n",
      "Epoch 94: TRAIN Accuracy = 0.791 Loss = 0.428 AUC = 0.796\n",
      "Epoch 94: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.816\n",
      "Epoch 95: TRAIN Accuracy = 0.794 Loss = 0.429 AUC = 0.791\n",
      "Epoch 95: VAL Accuracy = 0.82 Loss = 0.397 AUC = 0.816\n",
      "Epoch 96: TRAIN Accuracy = 0.8 Loss = 0.426 AUC = 0.78\n",
      "Epoch 96: VAL Accuracy = 0.82 Loss = 0.4 AUC = 0.816\n",
      "Epoch 97: TRAIN Accuracy = 0.8 Loss = 0.426 AUC = 0.782\n",
      "Epoch 97: VAL Accuracy = 0.82 Loss = 0.395 AUC = 0.819\n",
      "Epoch 98: TRAIN Accuracy = 0.803 Loss = 0.429 AUC = 0.768\n",
      "Epoch 98: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.817\n",
      "Epoch 99: TRAIN Accuracy = 0.8 Loss = 0.425 AUC = 0.797\n",
      "Epoch 99: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.817\n",
      "Epoch 100: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.792\n",
      "Epoch 100: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.824\n",
      "Epoch 101: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.8\n",
      "Epoch 101: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.829\n",
      "Epoch 102: TRAIN Accuracy = 0.806 Loss = 0.427 AUC = 0.775\n",
      "Epoch 102: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.819\n",
      "Epoch 103: TRAIN Accuracy = 0.803 Loss = 0.424 AUC = 0.777\n",
      "Epoch 103: VAL Accuracy = 0.82 Loss = 0.394 AUC = 0.818\n",
      "Epoch 104: TRAIN Accuracy = 0.8 Loss = 0.42 AUC = 0.815\n",
      "Epoch 104: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.822\n",
      "Epoch 105: TRAIN Accuracy = 0.809 Loss = 0.418 AUC = 0.785\n",
      "Epoch 105: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.82\n",
      "Epoch 106: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.809\n",
      "Epoch 106: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.824\n",
      "Epoch 107: TRAIN Accuracy = 0.806 Loss = 0.423 AUC = 0.775\n",
      "Epoch 107: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.819\n",
      "Epoch 108: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.825\n",
      "Epoch 108: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.819\n",
      "Epoch 109: TRAIN Accuracy = 0.806 Loss = 0.42 AUC = 0.783\n",
      "Epoch 109: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.815\n",
      "Epoch 110: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.804\n",
      "Epoch 110: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.815\n",
      "Epoch 111: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.817\n",
      "Epoch 111: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.819\n",
      "Epoch 112: TRAIN Accuracy = 0.806 Loss = 0.42 AUC = 0.792\n",
      "Epoch 112: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.818\n",
      "Epoch 113: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.806\n",
      "Epoch 113: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.822\n",
      "Epoch 114: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.811\n",
      "Epoch 114: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.829\n",
      "Epoch 115: TRAIN Accuracy = 0.806 Loss = 0.406 AUC = 0.832\n",
      "Epoch 115: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.829\n",
      "Epoch 116: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.8\n",
      "Epoch 116: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.822\n",
      "Epoch 117: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.786\n",
      "Epoch 117: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.824\n",
      "Epoch 118: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.788\n",
      "Epoch 118: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.824\n",
      "Epoch 119: TRAIN Accuracy = 0.803 Loss = 0.421 AUC = 0.783\n",
      "Epoch 119: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.82\n",
      "Epoch 120: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.797\n",
      "Epoch 120: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.82\n",
      "Epoch 121: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.789\n",
      "Epoch 121: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.824\n",
      "Epoch 122: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.799\n",
      "Epoch 122: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.815\n",
      "Epoch 123: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.797\n",
      "Epoch 123: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.817\n",
      "Epoch 124: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.804\n",
      "Epoch 124: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.817\n",
      "Epoch 125: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.806\n",
      "Epoch 125: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.823\n",
      "Epoch 126: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.822\n",
      "Epoch 126: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.823\n",
      "Epoch 127: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.812\n",
      "Epoch 127: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.823\n",
      "Epoch 128: TRAIN Accuracy = 0.806 Loss = 0.419 AUC = 0.78\n",
      "Epoch 128: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.823\n",
      "Epoch 129: TRAIN Accuracy = 0.803 Loss = 0.412 AUC = 0.823\n",
      "Epoch 129: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.827\n",
      "Epoch 130: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.821\n",
      "Epoch 130: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.827\n",
      "Epoch 131: TRAIN Accuracy = 0.803 Loss = 0.416 AUC = 0.801\n",
      "Epoch 131: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.823\n",
      "Epoch 132: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.814\n",
      "Epoch 132: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.817\n",
      "Epoch 133: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.812\n",
      "Epoch 133: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.817\n",
      "Epoch 134: TRAIN Accuracy = 0.803 Loss = 0.414 AUC = 0.808\n",
      "Epoch 134: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.823\n",
      "Epoch 135: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.804\n",
      "Epoch 135: VAL Accuracy = 0.82 Loss = 0.393 AUC = 0.822\n",
      "Epoch 136: TRAIN Accuracy = 0.803 Loss = 0.411 AUC = 0.831\n",
      "Epoch 136: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.825\n",
      "Epoch 137: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.824\n",
      "Epoch 137: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.817\n",
      "Epoch 138: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.812\n",
      "Epoch 138: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.823\n",
      "Epoch 139: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.811\n",
      "Epoch 139: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.827\n",
      "Epoch 140: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.792\n",
      "Epoch 140: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.823\n",
      "Epoch 141: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.83\n",
      "Epoch 141: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.823\n",
      "Epoch 142: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.812\n",
      "Epoch 142: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.823\n",
      "Epoch 143: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.8\n",
      "Epoch 143: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.823\n",
      "Epoch 144: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.782\n",
      "Epoch 144: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.825\n",
      "Epoch 145: TRAIN Accuracy = 0.806 Loss = 0.409 AUC = 0.822\n",
      "Epoch 145: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.823\n",
      "Epoch 146: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.806\n",
      "Epoch 146: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.82\n",
      "Epoch 147: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.809\n",
      "Epoch 147: VAL Accuracy = 0.807 Loss = 0.404 AUC = 0.817\n",
      "Epoch 148: TRAIN Accuracy = 0.8 Loss = 0.433 AUC = 0.811\n",
      "Epoch 148: VAL Accuracy = 0.8 Loss = 0.415 AUC = 0.827\n",
      "Epoch 149: TRAIN Accuracy = 0.786 Loss = 0.44 AUC = 0.789\n",
      "Epoch 149: VAL Accuracy = 0.8 Loss = 0.416 AUC = 0.829\n",
      "Epoch 150: TRAIN Accuracy = 0.78 Loss = 0.443 AUC = 0.78\n",
      "Epoch 150: VAL Accuracy = 0.8 Loss = 0.416 AUC = 0.807\n",
      "Epoch 151: TRAIN Accuracy = 0.786 Loss = 0.437 AUC = 0.8\n",
      "Epoch 151: VAL Accuracy = 0.8 Loss = 0.414 AUC = 0.829\n",
      "Epoch 152: TRAIN Accuracy = 0.783 Loss = 0.437 AUC = 0.807\n",
      "Epoch 152: VAL Accuracy = 0.8 Loss = 0.413 AUC = 0.827\n",
      "Epoch 153: TRAIN Accuracy = 0.786 Loss = 0.441 AUC = 0.772\n",
      "Epoch 153: VAL Accuracy = 0.8 Loss = 0.412 AUC = 0.829\n",
      "Epoch 154: TRAIN Accuracy = 0.786 Loss = 0.433 AUC = 0.8\n",
      "Epoch 154: VAL Accuracy = 0.8 Loss = 0.412 AUC = 0.834\n",
      "Epoch 155: TRAIN Accuracy = 0.789 Loss = 0.432 AUC = 0.788\n",
      "Epoch 155: VAL Accuracy = 0.8 Loss = 0.411 AUC = 0.829\n",
      "Epoch 156: TRAIN Accuracy = 0.789 Loss = 0.434 AUC = 0.784\n",
      "Epoch 156: VAL Accuracy = 0.8 Loss = 0.41 AUC = 0.829\n",
      "Epoch 157: TRAIN Accuracy = 0.791 Loss = 0.43 AUC = 0.808\n",
      "Epoch 157: VAL Accuracy = 0.82 Loss = 0.404 AUC = 0.824\n",
      "Epoch 158: TRAIN Accuracy = 0.803 Loss = 0.422 AUC = 0.808\n",
      "Epoch 158: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.824\n",
      "Epoch 159: TRAIN Accuracy = 0.8 Loss = 0.418 AUC = 0.816\n",
      "Epoch 159: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.824\n",
      "Epoch 160: TRAIN Accuracy = 0.803 Loss = 0.416 AUC = 0.803\n",
      "Epoch 160: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.815\n",
      "Epoch 161: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.792\n",
      "Epoch 161: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 162: TRAIN Accuracy = 0.803 Loss = 0.421 AUC = 0.779\n",
      "Epoch 162: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 163: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.804\n",
      "Epoch 163: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 164: TRAIN Accuracy = 0.806 Loss = 0.418 AUC = 0.782\n",
      "Epoch 164: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 165: TRAIN Accuracy = 0.803 Loss = 0.419 AUC = 0.786\n",
      "Epoch 165: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 166: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.815\n",
      "Epoch 166: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.82\n",
      "Epoch 167: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.819\n",
      "Epoch 167: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 168: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.787\n",
      "Epoch 168: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.828\n",
      "Epoch 169: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.824\n",
      "Epoch 169: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 170: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.803\n",
      "Epoch 170: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 171: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.824\n",
      "Epoch 171: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.829\n",
      "Epoch 172: TRAIN Accuracy = 0.809 Loss = 0.419 AUC = 0.782\n",
      "Epoch 172: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.829\n",
      "Epoch 173: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.819\n",
      "Epoch 173: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 174: TRAIN Accuracy = 0.806 Loss = 0.409 AUC = 0.834\n",
      "Epoch 174: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 175: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.813\n",
      "Epoch 175: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 176: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.801\n",
      "Epoch 176: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 177: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.79\n",
      "Epoch 177: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 178: TRAIN Accuracy = 0.806 Loss = 0.407 AUC = 0.825\n",
      "Epoch 178: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 179: TRAIN Accuracy = 0.806 Loss = 0.417 AUC = 0.785\n",
      "Epoch 179: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 180: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.822\n",
      "Epoch 180: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.815\n",
      "Epoch 181: TRAIN Accuracy = 0.803 Loss = 0.408 AUC = 0.83\n",
      "Epoch 181: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 182: TRAIN Accuracy = 0.803 Loss = 0.418 AUC = 0.814\n",
      "Epoch 182: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 183: TRAIN Accuracy = 0.806 Loss = 0.412 AUC = 0.828\n",
      "Epoch 183: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.829\n",
      "Epoch 184: TRAIN Accuracy = 0.806 Loss = 0.415 AUC = 0.801\n",
      "Epoch 184: VAL Accuracy = 0.82 Loss = 0.389 AUC = 0.824\n",
      "Epoch 185: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.812\n",
      "Epoch 185: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 186: TRAIN Accuracy = 0.8 Loss = 0.419 AUC = 0.805\n",
      "Epoch 186: VAL Accuracy = 0.82 Loss = 0.392 AUC = 0.822\n",
      "Epoch 187: TRAIN Accuracy = 0.797 Loss = 0.427 AUC = 0.786\n",
      "Epoch 187: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 188: TRAIN Accuracy = 0.803 Loss = 0.412 AUC = 0.824\n",
      "Epoch 188: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 189: TRAIN Accuracy = 0.806 Loss = 0.408 AUC = 0.829\n",
      "Epoch 189: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.829\n",
      "Epoch 190: TRAIN Accuracy = 0.803 Loss = 0.406 AUC = 0.838\n",
      "Epoch 190: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 191: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.798\n",
      "Epoch 191: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 192: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.794\n",
      "Epoch 192: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 193: TRAIN Accuracy = 0.806 Loss = 0.41 AUC = 0.81\n",
      "Epoch 193: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n",
      "Epoch 194: TRAIN Accuracy = 0.806 Loss = 0.416 AUC = 0.791\n",
      "Epoch 194: VAL Accuracy = 0.82 Loss = 0.389 AUC = 0.815\n",
      "Epoch 195: TRAIN Accuracy = 0.806 Loss = 0.407 AUC = 0.826\n",
      "Epoch 195: VAL Accuracy = 0.82 Loss = 0.389 AUC = 0.824\n",
      "Epoch 196: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.794\n",
      "Epoch 196: VAL Accuracy = 0.82 Loss = 0.389 AUC = 0.824\n",
      "Epoch 197: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.786\n",
      "Epoch 197: VAL Accuracy = 0.82 Loss = 0.389 AUC = 0.824\n",
      "Epoch 198: TRAIN Accuracy = 0.806 Loss = 0.411 AUC = 0.806\n",
      "Epoch 198: VAL Accuracy = 0.82 Loss = 0.389 AUC = 0.829\n",
      "Epoch 199: TRAIN Accuracy = 0.806 Loss = 0.413 AUC = 0.802\n",
      "Epoch 199: VAL Accuracy = 0.82 Loss = 0.391 AUC = 0.824\n",
      "Epoch 200: TRAIN Accuracy = 0.806 Loss = 0.414 AUC = 0.801\n",
      "Epoch 200: VAL Accuracy = 0.82 Loss = 0.39 AUC = 0.824\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {(i + 1)}: TRAIN Accuracy = {np.round(epoch_acc[i], 3)} Loss = {np.round(epoch_loss[i], 3)} AUC = {np.round(epoch_auc[i], 3)}\")\n",
    "    print(f\"Epoch {(i + 1)}: VAL Accuracy = {np.round(epoch_val_acc[i], 3)} Loss = {np.round(epoch_val_loss[i], 3)} AUC = {np.round(epoch_val_auc[i], 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-signals-_5HxkjSc-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
