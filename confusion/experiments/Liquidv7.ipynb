{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, GRU, Input, BatchNormalization, Dropout, TimeDistributed\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.keras import LTC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 300\n",
    "STEP = 5\n",
    "NUM_EXPERIMENTS = 10\n",
    "\n",
    "def create_model(train):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train.shape[1], train.shape[2])))\n",
    "\n",
    "    model.add(TimeDistributed(Dense(16, activation='relu')))\n",
    "\n",
    "    model.add(LTC(AutoNCP(32, 25), return_sequences=True))\n",
    "    model.add(LTC(AutoNCP(25, 16), return_sequences=False))\n",
    "\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0003), loss='binary_crossentropy', metrics=[\"accuracy\", AUC(name=\"auc\")])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = [\"ID\"]\n",
    "IDS = [\"SubjectID\", \"VideoID\"]\n",
    "TARGET = [\"predefinedlabel\"]\n",
    "FEATURES = [\"Raw\", \"Delta\", \"Theta\", \"Alpha1\", \"Alpha2\", \"Beta1\", \"Beta2\", \"Gamma1\", \"Gamma2\"]\n",
    "INIT_SEED = 5412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/home/aseliverstov/projects/brain_signals/data_confusion\")\n",
    "data = pd.read_csv(data_dir / \"EEG_data.csv\")\n",
    "\n",
    "data[\"ID\"] = (len(np.unique(data[\"VideoID\"])) * data[\"SubjectID\"] + data[\"VideoID\"]).astype(\"int\")\n",
    "data = data[ID + FEATURES + TARGET]\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_dataset(data):\n",
    "    features = []\n",
    "    target = []\n",
    "    for cur_id in np.unique(data[ID].to_numpy()):\n",
    "        cur_id_data = data[data[ID].to_numpy() == cur_id]\n",
    "        target.append(np.mean(cur_id_data[TARGET].to_numpy()).astype(\"int\"))\n",
    "        features.append(cur_id_data[FEATURES].to_numpy())\n",
    "\n",
    "    features = pad_sequences(features)\n",
    "    return np.array(features), np.array(target)\n",
    "\n",
    "def pad_sequences(arrays, pad_value=0):\n",
    "    max_length = max(arr.shape[0] for arr in arrays)\n",
    "    padded_arrays = [\n",
    "        np.pad(\n",
    "            arr,\n",
    "            ((0, max_length - arr.shape[0]), (0, 0)),\n",
    "            mode='constant',\n",
    "            constant_values=pad_value)\n",
    "            for arr in arrays\n",
    "        ]\n",
    "    return np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, _ = reshape_dataset(data)\n",
    "model = create_model(X)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "models = []\n",
    "\n",
    "for i in range(NUM_EPOCHS // STEP):\n",
    "    epoch_acc = []\n",
    "    epoch_loss = []\n",
    "    epoch_auc = []\n",
    "\n",
    "    epoch_val_acc = []\n",
    "    epoch_val_loss = []\n",
    "    epoch_val_auc = []\n",
    "\n",
    "    for j, seed in tqdm(enumerate(np.arange(NUM_EXPERIMENTS) + INIT_SEED)):\n",
    "        np.random.seed(int(seed))\n",
    "        random.seed(int(seed))\n",
    "        tf.random.set_seed(int(seed))\n",
    "\n",
    "        train_id = np.random.choice(np.unique(np.ravel(data[ID])), 70, replace=False)\n",
    "        train_index = np.isin(data[ID], train_id)\n",
    "\n",
    "        train = data.iloc[train_index]\n",
    "        test = data.iloc[~train_index]\n",
    "\n",
    "        X_train, y_train = reshape_dataset(train)\n",
    "        X_test, y_test = reshape_dataset(test)\n",
    "\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "        y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "        if i == 0:\n",
    "            model = create_model(X_train)\n",
    "            models.append(model)\n",
    "        else:\n",
    "            model = models[j]\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            validation_data=(X_test, y_test),\n",
    "            epochs=STEP,\n",
    "            batch_size=16,\n",
    "            verbose=0,\n",
    "        )\n",
    "        acc = history.history['accuracy'][0]\n",
    "        loss = history.history['loss'][0]\n",
    "        auc = history.history['auc'][0]\n",
    "\n",
    "        val_acc = history.history['val_accuracy'][0]\n",
    "        val_loss = history.history['val_loss'][0]\n",
    "        val_auc = history.history['val_auc'][0]\n",
    "\n",
    "        epoch_acc.append(acc)\n",
    "        epoch_loss.append(loss)\n",
    "        epoch_auc.append(auc)\n",
    "\n",
    "        epoch_val_acc.append(val_acc)\n",
    "        epoch_val_loss.append(val_loss)\n",
    "        epoch_val_auc.append(val_auc)\n",
    "\n",
    "    print(f\"Epoch {(i + 1) * STEP}: TRAIN Accuracy = {np.round(np.mean(epoch_acc), 3)} Loss = {np.round(np.mean(epoch_loss), 3)} AUC = {np.round(np.mean(epoch_auc), 3)}\")\n",
    "    print(f\"Epoch {(i + 1) * STEP}: VAL Accuracy = {np.round(np.mean(epoch_val_acc), 3)} Loss = {np.round(np.mean(epoch_val_loss), 3)} AUC = {np.round(np.mean(epoch_val_auc), 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-signals-_5HxkjSc-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
